using world size: 8, data-parallel-size: 8, tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
using torch.float16 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_query_key_layer_scaling ................... True
  apply_residual_connection_post_layernorm ........ False
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  bert_binary_head ................................ True
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  checkpoint_activations .......................... True
  checkpoint_num_layers ........................... 1
  clip_grad ....................................... 1.0
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  data_impl ....................................... mmap
  data_parallel_size .............................. 8
  data_path ....................................... ['/workspace/Megatron-LM/my-gpt2_text_document']
  dataloader_type ................................. single
  DDP_impl ........................................ local
  decoder_seq_length .............................. None
  distribute_checkpointed_activations ............. False
  distributed_backend ............................. nccl
  embedding_path .................................. None
  encoder_seq_length .............................. 1024
  eod_mask_loss ................................... False
  eval_interval ................................... 10
  eval_iters ...................................... 10
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  ffn_hidden_size ................................. 6400
  finetune ........................................ False
  fp16 ............................................ True
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  global_batch_size ............................... 512
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 1600
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_dim ......................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  kv_channels ..................................... 64
  layernorm_epsilon ............................... 1e-05
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... 0
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 1
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  make_vocab_size_divisible_by .................... 128
  mask_prob ....................................... 0.15
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 1024
  merge_file ...................................... /workspace/Megatron-LM/gpt2-merges.txt
  micro_batch_size ................................ 4
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_warmup ..................................... False
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_save_optim ................................... None
  no_save_rng ..................................... None
  num_attention_heads ............................. 25
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_layers ...................................... 48
  num_layers_per_virtual_pipeline_stage ........... None
  num_workers ..................................... 2
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  override_lr_scheduler ........................... False
  params_dtype .................................... torch.float16
  patch_dim ....................................... 16
  pipeline_model_parallel_size .................... 1
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 10000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 1024
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  split ........................................... 800,100,100
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  titles_data_path ................................ None
  tokenizer_type .................................. GPT2BPETokenizer
  train_iters ..................................... 1000
  train_samples ................................... None
  use_checkpoint_lr_scheduler ..................... False
  use_contiguous_buffers_in_ddp ................... False
  use_cpu_initialization .......................... None
  use_one_sent_docs ............................... False
  virtual_pipeline_model_parallel_size ............ None
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /workspace/Megatron-LM/gpt2-vocab.json
  weight_decay .................................... 0.01
  world_size ...................................... 8
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 16
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initializing tensor model parallel with size 1
> initializing pipeline model parallel with size 1
> setting random seeds to 1234 ...
> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234
> compiling dataset index builder ...
make: Entering directory '/workspace/Megatron-LM/megatron/data'
g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/opt/conda/include/python3.8 -I/opt/conda/lib/python3.8/site-packages/pybind11/include helpers.cpp -o helpers.cpython-38-x86_64-linux-gnu.so
make: Leaving directory '/workspace/Megatron-LM/megatron/data'
>>> done with dataset index builder. Compilation time: 4.686 seconds
> compiling and loading fused kernels ...
Detected CUDA files, patching ldflags
Emitting ninja build file /workspace/Megatron-LM/megatron/fused_kernels/build/build.ninja...
Building extension module scaled_upper_triang_masked_softmax_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/3] c++ -MMD -MF scaled_upper_triang_masked_softmax.o.d -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1013\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++14 -O3 -c /workspace/Megatron-LM/megatron/fused_kernels/scaled_upper_triang_masked_softmax.cpp -o scaled_upper_triang_masked_softmax.o 
[2/3] /usr/local/cuda/bin/nvcc -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1013\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -std=c++14 -c /workspace/Megatron-LM/megatron/fused_kernels/scaled_upper_triang_masked_softmax_cuda.cu -o scaled_upper_triang_masked_softmax_cuda.cuda.o 
[3/3] c++ scaled_upper_triang_masked_softmax.o scaled_upper_triang_masked_softmax_cuda.cuda.o -shared -L/opt/conda/lib/python3.8/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o scaled_upper_triang_masked_softmax_cuda.so
Loading extension module scaled_upper_triang_masked_softmax_cuda...
Detected CUDA files, patching ldflags
Emitting ninja build file /workspace/Megatron-LM/megatron/fused_kernels/build/build.ninja...
Building extension module scaled_masked_softmax_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/3] c++ -MMD -MF scaled_masked_softmax.o.d -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1013\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++14 -O3 -c /workspace/Megatron-LM/megatron/fused_kernels/scaled_masked_softmax.cpp -o scaled_masked_softmax.o 
[2/3] /usr/local/cuda/bin/nvcc -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1013\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -gencode arch=compute_80,code=sm_80 -std=c++14 -c /workspace/Megatron-LM/megatron/fused_kernels/scaled_masked_softmax_cuda.cu -o scaled_masked_softmax_cuda.cuda.o 
[3/3] c++ scaled_masked_softmax.o scaled_masked_softmax_cuda.cuda.o -shared -L/opt/conda/lib/python3.8/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o scaled_masked_softmax_cuda.so
Loading extension module scaled_masked_softmax_cuda...
Detected CUDA files, patching ldflags
Emitting ninja build file /workspace/Megatron-LM/megatron/fused_kernels/build/build.ninja...
Building extension module fused_mix_prec_layer_norm_cuda...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[1/3] /usr/local/cuda/bin/nvcc -DTORCH_EXTENSION_NAME=fused_mix_prec_layer_norm_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1013\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_80,code=sm_80 --compiler-options '-fPIC' -O3 -gencode arch=compute_70,code=sm_70 --use_fast_math -maxrregcount=50 -gencode arch=compute_80,code=sm_80 -std=c++14 -c /workspace/Megatron-LM/megatron/fused_kernels/layer_norm_cuda_kernel.cu -o layer_norm_cuda_kernel.cuda.o 
[2/3] c++ -MMD -MF layer_norm_cuda.o.d -DTORCH_EXTENSION_NAME=fused_mix_prec_layer_norm_cuda -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1013\" -isystem /opt/conda/lib/python3.8/site-packages/torch/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.8/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.8/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.8 -D_GLIBCXX_USE_CXX11_ABI=1 -fPIC -std=c++14 -O3 -c /workspace/Megatron-LM/megatron/fused_kernels/layer_norm_cuda.cpp -o layer_norm_cuda.o 
[3/3] c++ layer_norm_cuda.o layer_norm_cuda_kernel.cuda.o -shared -L/opt/conda/lib/python3.8/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_mix_prec_layer_norm_cuda.so
Loading extension module fused_mix_prec_layer_norm_cuda...
>>> done with compiling and loading fused kernels. Compilation time: 104.341 seconds
time to initialize megatron (seconds): 150.266
[after megatron is initialized] datetime: 2021-08-12 09:55:34 
building GPT model ...
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 1557686400
> learning rate decay style: cosine
[after model, optimizer, and learning rate scheduler are built] datetime: 2021-08-12 09:55:36 
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      512000
    validation: 517120
    test:       5120
> building train, validation, and test datasets for GPT ...
 > building dataset index ...
    reading sizes...
    reading pointers...
    reading document index...
    creating numpy buffer of mmap...
    creating memory view of numpy buffer...
 > finished creating indexed dataset in 0.000900 seconds
    number of documents: 398
 > dataset split:
    train:
     document indices in [0, 318) total of 318 documents
    validation:
     document indices in [318, 358) total of 40 documents
    test:
     document indices in [358, 398) total of 40 documents
 > WARNING: could not find index map files, building the indices on rank 0 ...
 > last epoch number of samples (1) is larger than 80% of number of samples per epoch (1), setting separate_last_epoch to False
 > elasped time to build and save doc-idx mapping (seconds): 6.213482
    using:
     number of documents:       318
     number of epochs:          274497
     sequence length:           1024
     total number of samples:   512001
 > elasped time to build and save sample-idx mapping (seconds): 0.066880
 > building shuffle index with split [0, 512001) and [512001, 512001) ...
 > elasped time to build and save shuffle-idx mapping (seconds): 0.012505
 > loading doc-idx mapping from /workspace/Megatron-LM/my-gpt2_text_document_train_indexmap_512000ns_1024sl_1234s_doc_idx.npy
 > loading sample-idx mapping from /workspace/Megatron-LM/my-gpt2_text_document_train_indexmap_512000ns_1024sl_1234s_sample_idx.npy
 > loading shuffle-idx mapping from /workspace/Megatron-LM/my-gpt2_text_document_train_indexmap_512000ns_1024sl_1234s_shuffle_idx.npy
    loaded indexed file in 0.002 seconds
    total number of samples: 512002
    total number of epochs: 274497
 > WARNING: could not find index map files, building the indices on rank 0 ...
 > last epoch number of samples (1) is larger than 80% of number of samples per epoch (0), setting separate_last_epoch to False
 > elasped time to build and save doc-idx mapping (seconds): 6.325998
    using:
     number of documents:       40
     number of epochs:          2206379
     sequence length:           1024
     total number of samples:   517120
 > elasped time to build and save sample-idx mapping (seconds): 0.067892
 > building shuffle index with split [0, 517120) and [517120, 517120) ...
 > elasped time to build and save shuffle-idx mapping (seconds): 0.013222
 > loading doc-idx mapping from /workspace/Megatron-LM/my-gpt2_text_document_valid_indexmap_517120ns_1024sl_1234s_doc_idx.npy
 > loading sample-idx mapping from /workspace/Megatron-LM/my-gpt2_text_document_valid_indexmap_517120ns_1024sl_1234s_sample_idx.npy
 > loading shuffle-idx mapping from /workspace/Megatron-LM/my-gpt2_text_document_valid_indexmap_517120ns_1024sl_1234s_shuffle_idx.npy
    loaded indexed file in 0.002 seconds
    total number of samples: 517121
    total number of epochs: 2206379
 > WARNING: could not find index map files, building the indices on rank 0 ...
 > last epoch number of samples (1) is larger than 80% of number of samples per epoch (0), setting separate_last_epoch to False
 > elasped time to build and save doc-idx mapping (seconds): 0.030442
    using:
     number of documents:       40
     number of epochs:          21846
     sequence length:           1024
     total number of samples:   5120
 > elasped time to build and save sample-idx mapping (seconds): 0.000888
 > building shuffle index with split [0, 5120) and [5120, 5120) ...
 > elasped time to build and save shuffle-idx mapping (seconds): 0.000332
 > loading doc-idx mapping from /workspace/Megatron-LM/my-gpt2_text_document_test_indexmap_5120ns_1024sl_1234s_doc_idx.npy
 > loading sample-idx mapping from /workspace/Megatron-LM/my-gpt2_text_document_test_indexmap_5120ns_1024sl_1234s_sample_idx.npy
 > loading shuffle-idx mapping from /workspace/Megatron-LM/my-gpt2_text_document_test_indexmap_5120ns_1024sl_1234s_shuffle_idx.npy
    loaded indexed file in 0.001 seconds
    total number of samples: 5121
    total number of epochs: 21846
> finished creating GPT datasets ...
[after dataloaders are built] datetime: 2021-08-12 09:55:55 
done with setup ...
time (ms) | model-and-optimizer-setup: 1969.91 | train/valid/test-data-iterators-setup: 19172.04
training ...
[before the start of training step] datetime: 2021-08-12 09:55:55 
 iteration        1/    1000 | consumed samples:          512 | elapsed time per iteration (ms): 10512.7 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 4294967296.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 3842.21 | backward-compute: 6099.36 | backward-params-all-reduce: 89.74 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 88.90 | optimizer-unscale-and-check-inf: 386.15 | optimizer: 475.13 | batch-generator: 13.13
 iteration        2/    1000 | consumed samples:         1024 | elapsed time per iteration (ms): 7722.9 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 2147483648.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.26 | backward-compute: 5487.09 | backward-params-all-reduce: 90.59 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 13.01 | optimizer: 24.36 | batch-generator: 12.60
 iteration        3/    1000 | consumed samples:         1536 | elapsed time per iteration (ms): 7683.0 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 1073741824.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.44 | backward-compute: 5486.74 | backward-params-all-reduce: 51.99 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 13.00 | optimizer: 24.31 | batch-generator: 12.37
 iteration        4/    1000 | consumed samples:         2048 | elapsed time per iteration (ms): 7679.2 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 536870912.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.82 | backward-compute: 5486.70 | backward-params-all-reduce: 52.27 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 13.01 | optimizer: 24.34 | batch-generator: 12.34
 iteration        5/    1000 | consumed samples:         2560 | elapsed time per iteration (ms): 7687.6 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 268435456.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.54 | backward-compute: 5494.21 | backward-params-all-reduce: 52.61 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 12.94 | optimizer: 24.24 | batch-generator: 11.96
 iteration        6/    1000 | consumed samples:         3072 | elapsed time per iteration (ms): 7776.5 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 134217728.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2147.75 | backward-compute: 5542.80 | backward-params-all-reduce: 54.74 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 12.99 | optimizer: 24.38 | batch-generator: 12.00
 iteration        7/    1000 | consumed samples:         3584 | elapsed time per iteration (ms): 7782.0 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 67108864.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2144.26 | backward-compute: 5551.52 | backward-params-all-reduce: 54.79 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 13.00 | optimizer: 24.38 | batch-generator: 12.69
 iteration        8/    1000 | consumed samples:         4096 | elapsed time per iteration (ms): 7785.3 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 33554432.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2145.27 | backward-compute: 5554.49 | backward-params-all-reduce: 54.30 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.28 | optimizer-unscale-and-check-inf: 12.91 | optimizer: 24.28 | batch-generator: 11.96
 iteration        9/    1000 | consumed samples:         4608 | elapsed time per iteration (ms): 7791.7 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 16777216.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2150.33 | backward-compute: 5552.30 | backward-params-all-reduce: 57.85 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 12.87 | optimizer: 24.27 | batch-generator: 12.06
 iteration       10/    1000 | consumed samples:         5120 | elapsed time per iteration (ms): 7789.5 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 8388608.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2150.97 | backward-compute: 5553.14 | backward-params-all-reduce: 54.42 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 12.66 | optimizer: 24.06 | batch-generator: 12.24
----------------------------------------------------------------------------------------------
 validation loss at iteration 10 | lm loss value: 1.133043E+01 | lm loss PPL: 8.331916E+04 | 
----------------------------------------------------------------------------------------------
 iteration       11/    1000 | consumed samples:         5632 | elapsed time per iteration (ms): 25935.3 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 4194304.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 20280.89 | backward-compute: 5555.02 | backward-params-all-reduce: 55.33 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.28 | optimizer-unscale-and-check-inf: 12.50 | optimizer: 23.90 | batch-generator: 107.87
 iteration       12/    1000 | consumed samples:         6144 | elapsed time per iteration (ms): 7810.7 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 2097152.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2163.64 | backward-compute: 5561.17 | backward-params-all-reduce: 55.42 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.31 | optimizer-unscale-and-check-inf: 12.17 | optimizer: 23.58 | batch-generator: 12.16
 iteration       13/    1000 | consumed samples:         6656 | elapsed time per iteration (ms): 7803.0 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 1048576.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2163.56 | backward-compute: 5554.38 | backward-params-all-reduce: 54.99 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.28 | optimizer-unscale-and-check-inf: 11.77 | optimizer: 23.14 | batch-generator: 11.81
 iteration       14/    1000 | consumed samples:         7168 | elapsed time per iteration (ms): 7795.3 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 524288.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2153.99 | backward-compute: 5556.98 | backward-params-all-reduce: 54.30 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.26 | optimizer-unscale-and-check-inf: 11.74 | optimizer: 23.10 | batch-generator: 12.01
 iteration       15/    1000 | consumed samples:         7680 | elapsed time per iteration (ms): 7792.2 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 262144.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2151.31 | backward-compute: 5555.52 | backward-params-all-reduce: 55.28 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 11.74 | optimizer: 23.13 | batch-generator: 11.88
 iteration       16/    1000 | consumed samples:         8192 | elapsed time per iteration (ms): 7787.0 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 131072.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2151.24 | backward-compute: 5550.83 | backward-params-all-reduce: 55.03 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 11.74 | optimizer: 23.12 | batch-generator: 11.81
 iteration       17/    1000 | consumed samples:         8704 | elapsed time per iteration (ms): 7783.8 | learning rate: 0.000E+00 | global batch size:   512 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
time (ms) | forward-compute: 2147.94 | backward-compute: 5550.82 | backward-params-all-reduce: 54.73 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.32 | optimizer-unscale-and-check-inf: 11.74 | optimizer: 23.17 | batch-generator: 12.27
 iteration       18/    1000 | consumed samples:         9216 | elapsed time per iteration (ms): 9842.6 | learning rate: 4.687E-05 | global batch size:   512 | lm loss: 1.129834E+01 | loss scale: 65536.0 | grad norm: 199.059 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2146.73 | backward-compute: 5548.51 | backward-params-all-reduce: 55.22 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.27 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 18.90 | optimizer-copy-main-to-model-params: 13.97 | optimizer: 2085.03 | batch-generator: 12.39
[Rank 0] (after 18 iterations) memory (MB) | allocated: 30147.1552734375 | max allocated: 30147.16357421875 | reserved: 30508.0 | max reserved: 30508.0
 iteration       19/    1000 | consumed samples:         9728 | elapsed time per iteration (ms): 7891.7 | learning rate: 9.375E-05 | global batch size:   512 | lm loss: 1.129910E+01 | loss scale: 65536.0 | grad norm: 199.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2162.75 | backward-compute: 5541.76 | backward-params-all-reduce: 88.96 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 18.72 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 89.97 | batch-generator: 12.22
 iteration       20/    1000 | consumed samples:        10240 | elapsed time per iteration (ms): 7803.8 | learning rate: 1.406E-04 | global batch size:   512 | lm loss: 4.272350E+00 | loss scale: 65536.0 | grad norm: 49.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2126.88 | backward-compute: 5526.04 | backward-params-all-reduce: 53.44 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.28 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 18.84 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 90.29 | batch-generator: 12.25
----------------------------------------------------------------------------------------------
 validation loss at iteration 20 | lm loss value: 7.295216E+00 | lm loss PPL: 1.473235E+03 | 
----------------------------------------------------------------------------------------------
 iteration       21/    1000 | consumed samples:        10752 | elapsed time per iteration (ms): 25653.9 | learning rate: 1.500E-04 | global batch size:   512 | lm loss: 7.279854E+00 | loss scale: 65536.0 | grad norm: 35.743 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 19969.22 | backward-compute: 5521.10 | backward-params-all-reduce: 54.18 | backward-embedding-all-reduce: 0.04 | optimizer-copy-to-main-grad: 11.30 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 18.77 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 90.16 | batch-generator: 107.91
 iteration       22/    1000 | consumed samples:        11264 | elapsed time per iteration (ms): 7778.0 | learning rate: 1.500E-04 | global batch size:   512 | lm loss: 4.498240E+00 | loss scale: 65536.0 | grad norm: 9.547 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.79 | backward-compute: 5507.84 | backward-params-all-reduce: 52.86 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 18.76 | optimizer-copy-main-to-model-params: 11.82 | optimizer: 90.28 | batch-generator: 12.23
 iteration       23/    1000 | consumed samples:        11776 | elapsed time per iteration (ms): 7771.0 | learning rate: 1.500E-04 | global batch size:   512 | lm loss: 3.477098E+00 | loss scale: 65536.0 | grad norm: 9.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.32 | backward-compute: 5509.77 | backward-params-all-reduce: 53.54 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 18.74 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 90.09 | batch-generator: 12.07
 iteration       24/    1000 | consumed samples:        12288 | elapsed time per iteration (ms): 7781.6 | learning rate: 1.500E-04 | global batch size:   512 | lm loss: 2.863734E+00 | loss scale: 65536.0 | grad norm: 13.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.86 | backward-compute: 5515.50 | backward-params-all-reduce: 53.77 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 18.81 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 90.25 | batch-generator: 12.16
 iteration       25/    1000 | consumed samples:        12800 | elapsed time per iteration (ms): 7795.2 | learning rate: 1.499E-04 | global batch size:   512 | lm loss: 2.002452E+01 | loss scale: 65536.0 | grad norm: 15.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2124.41 | backward-compute: 5519.69 | backward-params-all-reduce: 53.69 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.28 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 18.82 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 90.21 | batch-generator: 12.20
 iteration       26/    1000 | consumed samples:        13312 | elapsed time per iteration (ms): 7790.5 | learning rate: 1.499E-04 | global batch size:   512 | lm loss: 2.351950E+00 | loss scale: 65536.0 | grad norm: 6.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.72 | backward-compute: 5517.33 | backward-params-all-reduce: 54.25 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.30 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 18.77 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 90.11 | batch-generator: 12.06
 iteration       27/    1000 | consumed samples:        13824 | elapsed time per iteration (ms): 7799.5 | learning rate: 1.498E-04 | global batch size:   512 | lm loss: 1.809906E+00 | loss scale: 65536.0 | grad norm: 5.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2124.23 | backward-compute: 5524.11 | backward-params-all-reduce: 53.78 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.28 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 18.83 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 90.19 | batch-generator: 12.09
 iteration       28/    1000 | consumed samples:        14336 | elapsed time per iteration (ms): 7811.9 | learning rate: 1.498E-04 | global batch size:   512 | lm loss: 1.432230E+00 | loss scale: 65536.0 | grad norm: 8.233 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2132.10 | backward-compute: 5528.74 | backward-params-all-reduce: 53.83 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.31 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 18.76 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 90.12 | batch-generator: 12.16
 iteration       29/    1000 | consumed samples:        14848 | elapsed time per iteration (ms): 7819.7 | learning rate: 1.497E-04 | global batch size:   512 | lm loss: 1.286670E+00 | loss scale: 65536.0 | grad norm: 10.569 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2137.99 | backward-compute: 5530.68 | backward-params-all-reduce: 53.58 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.27 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 18.77 | optimizer-copy-main-to-model-params: 11.80 | optimizer: 90.22 | batch-generator: 11.90
 iteration       30/    1000 | consumed samples:        15360 | elapsed time per iteration (ms): 7828.1 | learning rate: 1.497E-04 | global batch size:   512 | lm loss: 5.545135E-01 | loss scale: 65536.0 | grad norm: 5.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2145.66 | backward-compute: 5531.44 | backward-params-all-reduce: 53.83 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.28 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 18.74 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 90.04 | batch-generator: 12.06
----------------------------------------------------------------------------------------------
 validation loss at iteration 30 | lm loss value: 2.688705E+00 | lm loss PPL: 1.471261E+01 | 
----------------------------------------------------------------------------------------------
 iteration       31/    1000 | consumed samples:        15872 | elapsed time per iteration (ms): 26022.9 | learning rate: 1.496E-04 | global batch size:   512 | lm loss: 2.848366E+00 | loss scale: 65536.0 | grad norm: 39.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20311.01 | backward-compute: 5547.83 | backward-params-all-reduce: 54.64 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.27 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 18.73 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 90.12 | batch-generator: 107.15
 iteration       32/    1000 | consumed samples:        16384 | elapsed time per iteration (ms): 7837.7 | learning rate: 1.495E-04 | global batch size:   512 | lm loss: 6.985775E-01 | loss scale: 65536.0 | grad norm: 8.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2156.42 | backward-compute: 5528.84 | backward-params-all-reduce: 54.99 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.28 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 18.81 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 90.21 | batch-generator: 12.04
 iteration       33/    1000 | consumed samples:        16896 | elapsed time per iteration (ms): 7831.4 | learning rate: 1.494E-04 | global batch size:   512 | lm loss: 4.180769E-01 | loss scale: 65536.0 | grad norm: 5.817 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2153.04 | backward-compute: 5526.56 | backward-params-all-reduce: 54.25 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 18.74 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 90.14 | batch-generator: 11.88
 iteration       34/    1000 | consumed samples:        17408 | elapsed time per iteration (ms): 7807.3 | learning rate: 1.493E-04 | global batch size:   512 | lm loss: 2.005866E-01 | loss scale: 65536.0 | grad norm: 3.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2138.14 | backward-compute: 5517.84 | backward-params-all-reduce: 53.52 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 11.86 | optimizer-clip-main-grad: 18.80 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 90.26 | batch-generator: 12.37
 iteration       35/    1000 | consumed samples:        17920 | elapsed time per iteration (ms): 7809.7 | learning rate: 1.492E-04 | global batch size:   512 | lm loss: 2.856708E-01 | loss scale: 65536.0 | grad norm: 9.187 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2137.98 | backward-compute: 5520.82 | backward-params-all-reduce: 53.52 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.28 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 18.73 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 90.16 | batch-generator: 11.99
 iteration       36/    1000 | consumed samples:        18432 | elapsed time per iteration (ms): 7804.2 | learning rate: 1.491E-04 | global batch size:   512 | lm loss: 1.109529E+00 | loss scale: 65536.0 | grad norm: 16.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2129.21 | backward-compute: 5522.55 | backward-params-all-reduce: 55.06 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.28 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 18.78 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 90.18 | batch-generator: 11.79
 iteration       37/    1000 | consumed samples:        18944 | elapsed time per iteration (ms): 7789.5 | learning rate: 1.490E-04 | global batch size:   512 | lm loss: 1.698073E-01 | loss scale: 65536.0 | grad norm: 2.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2128.23 | backward-compute: 5510.00 | backward-params-all-reduce: 53.99 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 18.80 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 90.00 | batch-generator: 11.90
 iteration       38/    1000 | consumed samples:        19456 | elapsed time per iteration (ms): 7786.4 | learning rate: 1.489E-04 | global batch size:   512 | lm loss: 3.042384E-01 | loss scale: 65536.0 | grad norm: 4.554 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2124.53 | backward-compute: 5510.55 | backward-params-all-reduce: 54.07 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 18.74 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 90.08 | batch-generator: 11.97
 iteration       39/    1000 | consumed samples:        19968 | elapsed time per iteration (ms): 7823.6 | learning rate: 1.488E-04 | global batch size:   512 | lm loss: 3.063773E-01 | loss scale: 65536.0 | grad norm: 4.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2130.58 | backward-compute: 5519.10 | backward-params-all-reduce: 53.81 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.27 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 18.74 | optimizer-copy-main-to-model-params: 12.02 | optimizer: 112.74 | batch-generator: 11.96
 iteration       40/    1000 | consumed samples:        20480 | elapsed time per iteration (ms): 7837.5 | learning rate: 1.487E-04 | global batch size:   512 | lm loss: 1.504055E-01 | loss scale: 65536.0 | grad norm: 1.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2175.27 | backward-compute: 5511.87 | backward-params-all-reduce: 52.38 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 18.74 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 90.12 | batch-generator: 11.97
----------------------------------------------------------------------------------------------
 validation loss at iteration 40 | lm loss value: 1.389839E-01 | lm loss PPL: 1.149106E+00 | 
----------------------------------------------------------------------------------------------
 iteration       41/    1000 | consumed samples:        20992 | elapsed time per iteration (ms): 25856.6 | learning rate: 1.485E-04 | global batch size:   512 | lm loss: 1.407094E-01 | loss scale: 65536.0 | grad norm: 1.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20189.46 | backward-compute: 5503.05 | backward-params-all-reduce: 54.78 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 18.74 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 90.00 | batch-generator: 112.09
 iteration       42/    1000 | consumed samples:        21504 | elapsed time per iteration (ms): 7780.3 | learning rate: 1.484E-04 | global batch size:   512 | lm loss: 1.664059E-01 | loss scale: 65536.0 | grad norm: 3.117 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2129.57 | backward-compute: 5500.19 | backward-params-all-reduce: 53.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 18.83 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 90.14 | batch-generator: 11.95
 iteration       43/    1000 | consumed samples:        22016 | elapsed time per iteration (ms): 7774.5 | learning rate: 1.482E-04 | global batch size:   512 | lm loss: 1.319990E-01 | loss scale: 65536.0 | grad norm: 1.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2130.77 | backward-compute: 5492.45 | backward-params-all-reduce: 53.80 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 18.85 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 90.21 | batch-generator: 11.98
 iteration       44/    1000 | consumed samples:        22528 | elapsed time per iteration (ms): 7775.2 | learning rate: 1.481E-04 | global batch size:   512 | lm loss: 2.271162E-01 | loss scale: 65536.0 | grad norm: 4.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2122.39 | backward-compute: 5502.09 | backward-params-all-reduce: 52.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 18.71 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 90.07 | batch-generator: 12.00
 iteration       45/    1000 | consumed samples:        23040 | elapsed time per iteration (ms): 7773.7 | learning rate: 1.479E-04 | global batch size:   512 | lm loss: 2.508796E-01 | loss scale: 65536.0 | grad norm: 4.267 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2123.05 | backward-compute: 5500.15 | backward-params-all-reduce: 53.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.30 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 18.83 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 90.20 | batch-generator: 12.03
 iteration       46/    1000 | consumed samples:        23552 | elapsed time per iteration (ms): 7774.2 | learning rate: 1.477E-04 | global batch size:   512 | lm loss: 1.393337E-01 | loss scale: 65536.0 | grad norm: 2.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2124.45 | backward-compute: 5498.87 | backward-params-all-reduce: 53.75 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 18.74 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 90.00 | batch-generator: 11.91
 iteration       47/    1000 | consumed samples:        24064 | elapsed time per iteration (ms): 7776.9 | learning rate: 1.475E-04 | global batch size:   512 | lm loss: 2.200755E-01 | loss scale: 65536.0 | grad norm: 3.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2123.10 | backward-compute: 5501.29 | backward-params-all-reduce: 55.11 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 18.79 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 90.16 | batch-generator: 11.94
 iteration       48/    1000 | consumed samples:        24576 | elapsed time per iteration (ms): 7780.7 | learning rate: 1.474E-04 | global batch size:   512 | lm loss: 2.883160E-01 | loss scale: 65536.0 | grad norm: 4.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2127.11 | backward-compute: 5502.76 | backward-params-all-reduce: 53.56 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 18.81 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 90.11 | batch-generator: 11.92
 iteration       49/    1000 | consumed samples:        25088 | elapsed time per iteration (ms): 7777.2 | learning rate: 1.472E-04 | global batch size:   512 | lm loss: 2.238913E-01 | loss scale: 65536.0 | grad norm: 3.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2124.35 | backward-compute: 5502.38 | backward-params-all-reduce: 53.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 18.67 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 90.25 | batch-generator: 11.87
 iteration       50/    1000 | consumed samples:        25600 | elapsed time per iteration (ms): 7765.2 | learning rate: 1.470E-04 | global batch size:   512 | lm loss: 1.266498E-01 | loss scale: 65536.0 | grad norm: 0.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2123.75 | backward-compute: 5500.24 | backward-params-all-reduce: 53.88 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.82 | optimizer: 80.15 | batch-generator: 11.86
----------------------------------------------------------------------------------------------
 validation loss at iteration 50 | lm loss value: 2.119202E-01 | lm loss PPL: 1.236049E+00 | 
----------------------------------------------------------------------------------------------
 iteration       51/    1000 | consumed samples:        26112 | elapsed time per iteration (ms): 25855.5 | learning rate: 1.468E-04 | global batch size:   512 | lm loss: 2.132794E-01 | loss scale: 65536.0 | grad norm: 3.907 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20187.60 | backward-compute: 5505.40 | backward-params-all-reduce: 53.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.30 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 18.78 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 90.22 | batch-generator: 122.66
 iteration       52/    1000 | consumed samples:        26624 | elapsed time per iteration (ms): 7782.5 | learning rate: 1.465E-04 | global batch size:   512 | lm loss: 2.756251E-01 | loss scale: 65536.0 | grad norm: 4.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2122.35 | backward-compute: 5508.33 | backward-params-all-reduce: 54.44 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 18.74 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 90.07 | batch-generator: 12.36
 iteration       53/    1000 | consumed samples:        27136 | elapsed time per iteration (ms): 7779.3 | learning rate: 1.463E-04 | global batch size:   512 | lm loss: 2.424729E-01 | loss scale: 65536.0 | grad norm: 4.254 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2126.14 | backward-compute: 5501.75 | backward-params-all-reduce: 54.00 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 18.73 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 90.15 | batch-generator: 12.32
 iteration       54/    1000 | consumed samples:        27648 | elapsed time per iteration (ms): 7776.8 | learning rate: 1.461E-04 | global batch size:   512 | lm loss: 1.523936E-01 | loss scale: 65536.0 | grad norm: 2.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2126.90 | backward-compute: 5499.16 | backward-params-all-reduce: 53.37 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.28 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 18.77 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 90.15 | batch-generator: 12.11
 iteration       55/    1000 | consumed samples:        28160 | elapsed time per iteration (ms): 7777.8 | learning rate: 1.459E-04 | global batch size:   512 | lm loss: 1.333006E-01 | loss scale: 65536.0 | grad norm: 1.901 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2131.67 | backward-compute: 5495.79 | backward-params-all-reduce: 53.07 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.29 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 18.77 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 90.15 | batch-generator: 12.01
 iteration       56/    1000 | consumed samples:        28672 | elapsed time per iteration (ms): 7775.4 | learning rate: 1.456E-04 | global batch size:   512 | lm loss: 1.719534E-01 | loss scale: 65536.0 | grad norm: 3.280 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2128.15 | backward-compute: 5495.91 | backward-params-all-reduce: 53.95 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.71 | optimizer-clip-main-grad: 18.80 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 90.15 | batch-generator: 11.86
 iteration       57/    1000 | consumed samples:        29184 | elapsed time per iteration (ms): 7775.8 | learning rate: 1.454E-04 | global batch size:   512 | lm loss: 1.634308E-01 | loss scale: 65536.0 | grad norm: 3.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2126.85 | backward-compute: 5498.45 | backward-params-all-reduce: 53.27 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 18.78 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 90.12 | batch-generator: 12.01
 iteration       58/    1000 | consumed samples:        29696 | elapsed time per iteration (ms): 7771.4 | learning rate: 1.451E-04 | global batch size:   512 | lm loss: 1.234822E-01 | loss scale: 65536.0 | grad norm: 1.254 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2127.37 | backward-compute: 5491.35 | backward-params-all-reduce: 53.74 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 18.74 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 90.02 | batch-generator: 11.97
 iteration       59/    1000 | consumed samples:        30208 | elapsed time per iteration (ms): 7777.0 | learning rate: 1.449E-04 | global batch size:   512 | lm loss: 1.424746E-01 | loss scale: 65536.0 | grad norm: 2.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2128.49 | backward-compute: 5496.78 | backward-params-all-reduce: 54.41 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 18.76 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 90.12 | batch-generator: 12.08
 iteration       60/    1000 | consumed samples:        30720 | elapsed time per iteration (ms): 7776.3 | learning rate: 1.446E-04 | global batch size:   512 | lm loss: 1.777033E-01 | loss scale: 65536.0 | grad norm: 3.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2128.85 | backward-compute: 5494.47 | backward-params-all-reduce: 55.40 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 18.77 | optimizer-copy-main-to-model-params: 11.89 | optimizer: 90.28 | batch-generator: 11.94
----------------------------------------------------------------------------------------------
 validation loss at iteration 60 | lm loss value: 1.658260E-01 | lm loss PPL: 1.180368E+00 | 
----------------------------------------------------------------------------------------------
 iteration       61/    1000 | consumed samples:        31232 | elapsed time per iteration (ms): 25835.1 | learning rate: 1.443E-04 | global batch size:   512 | lm loss: 1.653696E-01 | loss scale: 65536.0 | grad norm: 3.173 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20179.23 | backward-compute: 5493.53 | backward-params-all-reduce: 52.46 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 18.69 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 90.02 | batch-generator: 122.74
 iteration       62/    1000 | consumed samples:        31744 | elapsed time per iteration (ms): 7736.9 | learning rate: 1.441E-04 | global batch size:   512 | lm loss: 1.261021E-01 | loss scale: 65536.0 | grad norm: 1.607 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.44 | backward-compute: 5490.89 | backward-params-all-reduce: 53.34 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 18.76 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 90.05 | batch-generator: 11.97
 iteration       63/    1000 | consumed samples:        32256 | elapsed time per iteration (ms): 7738.5 | learning rate: 1.438E-04 | global batch size:   512 | lm loss: 1.300631E-01 | loss scale: 65536.0 | grad norm: 1.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.87 | backward-compute: 5485.29 | backward-params-all-reduce: 54.10 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 18.74 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 90.10 | batch-generator: 11.89
 iteration       64/    1000 | consumed samples:        32768 | elapsed time per iteration (ms): 7738.5 | learning rate: 1.435E-04 | global batch size:   512 | lm loss: 1.563956E-01 | loss scale: 65536.0 | grad norm: 2.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.85 | backward-compute: 5484.67 | backward-params-all-reduce: 53.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 18.78 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 90.04 | batch-generator: 11.92
 iteration       65/    1000 | consumed samples:        33280 | elapsed time per iteration (ms): 7736.2 | learning rate: 1.432E-04 | global batch size:   512 | lm loss: 1.512937E-01 | loss scale: 65536.0 | grad norm: 2.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.29 | backward-compute: 5485.65 | backward-params-all-reduce: 54.04 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 18.72 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 90.01 | batch-generator: 12.09
 iteration       66/    1000 | consumed samples:        33792 | elapsed time per iteration (ms): 7730.8 | learning rate: 1.429E-04 | global batch size:   512 | lm loss: 1.221561E-01 | loss scale: 65536.0 | grad norm: 1.247 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2089.62 | backward-compute: 5489.89 | backward-params-all-reduce: 53.95 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 18.82 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 90.15 | batch-generator: 11.96
 iteration       67/    1000 | consumed samples:        34304 | elapsed time per iteration (ms): 7736.7 | learning rate: 1.426E-04 | global batch size:   512 | lm loss: 1.281762E-01 | loss scale: 65536.0 | grad norm: 1.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.53 | backward-compute: 5485.20 | backward-params-all-reduce: 54.65 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 18.74 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 89.95 | batch-generator: 11.90
 iteration       68/    1000 | consumed samples:        34816 | elapsed time per iteration (ms): 7742.7 | learning rate: 1.423E-04 | global batch size:   512 | lm loss: 1.496592E-01 | loss scale: 65536.0 | grad norm: 2.737 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.63 | backward-compute: 5483.37 | backward-params-all-reduce: 54.79 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 18.75 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 90.12 | batch-generator: 12.34
 iteration       69/    1000 | consumed samples:        35328 | elapsed time per iteration (ms): 7741.7 | learning rate: 1.420E-04 | global batch size:   512 | lm loss: 1.432120E-01 | loss scale: 65536.0 | grad norm: 2.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.76 | backward-compute: 5481.55 | backward-params-all-reduce: 53.95 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 18.72 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 90.12 | batch-generator: 12.50
 iteration       70/    1000 | consumed samples:        35840 | elapsed time per iteration (ms): 7725.5 | learning rate: 1.416E-04 | global batch size:   512 | lm loss: 1.196093E-01 | loss scale: 65536.0 | grad norm: 0.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.15 | backward-compute: 5484.62 | backward-params-all-reduce: 54.53 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.90 | batch-generator: 12.37
----------------------------------------------------------------------------------------------
 validation loss at iteration 70 | lm loss value: 1.297505E-01 | lm loss PPL: 1.138544E+00 | 
----------------------------------------------------------------------------------------------
 iteration       71/    1000 | consumed samples:        36352 | elapsed time per iteration (ms): 25730.1 | learning rate: 1.413E-04 | global batch size:   512 | lm loss: 1.295333E-01 | loss scale: 65536.0 | grad norm: 1.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20083.57 | backward-compute: 5482.47 | backward-params-all-reduce: 54.73 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 18.82 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 90.15 | batch-generator: 121.64
 iteration       72/    1000 | consumed samples:        36864 | elapsed time per iteration (ms): 7744.2 | learning rate: 1.410E-04 | global batch size:   512 | lm loss: 1.499090E-01 | loss scale: 65536.0 | grad norm: 2.730 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.40 | backward-compute: 5487.63 | backward-params-all-reduce: 54.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 18.69 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 90.11 | batch-generator: 11.98
 iteration       73/    1000 | consumed samples:        37376 | elapsed time per iteration (ms): 7748.8 | learning rate: 1.406E-04 | global batch size:   512 | lm loss: 1.439198E-01 | loss scale: 65536.0 | grad norm: 2.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.46 | backward-compute: 5489.70 | backward-params-all-reduce: 54.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 18.80 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 90.18 | batch-generator: 12.02
 iteration       74/    1000 | consumed samples:        37888 | elapsed time per iteration (ms): 7746.3 | learning rate: 1.403E-04 | global batch size:   512 | lm loss: 1.212836E-01 | loss scale: 65536.0 | grad norm: 1.177 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.83 | backward-compute: 5485.83 | backward-params-all-reduce: 54.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 18.78 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 90.08 | batch-generator: 12.27
 iteration       75/    1000 | consumed samples:        38400 | elapsed time per iteration (ms): 7741.9 | learning rate: 1.399E-04 | global batch size:   512 | lm loss: 1.244136E-01 | loss scale: 65536.0 | grad norm: 1.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.27 | backward-compute: 5484.68 | backward-params-all-reduce: 54.75 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 18.77 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 90.06 | batch-generator: 11.96
 iteration       76/    1000 | consumed samples:        38912 | elapsed time per iteration (ms): 7748.2 | learning rate: 1.396E-04 | global batch size:   512 | lm loss: 1.408839E-01 | loss scale: 65536.0 | grad norm: 2.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.21 | backward-compute: 5488.69 | backward-params-all-reduce: 54.04 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 18.75 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 90.10 | batch-generator: 11.90
 iteration       77/    1000 | consumed samples:        39424 | elapsed time per iteration (ms): 7752.9 | learning rate: 1.392E-04 | global batch size:   512 | lm loss: 1.364326E-01 | loss scale: 65536.0 | grad norm: 2.221 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.73 | backward-compute: 5491.05 | backward-params-all-reduce: 54.70 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 18.76 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 90.05 | batch-generator: 12.23
 iteration       78/    1000 | consumed samples:        39936 | elapsed time per iteration (ms): 7741.4 | learning rate: 1.388E-04 | global batch size:   512 | lm loss: 1.186763E-01 | loss scale: 65536.0 | grad norm: 0.847 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.21 | backward-compute: 5487.06 | backward-params-all-reduce: 54.66 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.08 | batch-generator: 12.01
 iteration       79/    1000 | consumed samples:        40448 | elapsed time per iteration (ms): 7755.9 | learning rate: 1.384E-04 | global batch size:   512 | lm loss: 1.244992E-01 | loss scale: 65536.0 | grad norm: 1.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.66 | backward-compute: 5487.56 | backward-params-all-reduce: 54.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 18.85 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 90.23 | batch-generator: 11.87
 iteration       80/    1000 | consumed samples:        40960 | elapsed time per iteration (ms): 7761.9 | learning rate: 1.380E-04 | global batch size:   512 | lm loss: 1.370237E-01 | loss scale: 65536.0 | grad norm: 2.237 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2122.13 | backward-compute: 5487.98 | backward-params-all-reduce: 54.45 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 18.74 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 90.09 | batch-generator: 11.84
----------------------------------------------------------------------------------------------
 validation loss at iteration 80 | lm loss value: 1.306973E-01 | lm loss PPL: 1.139623E+00 | 
----------------------------------------------------------------------------------------------
 iteration       81/    1000 | consumed samples:        41472 | elapsed time per iteration (ms): 25880.5 | learning rate: 1.377E-04 | global batch size:   512 | lm loss: 1.311396E-01 | loss scale: 65536.0 | grad norm: 1.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20225.47 | backward-compute: 5489.42 | backward-params-all-reduce: 56.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 18.78 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 90.17 | batch-generator: 121.49
 iteration       82/    1000 | consumed samples:        41984 | elapsed time per iteration (ms): 7774.7 | learning rate: 1.373E-04 | global batch size:   512 | lm loss: 1.163925E-01 | loss scale: 65536.0 | grad norm: 0.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2143.77 | backward-compute: 5488.15 | backward-params-all-reduce: 55.60 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.96 | batch-generator: 11.77
 iteration       83/    1000 | consumed samples:        42496 | elapsed time per iteration (ms): 7789.8 | learning rate: 1.369E-04 | global batch size:   512 | lm loss: 1.238562E-01 | loss scale: 65536.0 | grad norm: 1.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2146.98 | backward-compute: 5489.76 | backward-params-all-reduce: 55.73 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 18.78 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 90.13 | batch-generator: 12.01
 iteration       84/    1000 | consumed samples:        43008 | elapsed time per iteration (ms): 7790.7 | learning rate: 1.365E-04 | global batch size:   512 | lm loss: 1.301351E-01 | loss scale: 65536.0 | grad norm: 1.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2151.16 | backward-compute: 5485.43 | backward-params-all-reduce: 56.65 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 18.82 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 90.24 | batch-generator: 12.05
 iteration       85/    1000 | consumed samples:        43520 | elapsed time per iteration (ms): 7776.4 | learning rate: 1.360E-04 | global batch size:   512 | lm loss: 1.216110E-01 | loss scale: 65536.0 | grad norm: 1.226 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2134.73 | backward-compute: 5487.82 | backward-params-all-reduce: 56.50 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 18.77 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 90.24 | batch-generator: 12.01
 iteration       86/    1000 | consumed samples:        44032 | elapsed time per iteration (ms): 7758.2 | learning rate: 1.356E-04 | global batch size:   512 | lm loss: 1.169197E-01 | loss scale: 65536.0 | grad norm: 0.547 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2129.53 | backward-compute: 5486.98 | backward-params-all-reduce: 54.75 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 79.82 | batch-generator: 11.91
 iteration       87/    1000 | consumed samples:        44544 | elapsed time per iteration (ms): 7772.2 | learning rate: 1.352E-04 | global batch size:   512 | lm loss: 1.248129E-01 | loss scale: 65536.0 | grad norm: 1.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2136.19 | backward-compute: 5482.93 | backward-params-all-reduce: 55.70 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 18.77 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 90.13 | batch-generator: 12.12
 iteration       88/    1000 | consumed samples:        45056 | elapsed time per iteration (ms): 7765.8 | learning rate: 1.348E-04 | global batch size:   512 | lm loss: 1.214829E-01 | loss scale: 65536.0 | grad norm: 1.224 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2125.46 | backward-compute: 5487.64 | backward-params-all-reduce: 55.25 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 18.78 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 90.17 | batch-generator: 12.21
 iteration       89/    1000 | consumed samples:        45568 | elapsed time per iteration (ms): 7753.5 | learning rate: 1.343E-04 | global batch size:   512 | lm loss: 1.158006E-01 | loss scale: 65536.0 | grad norm: 0.118 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2125.52 | backward-compute: 5486.19 | backward-params-all-reduce: 54.44 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.07 | batch-generator: 11.97
 iteration       90/    1000 | consumed samples:        46080 | elapsed time per iteration (ms): 7766.7 | learning rate: 1.339E-04 | global batch size:   512 | lm loss: 1.213177E-01 | loss scale: 65536.0 | grad norm: 1.198 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2125.79 | backward-compute: 5489.17 | backward-params-all-reduce: 54.59 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 18.71 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 90.08 | batch-generator: 11.79
----------------------------------------------------------------------------------------------
 validation loss at iteration 90 | lm loss value: 1.201479E-01 | lm loss PPL: 1.127664E+00 | 
----------------------------------------------------------------------------------------------
 iteration       91/    1000 | consumed samples:        46592 | elapsed time per iteration (ms): 25830.3 | learning rate: 1.334E-04 | global batch size:   512 | lm loss: 1.201199E-01 | loss scale: 65536.0 | grad norm: 1.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20178.36 | backward-compute: 5488.09 | backward-params-all-reduce: 54.70 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 18.75 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 90.05 | batch-generator: 122.27
 iteration       92/    1000 | consumed samples:        47104 | elapsed time per iteration (ms): 7738.2 | learning rate: 1.330E-04 | global batch size:   512 | lm loss: 1.158159E-01 | loss scale: 65536.0 | grad norm: 0.168 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.38 | backward-compute: 5487.94 | backward-params-all-reduce: 53.85 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.93 | batch-generator: 12.14
 iteration       93/    1000 | consumed samples:        47616 | elapsed time per iteration (ms): 7751.0 | learning rate: 1.325E-04 | global batch size:   512 | lm loss: 1.204859E-01 | loss scale: 65536.0 | grad norm: 1.109 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.84 | backward-compute: 5487.44 | backward-params-all-reduce: 54.47 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 18.75 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 90.07 | batch-generator: 12.17
 iteration       94/    1000 | consumed samples:        48128 | elapsed time per iteration (ms): 7738.3 | learning rate: 1.321E-04 | global batch size:   512 | lm loss: 1.184346E-01 | loss scale: 65536.0 | grad norm: 0.844 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.31 | backward-compute: 5488.12 | backward-params-all-reduce: 54.60 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.02 | batch-generator: 12.05
 iteration       95/    1000 | consumed samples:        48640 | elapsed time per iteration (ms): 7735.5 | learning rate: 1.316E-04 | global batch size:   512 | lm loss: 1.161726E-01 | loss scale: 65536.0 | grad norm: 0.375 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.80 | backward-compute: 5488.11 | backward-params-all-reduce: 54.29 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.97 | batch-generator: 12.19
 iteration       96/    1000 | consumed samples:        49152 | elapsed time per iteration (ms): 7749.9 | learning rate: 1.311E-04 | global batch size:   512 | lm loss: 1.195251E-01 | loss scale: 65536.0 | grad norm: 1.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.24 | backward-compute: 5487.53 | backward-params-all-reduce: 53.92 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 18.80 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 90.11 | batch-generator: 12.08
 iteration       97/    1000 | consumed samples:        49664 | elapsed time per iteration (ms): 7736.3 | learning rate: 1.307E-04 | global batch size:   512 | lm loss: 1.165582E-01 | loss scale: 65536.0 | grad norm: 0.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.04 | backward-compute: 5488.86 | backward-params-all-reduce: 53.97 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.13 | batch-generator: 12.53
 iteration       98/    1000 | consumed samples:        50176 | elapsed time per iteration (ms): 7740.7 | learning rate: 1.302E-04 | global batch size:   512 | lm loss: 1.167323E-01 | loss scale: 65536.0 | grad norm: 0.536 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.30 | backward-compute: 5486.78 | backward-params-all-reduce: 55.24 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.01 | batch-generator: 12.17
 iteration       99/    1000 | consumed samples:        50688 | elapsed time per iteration (ms): 7738.6 | learning rate: 1.297E-04 | global batch size:   512 | lm loss: 1.183281E-01 | loss scale: 65536.0 | grad norm: 0.849 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.03 | backward-compute: 5487.79 | backward-params-all-reduce: 54.59 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.00 | batch-generator: 12.12
 iteration      100/    1000 | consumed samples:        51200 | elapsed time per iteration (ms): 7736.4 | learning rate: 1.292E-04 | global batch size:   512 | lm loss: 1.158419E-01 | loss scale: 65536.0 | grad norm: 0.225 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.22 | backward-compute: 5487.87 | backward-params-all-reduce: 54.09 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.00 | batch-generator: 11.87
-----------------------------------------------------------------------------------------------
 validation loss at iteration 100 | lm loss value: 1.169608E-01 | lm loss PPL: 1.124075E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      101/    1000 | consumed samples:        51712 | elapsed time per iteration (ms): 25779.5 | learning rate: 1.287E-04 | global batch size:   512 | lm loss: 1.169431E-01 | loss scale: 65536.0 | grad norm: 0.584 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20141.07 | backward-compute: 5484.63 | backward-params-all-reduce: 53.45 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.78 | optimizer-copy-main-to-model-params: 11.99 | optimizer: 81.18 | batch-generator: 121.24
 iteration      102/    1000 | consumed samples:        52224 | elapsed time per iteration (ms): 7729.7 | learning rate: 1.282E-04 | global batch size:   512 | lm loss: 1.174069E-01 | loss scale: 65536.0 | grad norm: 0.674 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.17 | backward-compute: 5481.27 | backward-params-all-reduce: 54.56 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.91 | batch-generator: 12.27
 iteration      103/    1000 | consumed samples:        52736 | elapsed time per iteration (ms): 7723.8 | learning rate: 1.277E-04 | global batch size:   512 | lm loss: 1.154604E-01 | loss scale: 65536.0 | grad norm: 0.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.60 | backward-compute: 5483.55 | backward-params-all-reduce: 54.38 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.10 | batch-generator: 12.03
 iteration      104/    1000 | consumed samples:        53248 | elapsed time per iteration (ms): 7720.9 | learning rate: 1.272E-04 | global batch size:   512 | lm loss: 1.171868E-01 | loss scale: 65536.0 | grad norm: 0.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2097.95 | backward-compute: 5480.80 | backward-params-all-reduce: 54.96 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.03 | batch-generator: 11.95
 iteration      105/    1000 | consumed samples:        53760 | elapsed time per iteration (ms): 7726.7 | learning rate: 1.267E-04 | global batch size:   512 | lm loss: 1.166878E-01 | loss scale: 65536.0 | grad norm: 0.537 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.47 | backward-compute: 5482.18 | backward-params-all-reduce: 54.48 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.16 | batch-generator: 11.90
 iteration      106/    1000 | consumed samples:        54272 | elapsed time per iteration (ms): 7726.5 | learning rate: 1.262E-04 | global batch size:   512 | lm loss: 1.157109E-01 | loss scale: 65536.0 | grad norm: 0.129 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.10 | backward-compute: 5481.75 | backward-params-all-reduce: 54.51 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.96 | batch-generator: 11.87
 iteration      107/    1000 | consumed samples:        54784 | elapsed time per iteration (ms): 7726.5 | learning rate: 1.256E-04 | global batch size:   512 | lm loss: 1.169619E-01 | loss scale: 65536.0 | grad norm: 0.612 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.51 | backward-compute: 5478.77 | backward-params-all-reduce: 54.99 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.95 | batch-generator: 11.78
 iteration      108/    1000 | consumed samples:        55296 | elapsed time per iteration (ms): 7722.1 | learning rate: 1.251E-04 | global batch size:   512 | lm loss: 1.161284E-01 | loss scale: 65536.0 | grad norm: 0.331 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.54 | backward-compute: 5481.97 | backward-params-all-reduce: 54.38 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.07 | batch-generator: 11.94
 iteration      109/    1000 | consumed samples:        55808 | elapsed time per iteration (ms): 7718.9 | learning rate: 1.246E-04 | global batch size:   512 | lm loss: 1.160383E-01 | loss scale: 65536.0 | grad norm: 0.270 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2092.93 | backward-compute: 5485.47 | backward-params-all-reduce: 53.31 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.92 | batch-generator: 12.35
 iteration      110/    1000 | consumed samples:        56320 | elapsed time per iteration (ms): 7721.3 | learning rate: 1.240E-04 | global batch size:   512 | lm loss: 1.161982E-01 | loss scale: 65536.0 | grad norm: 0.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.21 | backward-compute: 5482.74 | backward-params-all-reduce: 54.48 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.02 | batch-generator: 12.37
-----------------------------------------------------------------------------------------------
 validation loss at iteration 110 | lm loss value: 1.158487E-01 | lm loss PPL: 1.122826E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      111/    1000 | consumed samples:        56832 | elapsed time per iteration (ms): 25676.4 | learning rate: 1.235E-04 | global batch size:   512 | lm loss: 1.156973E-01 | loss scale: 65536.0 | grad norm: 0.191 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20041.50 | backward-compute: 5481.81 | backward-params-all-reduce: 54.08 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.03 | batch-generator: 122.68
 iteration      112/    1000 | consumed samples:        57344 | elapsed time per iteration (ms): 7718.0 | learning rate: 1.229E-04 | global batch size:   512 | lm loss: 1.158512E-01 | loss scale: 65536.0 | grad norm: 0.254 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.28 | backward-compute: 5481.01 | backward-params-all-reduce: 54.47 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.98 | batch-generator: 12.24
 iteration      113/    1000 | consumed samples:        57856 | elapsed time per iteration (ms): 7718.2 | learning rate: 1.224E-04 | global batch size:   512 | lm loss: 1.161198E-01 | loss scale: 65536.0 | grad norm: 0.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2091.38 | backward-compute: 5484.94 | backward-params-all-reduce: 54.31 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.16 | batch-generator: 12.26
 iteration      114/    1000 | consumed samples:        58368 | elapsed time per iteration (ms): 7721.3 | learning rate: 1.218E-04 | global batch size:   512 | lm loss: 1.154794E-01 | loss scale: 65536.0 | grad norm: 0.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.90 | backward-compute: 5485.90 | backward-params-all-reduce: 54.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.08 | batch-generator: 12.16
 iteration      115/    1000 | consumed samples:        58880 | elapsed time per iteration (ms): 7714.0 | learning rate: 1.213E-04 | global batch size:   512 | lm loss: 1.159746E-01 | loss scale: 65536.0 | grad norm: 0.333 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2090.84 | backward-compute: 5481.95 | backward-params-all-reduce: 53.86 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.06 | batch-generator: 12.38
 iteration      116/    1000 | consumed samples:        59392 | elapsed time per iteration (ms): 7710.3 | learning rate: 1.207E-04 | global batch size:   512 | lm loss: 1.160831E-01 | loss scale: 65536.0 | grad norm: 0.341 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2086.13 | backward-compute: 5482.93 | backward-params-all-reduce: 53.93 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.61 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.96 | batch-generator: 12.17
 iteration      117/    1000 | consumed samples:        59904 | elapsed time per iteration (ms): 7719.0 | learning rate: 1.202E-04 | global batch size:   512 | lm loss: 1.154478E-01 | loss scale: 65536.0 | grad norm: 0.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2097.11 | backward-compute: 5480.09 | backward-params-all-reduce: 54.58 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.01 | batch-generator: 12.44
 iteration      118/    1000 | consumed samples:        60416 | elapsed time per iteration (ms): 7723.0 | learning rate: 1.196E-04 | global batch size:   512 | lm loss: 1.159098E-01 | loss scale: 65536.0 | grad norm: 0.309 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.24 | backward-compute: 5480.77 | backward-params-all-reduce: 53.79 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.77 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.01 | batch-generator: 12.32
 iteration      119/    1000 | consumed samples:        60928 | elapsed time per iteration (ms): 7721.2 | learning rate: 1.190E-04 | global batch size:   512 | lm loss: 1.156684E-01 | loss scale: 65536.0 | grad norm: 0.204 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.66 | backward-compute: 5478.76 | backward-params-all-reduce: 55.29 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.04 | batch-generator: 13.07
 iteration      120/    1000 | consumed samples:        61440 | elapsed time per iteration (ms): 7723.9 | learning rate: 1.184E-04 | global batch size:   512 | lm loss: 1.155184E-01 | loss scale: 65536.0 | grad norm: 0.116 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.09 | backward-compute: 5478.33 | backward-params-all-reduce: 54.95 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.85 | optimizer: 80.24 | batch-generator: 12.34
-----------------------------------------------------------------------------------------------
 validation loss at iteration 120 | lm loss value: 1.160190E-01 | lm loss PPL: 1.123017E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      121/    1000 | consumed samples:        61952 | elapsed time per iteration (ms): 25670.1 | learning rate: 1.178E-04 | global batch size:   512 | lm loss: 1.159795E-01 | loss scale: 65536.0 | grad norm: 0.318 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20033.92 | backward-compute: 5481.14 | backward-params-all-reduce: 54.28 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.01 | batch-generator: 108.95
 iteration      122/    1000 | consumed samples:        62464 | elapsed time per iteration (ms): 7717.7 | learning rate: 1.173E-04 | global batch size:   512 | lm loss: 1.156902E-01 | loss scale: 65536.0 | grad norm: 0.119 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2094.39 | backward-compute: 5481.27 | backward-params-all-reduce: 54.64 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.78 | optimizer-copy-main-to-model-params: 11.82 | optimizer: 80.25 | batch-generator: 12.11
 iteration      123/    1000 | consumed samples:        62976 | elapsed time per iteration (ms): 7716.9 | learning rate: 1.167E-04 | global batch size:   512 | lm loss: 1.157204E-01 | loss scale: 65536.0 | grad norm: 0.203 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.69 | backward-compute: 5478.67 | backward-params-all-reduce: 54.10 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.08 | batch-generator: 12.36
 iteration      124/    1000 | consumed samples:        63488 | elapsed time per iteration (ms): 7716.0 | learning rate: 1.161E-04 | global batch size:   512 | lm loss: 1.157576E-01 | loss scale: 65536.0 | grad norm: 0.283 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.72 | backward-compute: 5480.95 | backward-params-all-reduce: 54.01 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.08 | batch-generator: 12.30
 iteration      125/    1000 | consumed samples:        64000 | elapsed time per iteration (ms): 7720.4 | learning rate: 1.155E-04 | global batch size:   512 | lm loss: 1.153985E-01 | loss scale: 65536.0 | grad norm: 0.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2097.48 | backward-compute: 5480.76 | backward-params-all-reduce: 54.72 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.11 | batch-generator: 12.18
 iteration      126/    1000 | consumed samples:        64512 | elapsed time per iteration (ms): 7716.8 | learning rate: 1.149E-04 | global batch size:   512 | lm loss: 1.158161E-01 | loss scale: 65536.0 | grad norm: 0.276 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.35 | backward-compute: 5482.00 | backward-params-all-reduce: 54.15 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.03 | batch-generator: 12.20
 iteration      127/    1000 | consumed samples:        65024 | elapsed time per iteration (ms): 7717.8 | learning rate: 1.143E-04 | global batch size:   512 | lm loss: 1.158160E-01 | loss scale: 65536.0 | grad norm: 0.241 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2090.07 | backward-compute: 5486.17 | backward-params-all-reduce: 53.91 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.18 | batch-generator: 12.69
 iteration      128/    1000 | consumed samples:        65536 | elapsed time per iteration (ms): 7720.9 | learning rate: 1.137E-04 | global batch size:   512 | lm loss: 1.156143E-01 | loss scale: 65536.0 | grad norm: 0.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.84 | backward-compute: 5485.30 | backward-params-all-reduce: 54.40 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.08 | batch-generator: 12.39
 iteration      129/    1000 | consumed samples:        66048 | elapsed time per iteration (ms): 7719.7 | learning rate: 1.131E-04 | global batch size:   512 | lm loss: 1.158752E-01 | loss scale: 65536.0 | grad norm: 0.287 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.34 | backward-compute: 5484.20 | backward-params-all-reduce: 53.03 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.90 | batch-generator: 12.14
 iteration      130/    1000 | consumed samples:        66560 | elapsed time per iteration (ms): 7723.2 | learning rate: 1.124E-04 | global batch size:   512 | lm loss: 1.156404E-01 | loss scale: 65536.0 | grad norm: 0.157 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.26 | backward-compute: 5483.65 | backward-params-all-reduce: 54.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.61 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.05 | batch-generator: 12.10
-----------------------------------------------------------------------------------------------
 validation loss at iteration 130 | lm loss value: 1.157353E-01 | lm loss PPL: 1.122699E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      131/    1000 | consumed samples:        67072 | elapsed time per iteration (ms): 25720.5 | learning rate: 1.118E-04 | global batch size:   512 | lm loss: 1.157580E-01 | loss scale: 65536.0 | grad norm: 0.166 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20081.09 | backward-compute: 5484.91 | backward-params-all-reduce: 54.48 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.99 | optimizer-clip-main-grad: 8.98 | optimizer-copy-main-to-model-params: 11.85 | optimizer: 80.78 | batch-generator: 108.89
 iteration      132/    1000 | consumed samples:        67584 | elapsed time per iteration (ms): 7729.4 | learning rate: 1.112E-04 | global batch size:   512 | lm loss: 1.157484E-01 | loss scale: 65536.0 | grad norm: 0.223 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.73 | backward-compute: 5484.86 | backward-params-all-reduce: 54.51 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.00 | batch-generator: 12.09
 iteration      133/    1000 | consumed samples:        68096 | elapsed time per iteration (ms): 7737.6 | learning rate: 1.106E-04 | global batch size:   512 | lm loss: 1.155127E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.97 | backward-compute: 5483.39 | backward-params-all-reduce: 54.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.12 | batch-generator: 12.10
 iteration      134/    1000 | consumed samples:        68608 | elapsed time per iteration (ms): 7731.8 | learning rate: 1.100E-04 | global batch size:   512 | lm loss: 1.156084E-01 | loss scale: 65536.0 | grad norm: 0.148 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.92 | backward-compute: 5479.25 | backward-params-all-reduce: 55.24 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.12 | batch-generator: 12.15
 iteration      135/    1000 | consumed samples:        69120 | elapsed time per iteration (ms): 7737.5 | learning rate: 1.093E-04 | global batch size:   512 | lm loss: 1.155732E-01 | loss scale: 65536.0 | grad norm: 0.170 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.03 | backward-compute: 5484.32 | backward-params-all-reduce: 54.03 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.93 | batch-generator: 12.09
 iteration      136/    1000 | consumed samples:        69632 | elapsed time per iteration (ms): 7739.4 | learning rate: 1.087E-04 | global batch size:   512 | lm loss: 1.156178E-01 | loss scale: 65536.0 | grad norm: 0.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.10 | backward-compute: 5484.33 | backward-params-all-reduce: 54.84 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.90 | batch-generator: 12.24
 iteration      137/    1000 | consumed samples:        70144 | elapsed time per iteration (ms): 7742.8 | learning rate: 1.081E-04 | global batch size:   512 | lm loss: 1.154699E-01 | loss scale: 65536.0 | grad norm: 0.117 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.22 | backward-compute: 5483.23 | backward-params-all-reduce: 55.04 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.03 | batch-generator: 12.01
 iteration      138/    1000 | consumed samples:        70656 | elapsed time per iteration (ms): 7746.8 | learning rate: 1.074E-04 | global batch size:   512 | lm loss: 1.155195E-01 | loss scale: 65536.0 | grad norm: 0.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.58 | backward-compute: 5484.10 | backward-params-all-reduce: 55.13 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.85 | batch-generator: 12.01
 iteration      139/    1000 | consumed samples:        71168 | elapsed time per iteration (ms): 7748.8 | learning rate: 1.068E-04 | global batch size:   512 | lm loss: 1.156060E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.19 | backward-compute: 5486.42 | backward-params-all-reduce: 54.97 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.98 | batch-generator: 12.39
 iteration      140/    1000 | consumed samples:        71680 | elapsed time per iteration (ms): 7753.2 | learning rate: 1.061E-04 | global batch size:   512 | lm loss: 1.155876E-01 | loss scale: 65536.0 | grad norm: 0.135 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2124.26 | backward-compute: 5486.69 | backward-params-all-reduce: 54.71 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.13 | batch-generator: 12.48
-----------------------------------------------------------------------------------------------
 validation loss at iteration 140 | lm loss value: 1.156363E-01 | lm loss PPL: 1.122588E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      141/    1000 | consumed samples:        72192 | elapsed time per iteration (ms): 25924.3 | learning rate: 1.055E-04 | global batch size:   512 | lm loss: 1.155143E-01 | loss scale: 65536.0 | grad norm: 0.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20285.21 | backward-compute: 5485.04 | backward-params-all-reduce: 54.72 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.02 | batch-generator: 108.40
 iteration      142/    1000 | consumed samples:        72704 | elapsed time per iteration (ms): 7758.4 | learning rate: 1.049E-04 | global batch size:   512 | lm loss: 1.154233E-01 | loss scale: 65536.0 | grad norm: 0.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2127.27 | backward-compute: 5488.39 | backward-params-all-reduce: 55.41 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.04 | batch-generator: 11.99
 iteration      143/    1000 | consumed samples:        73216 | elapsed time per iteration (ms): 7752.8 | learning rate: 1.042E-04 | global batch size:   512 | lm loss: 1.156049E-01 | loss scale: 65536.0 | grad norm: 0.155 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2125.76 | backward-compute: 5485.04 | backward-params-all-reduce: 54.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.01 | batch-generator: 12.15
 iteration      144/    1000 | consumed samples:        73728 | elapsed time per iteration (ms): 7747.9 | learning rate: 1.035E-04 | global batch size:   512 | lm loss: 1.155738E-01 | loss scale: 65536.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.82 | backward-compute: 5484.18 | backward-params-all-reduce: 54.68 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.01 | batch-generator: 12.34
 iteration      145/    1000 | consumed samples:        74240 | elapsed time per iteration (ms): 7742.9 | learning rate: 1.029E-04 | global batch size:   512 | lm loss: 1.155462E-01 | loss scale: 65536.0 | grad norm: 0.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.82 | backward-compute: 5486.38 | backward-params-all-reduce: 54.50 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.94 | batch-generator: 12.25
 iteration      146/    1000 | consumed samples:        74752 | elapsed time per iteration (ms): 7749.1 | learning rate: 1.022E-04 | global batch size:   512 | lm loss: 1.155616E-01 | loss scale: 65536.0 | grad norm: 0.137 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.93 | backward-compute: 5485.71 | backward-params-all-reduce: 54.28 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.02 | batch-generator: 12.22
 iteration      147/    1000 | consumed samples:        75264 | elapsed time per iteration (ms): 7745.6 | learning rate: 1.016E-04 | global batch size:   512 | lm loss: 1.154644E-01 | loss scale: 65536.0 | grad norm: 0.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.13 | backward-compute: 5484.40 | backward-params-all-reduce: 54.69 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.05 | batch-generator: 12.62
 iteration      148/    1000 | consumed samples:        75776 | elapsed time per iteration (ms): 7747.9 | learning rate: 1.009E-04 | global batch size:   512 | lm loss: 1.155994E-01 | loss scale: 65536.0 | grad norm: 0.122 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.85 | backward-compute: 5485.54 | backward-params-all-reduce: 55.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.04 | batch-generator: 12.67
 iteration      149/    1000 | consumed samples:        76288 | elapsed time per iteration (ms): 7752.7 | learning rate: 1.003E-04 | global batch size:   512 | lm loss: 1.155592E-01 | loss scale: 65536.0 | grad norm: 0.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.52 | backward-compute: 5486.68 | backward-params-all-reduce: 61.77 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.77 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.19 | batch-generator: 12.08
 iteration      150/    1000 | consumed samples:        76800 | elapsed time per iteration (ms): 7737.4 | learning rate: 9.959E-05 | global batch size:   512 | lm loss: 1.155503E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.01 | backward-compute: 5487.21 | backward-params-all-reduce: 53.96 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.94 | batch-generator: 12.47
-----------------------------------------------------------------------------------------------
 validation loss at iteration 150 | lm loss value: 1.156158E-01 | lm loss PPL: 1.122565E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      151/    1000 | consumed samples:        77312 | elapsed time per iteration (ms): 25828.7 | learning rate: 9.892E-05 | global batch size:   512 | lm loss: 1.156238E-01 | loss scale: 65536.0 | grad norm: 0.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20188.49 | backward-compute: 5485.33 | backward-params-all-reduce: 54.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.77 | optimizer-copy-main-to-model-params: 11.89 | optimizer: 80.27 | batch-generator: 111.21
 iteration      152/    1000 | consumed samples:        77824 | elapsed time per iteration (ms): 7740.6 | learning rate: 9.825E-05 | global batch size:   512 | lm loss: 1.155673E-01 | loss scale: 65536.0 | grad norm: 0.110 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.69 | backward-compute: 5484.27 | backward-params-all-reduce: 54.20 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.00 | batch-generator: 12.84
 iteration      153/    1000 | consumed samples:        78336 | elapsed time per iteration (ms): 7739.1 | learning rate: 9.758E-05 | global batch size:   512 | lm loss: 1.153991E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.59 | backward-compute: 5486.87 | backward-params-all-reduce: 52.46 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.07 | batch-generator: 12.05
 iteration      154/    1000 | consumed samples:        78848 | elapsed time per iteration (ms): 7736.9 | learning rate: 9.691E-05 | global batch size:   512 | lm loss: 1.156187E-01 | loss scale: 65536.0 | grad norm: 0.145 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.74 | backward-compute: 5488.25 | backward-params-all-reduce: 52.64 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.96 | batch-generator: 12.51
 iteration      155/    1000 | consumed samples:        79360 | elapsed time per iteration (ms): 7735.7 | learning rate: 9.623E-05 | global batch size:   512 | lm loss: 1.156462E-01 | loss scale: 65536.0 | grad norm: 0.111 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.67 | backward-compute: 5486.07 | backward-params-all-reduce: 52.66 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.09 | batch-generator: 12.52
 iteration      156/    1000 | consumed samples:        79872 | elapsed time per iteration (ms): 7736.5 | learning rate: 9.556E-05 | global batch size:   512 | lm loss: 1.155074E-01 | loss scale: 65536.0 | grad norm: 0.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.18 | backward-compute: 5486.38 | backward-params-all-reduce: 51.78 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.92 | batch-generator: 12.43
 iteration      157/    1000 | consumed samples:        80384 | elapsed time per iteration (ms): 7739.1 | learning rate: 9.488E-05 | global batch size:   512 | lm loss: 1.155738E-01 | loss scale: 65536.0 | grad norm: 0.146 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.10 | backward-compute: 5484.08 | backward-params-all-reduce: 52.71 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.01 | batch-generator: 12.25
 iteration      158/    1000 | consumed samples:        80896 | elapsed time per iteration (ms): 7738.0 | learning rate: 9.420E-05 | global batch size:   512 | lm loss: 1.156042E-01 | loss scale: 65536.0 | grad norm: 0.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.82 | backward-compute: 5488.00 | backward-params-all-reduce: 52.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.92 | batch-generator: 13.01
 iteration      159/    1000 | consumed samples:        81408 | elapsed time per iteration (ms): 7738.8 | learning rate: 9.352E-05 | global batch size:   512 | lm loss: 1.153880E-01 | loss scale: 65536.0 | grad norm: 0.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.37 | backward-compute: 5488.00 | backward-params-all-reduce: 53.13 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.97 | batch-generator: 12.37
 iteration      160/    1000 | consumed samples:        81920 | elapsed time per iteration (ms): 7732.3 | learning rate: 9.284E-05 | global batch size:   512 | lm loss: 1.156158E-01 | loss scale: 65536.0 | grad norm: 0.133 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.92 | backward-compute: 5490.67 | backward-params-all-reduce: 52.57 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.01 | batch-generator: 12.21
-----------------------------------------------------------------------------------------------
 validation loss at iteration 160 | lm loss value: 1.156437E-01 | lm loss PPL: 1.122596E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      161/    1000 | consumed samples:        82432 | elapsed time per iteration (ms): 25840.5 | learning rate: 9.216E-05 | global batch size:   512 | lm loss: 1.154665E-01 | loss scale: 65536.0 | grad norm: 0.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20201.06 | backward-compute: 5487.61 | backward-params-all-reduce: 52.15 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.69 | optimizer: 79.90 | batch-generator: 111.20
 iteration      162/    1000 | consumed samples:        82944 | elapsed time per iteration (ms): 7741.3 | learning rate: 9.147E-05 | global batch size:   512 | lm loss: 1.153754E-01 | loss scale: 65536.0 | grad norm: 0.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.21 | backward-compute: 5488.83 | backward-params-all-reduce: 53.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.95 | batch-generator: 12.52
 iteration      163/    1000 | consumed samples:        83456 | elapsed time per iteration (ms): 7746.1 | learning rate: 9.079E-05 | global batch size:   512 | lm loss: 1.154952E-01 | loss scale: 65536.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.61 | backward-compute: 5486.49 | backward-params-all-reduce: 52.24 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 12.56 | optimizer: 85.32 | batch-generator: 12.51
 iteration      164/    1000 | consumed samples:        83968 | elapsed time per iteration (ms): 7744.5 | learning rate: 9.010E-05 | global batch size:   512 | lm loss: 1.155975E-01 | loss scale: 65536.0 | grad norm: 0.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.63 | backward-compute: 5487.28 | backward-params-all-reduce: 51.87 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.93 | batch-generator: 12.57
 iteration      165/    1000 | consumed samples:        84480 | elapsed time per iteration (ms): 7738.2 | learning rate: 8.941E-05 | global batch size:   512 | lm loss: 1.154942E-01 | loss scale: 65536.0 | grad norm: 0.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.20 | backward-compute: 5487.45 | backward-params-all-reduce: 52.20 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.04 | batch-generator: 12.14
 iteration      166/    1000 | consumed samples:        84992 | elapsed time per iteration (ms): 7743.5 | learning rate: 8.872E-05 | global batch size:   512 | lm loss: 1.154088E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.09 | backward-compute: 5487.50 | backward-params-all-reduce: 52.78 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.92 | batch-generator: 12.33
 iteration      167/    1000 | consumed samples:        85504 | elapsed time per iteration (ms): 7737.0 | learning rate: 8.803E-05 | global batch size:   512 | lm loss: 1.156178E-01 | loss scale: 65536.0 | grad norm: 0.037 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.38 | backward-compute: 5489.27 | backward-params-all-reduce: 52.03 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.12 | batch-generator: 12.53
 iteration      168/    1000 | consumed samples:        86016 | elapsed time per iteration (ms): 7734.9 | learning rate: 8.734E-05 | global batch size:   512 | lm loss: 1.153790E-01 | loss scale: 65536.0 | grad norm: 0.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.29 | backward-compute: 5484.95 | backward-params-all-reduce: 52.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.95 | batch-generator: 12.47
 iteration      169/    1000 | consumed samples:        86528 | elapsed time per iteration (ms): 7736.9 | learning rate: 8.665E-05 | global batch size:   512 | lm loss: 1.154555E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.90 | backward-compute: 5484.10 | backward-params-all-reduce: 52.43 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.01 | batch-generator: 12.30
 iteration      170/    1000 | consumed samples:        87040 | elapsed time per iteration (ms): 7737.1 | learning rate: 8.596E-05 | global batch size:   512 | lm loss: 1.154288E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.01 | backward-compute: 5484.80 | backward-params-all-reduce: 53.19 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.97 | batch-generator: 12.44
-----------------------------------------------------------------------------------------------
 validation loss at iteration 170 | lm loss value: 1.156079E-01 | lm loss PPL: 1.122556E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      171/    1000 | consumed samples:        87552 | elapsed time per iteration (ms): 25838.8 | learning rate: 8.527E-05 | global batch size:   512 | lm loss: 1.154594E-01 | loss scale: 65536.0 | grad norm: 0.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20202.14 | backward-compute: 5484.08 | backward-params-all-reduce: 52.75 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.91 | batch-generator: 111.15
 iteration      172/    1000 | consumed samples:        88064 | elapsed time per iteration (ms): 7736.5 | learning rate: 8.458E-05 | global batch size:   512 | lm loss: 1.154585E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.99 | backward-compute: 5485.81 | backward-params-all-reduce: 52.37 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.05 | batch-generator: 12.05
 iteration      173/    1000 | consumed samples:        88576 | elapsed time per iteration (ms): 7736.9 | learning rate: 8.389E-05 | global batch size:   512 | lm loss: 1.155085E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.98 | backward-compute: 5484.56 | backward-params-all-reduce: 52.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.95 | batch-generator: 11.91
 iteration      174/    1000 | consumed samples:        89088 | elapsed time per iteration (ms): 7735.3 | learning rate: 8.319E-05 | global batch size:   512 | lm loss: 1.154705E-01 | loss scale: 65536.0 | grad norm: 0.047 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.84 | backward-compute: 5485.61 | backward-params-all-reduce: 52.47 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.92 | batch-generator: 12.21
 iteration      175/    1000 | consumed samples:        89600 | elapsed time per iteration (ms): 7736.7 | learning rate: 8.250E-05 | global batch size:   512 | lm loss: 1.155795E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.14 | backward-compute: 5482.96 | backward-params-all-reduce: 52.39 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.09 | batch-generator: 11.91
 iteration      176/    1000 | consumed samples:        90112 | elapsed time per iteration (ms): 7739.9 | learning rate: 8.180E-05 | global batch size:   512 | lm loss: 1.154620E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.09 | backward-compute: 5484.10 | backward-params-all-reduce: 52.45 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.04 | batch-generator: 12.03
 iteration      177/    1000 | consumed samples:        90624 | elapsed time per iteration (ms): 7736.0 | learning rate: 8.111E-05 | global batch size:   512 | lm loss: 1.155411E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.38 | backward-compute: 5485.07 | backward-params-all-reduce: 52.29 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.12 | batch-generator: 12.63
 iteration      178/    1000 | consumed samples:        91136 | elapsed time per iteration (ms): 7740.9 | learning rate: 8.042E-05 | global batch size:   512 | lm loss: 1.154620E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.41 | backward-compute: 5485.94 | backward-params-all-reduce: 53.94 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 13.09 | optimizer-clip-main-grad: 11.55 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 85.37 | batch-generator: 12.40
 iteration      179/    1000 | consumed samples:        91648 | elapsed time per iteration (ms): 7728.3 | learning rate: 7.972E-05 | global batch size:   512 | lm loss: 1.155035E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.78 | backward-compute: 5486.23 | backward-params-all-reduce: 51.96 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.01 | batch-generator: 12.31
 iteration      180/    1000 | consumed samples:        92160 | elapsed time per iteration (ms): 7734.3 | learning rate: 7.903E-05 | global batch size:   512 | lm loss: 1.154175E-01 | loss scale: 65536.0 | grad norm: 0.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.48 | backward-compute: 5484.93 | backward-params-all-reduce: 52.45 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.09 | batch-generator: 13.08
-----------------------------------------------------------------------------------------------
 validation loss at iteration 180 | lm loss value: 1.156275E-01 | lm loss PPL: 1.122578E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      181/    1000 | consumed samples:        92672 | elapsed time per iteration (ms): 25826.4 | learning rate: 7.833E-05 | global batch size:   512 | lm loss: 1.154812E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20187.88 | backward-compute: 5486.21 | backward-params-all-reduce: 52.32 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.04 | batch-generator: 109.89
 iteration      182/    1000 | consumed samples:        93184 | elapsed time per iteration (ms): 7745.5 | learning rate: 7.764E-05 | global batch size:   512 | lm loss: 1.155003E-01 | loss scale: 65536.0 | grad norm: 0.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.22 | backward-compute: 5484.79 | backward-params-all-reduce: 52.17 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.86 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.99 | batch-generator: 12.07
 iteration      183/    1000 | consumed samples:        93696 | elapsed time per iteration (ms): 7746.6 | learning rate: 7.695E-05 | global batch size:   512 | lm loss: 1.153542E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.08 | backward-compute: 5482.97 | backward-params-all-reduce: 61.03 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.12 | batch-generator: 11.82
 iteration      184/    1000 | consumed samples:        94208 | elapsed time per iteration (ms): 7743.5 | learning rate: 7.625E-05 | global batch size:   512 | lm loss: 1.155831E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.29 | backward-compute: 5482.57 | backward-params-all-reduce: 52.52 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.99 | batch-generator: 12.02
 iteration      185/    1000 | consumed samples:        94720 | elapsed time per iteration (ms): 7739.9 | learning rate: 7.556E-05 | global batch size:   512 | lm loss: 1.154328E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.97 | backward-compute: 5485.27 | backward-params-all-reduce: 52.55 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.91 | batch-generator: 12.49
 iteration      186/    1000 | consumed samples:        95232 | elapsed time per iteration (ms): 7738.1 | learning rate: 7.487E-05 | global batch size:   512 | lm loss: 1.154716E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.21 | backward-compute: 5485.28 | backward-params-all-reduce: 53.24 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.01 | batch-generator: 12.02
 iteration      187/    1000 | consumed samples:        95744 | elapsed time per iteration (ms): 7737.4 | learning rate: 7.418E-05 | global batch size:   512 | lm loss: 1.155761E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.73 | backward-compute: 5484.20 | backward-params-all-reduce: 52.37 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 79.97 | batch-generator: 12.02
 iteration      188/    1000 | consumed samples:        96256 | elapsed time per iteration (ms): 7740.0 | learning rate: 7.348E-05 | global batch size:   512 | lm loss: 1.154006E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.08 | backward-compute: 5484.49 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 79.92 | batch-generator: 12.15
 iteration      189/    1000 | consumed samples:        96768 | elapsed time per iteration (ms): 7737.1 | learning rate: 7.279E-05 | global batch size:   512 | lm loss: 1.153592E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.24 | backward-compute: 5484.72 | backward-params-all-reduce: 51.96 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.04 | batch-generator: 11.94
 iteration      190/    1000 | consumed samples:        97280 | elapsed time per iteration (ms): 7735.6 | learning rate: 7.210E-05 | global batch size:   512 | lm loss: 1.155540E-01 | loss scale: 65536.0 | grad norm: 0.057 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.51 | backward-compute: 5487.00 | backward-params-all-reduce: 51.69 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 80.29 | batch-generator: 11.97
-----------------------------------------------------------------------------------------------
 validation loss at iteration 190 | lm loss value: 1.155691E-01 | lm loss PPL: 1.122512E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      191/    1000 | consumed samples:        97792 | elapsed time per iteration (ms): 25834.5 | learning rate: 7.141E-05 | global batch size:   512 | lm loss: 1.155015E-01 | loss scale: 65536.0 | grad norm: 0.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20195.38 | backward-compute: 5486.96 | backward-params-all-reduce: 52.40 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.96 | batch-generator: 107.46
 iteration      192/    1000 | consumed samples:        98304 | elapsed time per iteration (ms): 7733.3 | learning rate: 7.073E-05 | global batch size:   512 | lm loss: 1.154867E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.08 | backward-compute: 5484.38 | backward-params-all-reduce: 52.54 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.91 | batch-generator: 12.12
 iteration      193/    1000 | consumed samples:        98816 | elapsed time per iteration (ms): 7736.3 | learning rate: 7.004E-05 | global batch size:   512 | lm loss: 1.155577E-01 | loss scale: 65536.0 | grad norm: 0.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.86 | backward-compute: 5486.17 | backward-params-all-reduce: 52.17 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.94 | batch-generator: 12.15
 iteration      194/    1000 | consumed samples:        99328 | elapsed time per iteration (ms): 7742.2 | learning rate: 6.935E-05 | global batch size:   512 | lm loss: 1.156459E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.31 | backward-compute: 5485.18 | backward-params-all-reduce: 52.57 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.83 | batch-generator: 11.75
 iteration      195/    1000 | consumed samples:        99840 | elapsed time per iteration (ms): 7735.5 | learning rate: 6.867E-05 | global batch size:   512 | lm loss: 1.154436E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.56 | backward-compute: 5483.87 | backward-params-all-reduce: 52.83 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.98 | batch-generator: 11.92
 iteration      196/    1000 | consumed samples:       100352 | elapsed time per iteration (ms): 7738.2 | learning rate: 6.798E-05 | global batch size:   512 | lm loss: 1.154386E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.89 | backward-compute: 5484.17 | backward-params-all-reduce: 53.06 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.85 | batch-generator: 12.07
 iteration      197/    1000 | consumed samples:       100864 | elapsed time per iteration (ms): 7734.3 | learning rate: 6.730E-05 | global batch size:   512 | lm loss: 1.155177E-01 | loss scale: 65536.0 | grad norm: 0.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.73 | backward-compute: 5484.69 | backward-params-all-reduce: 52.66 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.79 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.08 | batch-generator: 12.08
 iteration      198/    1000 | consumed samples:       101376 | elapsed time per iteration (ms): 7742.5 | learning rate: 6.662E-05 | global batch size:   512 | lm loss: 1.156133E-01 | loss scale: 65536.0 | grad norm: 0.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.12 | backward-compute: 5485.97 | backward-params-all-reduce: 52.40 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.88 | batch-generator: 12.03
 iteration      199/    1000 | consumed samples:       101888 | elapsed time per iteration (ms): 7741.8 | learning rate: 6.594E-05 | global batch size:   512 | lm loss: 1.154496E-01 | loss scale: 65536.0 | grad norm: 0.057 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.89 | backward-compute: 5487.30 | backward-params-all-reduce: 52.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.82 | optimizer: 80.12 | batch-generator: 11.99
 iteration      200/    1000 | consumed samples:       102400 | elapsed time per iteration (ms): 7743.9 | learning rate: 6.526E-05 | global batch size:   512 | lm loss: 1.156788E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.19 | backward-compute: 5484.77 | backward-params-all-reduce: 52.64 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.06 | batch-generator: 12.20
-----------------------------------------------------------------------------------------------
 validation loss at iteration 200 | lm loss value: 1.155933E-01 | lm loss PPL: 1.122539E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      201/    1000 | consumed samples:       102912 | elapsed time per iteration (ms): 25868.5 | learning rate: 6.458E-05 | global batch size:   512 | lm loss: 1.155448E-01 | loss scale: 65536.0 | grad norm: 0.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20232.41 | backward-compute: 5483.85 | backward-params-all-reduce: 52.84 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.14 | batch-generator: 106.60
 iteration      202/    1000 | consumed samples:       103424 | elapsed time per iteration (ms): 7737.0 | learning rate: 6.390E-05 | global batch size:   512 | lm loss: 1.155745E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.18 | backward-compute: 5487.62 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.96 | batch-generator: 11.82
 iteration      203/    1000 | consumed samples:       103936 | elapsed time per iteration (ms): 7736.9 | learning rate: 6.323E-05 | global batch size:   512 | lm loss: 1.154547E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.05 | backward-compute: 5486.55 | backward-params-all-reduce: 52.91 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.01 | batch-generator: 12.55
 iteration      204/    1000 | consumed samples:       104448 | elapsed time per iteration (ms): 7735.9 | learning rate: 6.255E-05 | global batch size:   512 | lm loss: 1.156596E-01 | loss scale: 65536.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.47 | backward-compute: 5483.57 | backward-params-all-reduce: 52.56 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.04 | batch-generator: 12.23
 iteration      205/    1000 | consumed samples:       104960 | elapsed time per iteration (ms): 7736.0 | learning rate: 6.188E-05 | global batch size:   512 | lm loss: 1.155207E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.01 | backward-compute: 5482.24 | backward-params-all-reduce: 52.62 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.85 | batch-generator: 12.02
 iteration      206/    1000 | consumed samples:       105472 | elapsed time per iteration (ms): 7737.2 | learning rate: 6.121E-05 | global batch size:   512 | lm loss: 1.155491E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.94 | backward-compute: 5483.17 | backward-params-all-reduce: 51.76 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.26 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.04 | batch-generator: 12.06
 iteration      207/    1000 | consumed samples:       105984 | elapsed time per iteration (ms): 7733.4 | learning rate: 6.055E-05 | global batch size:   512 | lm loss: 1.154321E-01 | loss scale: 65536.0 | grad norm: 0.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.12 | backward-compute: 5485.50 | backward-params-all-reduce: 52.55 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.02 | batch-generator: 12.02
 iteration      208/    1000 | consumed samples:       106496 | elapsed time per iteration (ms): 7737.9 | learning rate: 5.988E-05 | global batch size:   512 | lm loss: 1.154617E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.34 | backward-compute: 5484.72 | backward-params-all-reduce: 52.65 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.94 | batch-generator: 11.92
 iteration      209/    1000 | consumed samples:       107008 | elapsed time per iteration (ms): 7727.8 | learning rate: 5.922E-05 | global batch size:   512 | lm loss: 1.155861E-01 | loss scale: 65536.0 | grad norm: 0.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.30 | backward-compute: 5485.08 | backward-params-all-reduce: 53.28 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.96 | batch-generator: 12.13
 iteration      210/    1000 | consumed samples:       107520 | elapsed time per iteration (ms): 7720.3 | learning rate: 5.855E-05 | global batch size:   512 | lm loss: 1.156105E-01 | loss scale: 65536.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.15 | backward-compute: 5484.84 | backward-params-all-reduce: 52.15 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.92 | batch-generator: 11.91
-----------------------------------------------------------------------------------------------
 validation loss at iteration 210 | lm loss value: 1.155648E-01 | lm loss PPL: 1.122507E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      211/    1000 | consumed samples:       108032 | elapsed time per iteration (ms): 25691.9 | learning rate: 5.789E-05 | global batch size:   512 | lm loss: 1.156204E-01 | loss scale: 65536.0 | grad norm: 0.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20058.52 | backward-compute: 5482.58 | backward-params-all-reduce: 51.73 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.92 | batch-generator: 105.33
 iteration      212/    1000 | consumed samples:       108544 | elapsed time per iteration (ms): 7717.5 | learning rate: 5.724E-05 | global batch size:   512 | lm loss: 1.154420E-01 | loss scale: 65536.0 | grad norm: 0.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2094.90 | backward-compute: 5483.87 | backward-params-all-reduce: 51.64 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.98 | batch-generator: 11.94
 iteration      213/    1000 | consumed samples:       109056 | elapsed time per iteration (ms): 7715.3 | learning rate: 5.658E-05 | global batch size:   512 | lm loss: 1.155147E-01 | loss scale: 65536.0 | grad norm: 0.057 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2094.48 | backward-compute: 5481.67 | backward-params-all-reduce: 51.93 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.84 | batch-generator: 11.99
 iteration      214/    1000 | consumed samples:       109568 | elapsed time per iteration (ms): 7718.3 | learning rate: 5.593E-05 | global batch size:   512 | lm loss: 1.155066E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.99 | backward-compute: 5480.23 | backward-params-all-reduce: 51.88 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.98 | batch-generator: 11.90
 iteration      215/    1000 | consumed samples:       110080 | elapsed time per iteration (ms): 7718.4 | learning rate: 5.528E-05 | global batch size:   512 | lm loss: 1.154419E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2097.23 | backward-compute: 5481.82 | backward-params-all-reduce: 52.31 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 79.97 | batch-generator: 12.13
 iteration      216/    1000 | consumed samples:       110592 | elapsed time per iteration (ms): 7712.8 | learning rate: 5.463E-05 | global batch size:   512 | lm loss: 1.155486E-01 | loss scale: 65536.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2089.15 | backward-compute: 5484.08 | backward-params-all-reduce: 52.36 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.02 | batch-generator: 12.23
 iteration      217/    1000 | consumed samples:       111104 | elapsed time per iteration (ms): 7713.4 | learning rate: 5.398E-05 | global batch size:   512 | lm loss: 1.156058E-01 | loss scale: 65536.0 | grad norm: 0.054 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2091.47 | backward-compute: 5482.51 | backward-params-all-reduce: 52.13 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.05 | batch-generator: 12.00
 iteration      218/    1000 | consumed samples:       111616 | elapsed time per iteration (ms): 7717.1 | learning rate: 5.334E-05 | global batch size:   512 | lm loss: 1.155238E-01 | loss scale: 65536.0 | grad norm: 0.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2097.72 | backward-compute: 5480.24 | backward-params-all-reduce: 52.18 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.61 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.84 | batch-generator: 11.83
 iteration      219/    1000 | consumed samples:       112128 | elapsed time per iteration (ms): 7716.9 | learning rate: 5.270E-05 | global batch size:   512 | lm loss: 1.154620E-01 | loss scale: 65536.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.66 | backward-compute: 5481.41 | backward-params-all-reduce: 51.71 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.90 | batch-generator: 11.91
 iteration      220/    1000 | consumed samples:       112640 | elapsed time per iteration (ms): 7714.0 | learning rate: 5.206E-05 | global batch size:   512 | lm loss: 1.154619E-01 | loss scale: 65536.0 | grad norm: 0.050 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.24 | backward-compute: 5481.04 | backward-params-all-reduce: 52.42 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.03 | batch-generator: 12.09
-----------------------------------------------------------------------------------------------
 validation loss at iteration 220 | lm loss value: 1.155821E-01 | lm loss PPL: 1.122527E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      221/    1000 | consumed samples:       113152 | elapsed time per iteration (ms): 25692.6 | learning rate: 5.143E-05 | global batch size:   512 | lm loss: 1.153199E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20055.60 | backward-compute: 5486.19 | backward-params-all-reduce: 51.75 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.94 | batch-generator: 105.20
 iteration      222/    1000 | consumed samples:       113664 | elapsed time per iteration (ms): 7718.1 | learning rate: 5.079E-05 | global batch size:   512 | lm loss: 1.155243E-01 | loss scale: 65536.0 | grad norm: 0.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.62 | backward-compute: 5484.95 | backward-params-all-reduce: 52.43 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.80 | batch-generator: 11.81
 iteration      223/    1000 | consumed samples:       114176 | elapsed time per iteration (ms): 7722.9 | learning rate: 5.017E-05 | global batch size:   512 | lm loss: 1.155069E-01 | loss scale: 65536.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.74 | backward-compute: 5483.60 | backward-params-all-reduce: 52.51 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 80.00 | batch-generator: 12.13
 iteration      224/    1000 | consumed samples:       114688 | elapsed time per iteration (ms): 7724.0 | learning rate: 4.954E-05 | global batch size:   512 | lm loss: 1.155097E-01 | loss scale: 65536.0 | grad norm: 0.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.57 | backward-compute: 5483.83 | backward-params-all-reduce: 52.37 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.05 | batch-generator: 11.90
 iteration      225/    1000 | consumed samples:       115200 | elapsed time per iteration (ms): 7730.2 | learning rate: 4.892E-05 | global batch size:   512 | lm loss: 1.156096E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.60 | backward-compute: 5483.39 | backward-params-all-reduce: 52.81 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.96 | optimizer: 81.09 | batch-generator: 12.16
 iteration      226/    1000 | consumed samples:       115712 | elapsed time per iteration (ms): 7730.7 | learning rate: 4.829E-05 | global batch size:   512 | lm loss: 1.155586E-01 | loss scale: 65536.0 | grad norm: 0.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.62 | backward-compute: 5485.57 | backward-params-all-reduce: 52.76 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.10 | batch-generator: 12.42
 iteration      227/    1000 | consumed samples:       116224 | elapsed time per iteration (ms): 7735.9 | learning rate: 4.768E-05 | global batch size:   512 | lm loss: 1.156033E-01 | loss scale: 65536.0 | grad norm: 0.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.86 | backward-compute: 5480.67 | backward-params-all-reduce: 53.13 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.87 | batch-generator: 12.25
 iteration      228/    1000 | consumed samples:       116736 | elapsed time per iteration (ms): 7744.9 | learning rate: 4.706E-05 | global batch size:   512 | lm loss: 1.155335E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2122.05 | backward-compute: 5481.97 | backward-params-all-reduce: 53.49 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.78 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.07 | batch-generator: 12.13
 iteration      229/    1000 | consumed samples:       117248 | elapsed time per iteration (ms): 7747.5 | learning rate: 4.645E-05 | global batch size:   512 | lm loss: 1.155026E-01 | loss scale: 65536.0 | grad norm: 0.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.14 | backward-compute: 5485.56 | backward-params-all-reduce: 53.52 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.10 | batch-generator: 11.98
 iteration      230/    1000 | consumed samples:       117760 | elapsed time per iteration (ms): 7755.1 | learning rate: 4.584E-05 | global batch size:   512 | lm loss: 1.155013E-01 | loss scale: 65536.0 | grad norm: 0.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2127.01 | backward-compute: 5487.81 | backward-params-all-reduce: 53.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.04 | batch-generator: 11.93
-----------------------------------------------------------------------------------------------
 validation loss at iteration 230 | lm loss value: 1.155950E-01 | lm loss PPL: 1.122541E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      231/    1000 | consumed samples:       118272 | elapsed time per iteration (ms): 25899.5 | learning rate: 4.524E-05 | global batch size:   512 | lm loss: 1.156440E-01 | loss scale: 65536.0 | grad norm: 0.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20258.58 | backward-compute: 5488.32 | backward-params-all-reduce: 53.42 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.01 | batch-generator: 108.02
 iteration      232/    1000 | consumed samples:       118784 | elapsed time per iteration (ms): 7751.4 | learning rate: 4.464E-05 | global batch size:   512 | lm loss: 1.154907E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.33 | backward-compute: 5489.94 | backward-params-all-reduce: 52.69 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 80.13 | batch-generator: 11.90
 iteration      233/    1000 | consumed samples:       119296 | elapsed time per iteration (ms): 7747.5 | learning rate: 4.404E-05 | global batch size:   512 | lm loss: 1.155880E-01 | loss scale: 65536.0 | grad norm: 0.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.59 | backward-compute: 5488.24 | backward-params-all-reduce: 53.54 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.87 | batch-generator: 12.06
 iteration      234/    1000 | consumed samples:       119808 | elapsed time per iteration (ms): 7750.0 | learning rate: 4.345E-05 | global batch size:   512 | lm loss: 1.154421E-01 | loss scale: 65536.0 | grad norm: 0.086 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2124.22 | backward-compute: 5485.66 | backward-params-all-reduce: 52.91 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.97 | batch-generator: 12.00
 iteration      235/    1000 | consumed samples:       120320 | elapsed time per iteration (ms): 7739.3 | learning rate: 4.286E-05 | global batch size:   512 | lm loss: 1.154803E-01 | loss scale: 65536.0 | grad norm: 0.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.34 | backward-compute: 5484.70 | backward-params-all-reduce: 53.11 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 79.94 | batch-generator: 11.88
 iteration      236/    1000 | consumed samples:       120832 | elapsed time per iteration (ms): 7738.4 | learning rate: 4.227E-05 | global batch size:   512 | lm loss: 1.154524E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.83 | backward-compute: 5484.63 | backward-params-all-reduce: 52.28 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.04 | batch-generator: 11.99
 iteration      237/    1000 | consumed samples:       121344 | elapsed time per iteration (ms): 7740.2 | learning rate: 4.169E-05 | global batch size:   512 | lm loss: 1.155613E-01 | loss scale: 65536.0 | grad norm: 0.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.46 | backward-compute: 5484.37 | backward-params-all-reduce: 52.87 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.79 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.09 | batch-generator: 12.09
 iteration      238/    1000 | consumed samples:       121856 | elapsed time per iteration (ms): 7733.4 | learning rate: 4.111E-05 | global batch size:   512 | lm loss: 1.155332E-01 | loss scale: 65536.0 | grad norm: 0.059 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.16 | backward-compute: 5490.18 | backward-params-all-reduce: 51.89 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.70 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.87 | batch-generator: 12.22
 iteration      239/    1000 | consumed samples:       122368 | elapsed time per iteration (ms): 7734.9 | learning rate: 4.053E-05 | global batch size:   512 | lm loss: 1.154924E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.42 | backward-compute: 5482.07 | backward-params-all-reduce: 51.90 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 80.23 | batch-generator: 12.20
 iteration      240/    1000 | consumed samples:       122880 | elapsed time per iteration (ms): 7727.4 | learning rate: 3.996E-05 | global batch size:   512 | lm loss: 1.155504E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.35 | backward-compute: 5482.95 | backward-params-all-reduce: 51.76 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.94 | batch-generator: 12.04
-----------------------------------------------------------------------------------------------
 validation loss at iteration 240 | lm loss value: 1.156099E-01 | lm loss PPL: 1.122558E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      241/    1000 | consumed samples:       123392 | elapsed time per iteration (ms): 25813.0 | learning rate: 3.940E-05 | global batch size:   512 | lm loss: 1.155346E-01 | loss scale: 65536.0 | grad norm: 0.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20175.08 | backward-compute: 5485.99 | backward-params-all-reduce: 52.73 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.00 | batch-generator: 107.69
 iteration      242/    1000 | consumed samples:       123904 | elapsed time per iteration (ms): 7732.4 | learning rate: 3.883E-05 | global batch size:   512 | lm loss: 1.155853E-01 | loss scale: 65536.0 | grad norm: 0.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.02 | backward-compute: 5488.11 | backward-params-all-reduce: 52.19 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 79.95 | batch-generator: 12.06
 iteration      243/    1000 | consumed samples:       124416 | elapsed time per iteration (ms): 7734.8 | learning rate: 3.827E-05 | global batch size:   512 | lm loss: 1.155646E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.82 | backward-compute: 5486.58 | backward-params-all-reduce: 52.70 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.96 | batch-generator: 12.06
 iteration      244/    1000 | consumed samples:       124928 | elapsed time per iteration (ms): 7737.9 | learning rate: 3.772E-05 | global batch size:   512 | lm loss: 1.155386E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.01 | backward-compute: 5486.62 | backward-params-all-reduce: 52.92 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.99 | batch-generator: 11.94
 iteration      245/    1000 | consumed samples:       125440 | elapsed time per iteration (ms): 7736.0 | learning rate: 3.717E-05 | global batch size:   512 | lm loss: 1.156679E-01 | loss scale: 65536.0 | grad norm: 0.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.55 | backward-compute: 5485.61 | backward-params-all-reduce: 52.74 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.92 | batch-generator: 11.99
 iteration      246/    1000 | consumed samples:       125952 | elapsed time per iteration (ms): 7736.5 | learning rate: 3.662E-05 | global batch size:   512 | lm loss: 1.154647E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.24 | backward-compute: 5486.90 | backward-params-all-reduce: 52.35 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.92 | batch-generator: 12.22
 iteration      247/    1000 | consumed samples:       126464 | elapsed time per iteration (ms): 7735.5 | learning rate: 3.608E-05 | global batch size:   512 | lm loss: 1.154477E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.94 | backward-compute: 5488.23 | backward-params-all-reduce: 52.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.99 | batch-generator: 12.21
 iteration      248/    1000 | consumed samples:       126976 | elapsed time per iteration (ms): 7741.5 | learning rate: 3.554E-05 | global batch size:   512 | lm loss: 1.154471E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.89 | backward-compute: 5486.40 | backward-params-all-reduce: 52.93 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.01 | batch-generator: 12.08
 iteration      249/    1000 | consumed samples:       127488 | elapsed time per iteration (ms): 7738.7 | learning rate: 3.500E-05 | global batch size:   512 | lm loss: 1.154168E-01 | loss scale: 65536.0 | grad norm: 0.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.30 | backward-compute: 5483.88 | backward-params-all-reduce: 52.55 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.89 | batch-generator: 11.90
 iteration      250/    1000 | consumed samples:       128000 | elapsed time per iteration (ms): 7740.5 | learning rate: 3.448E-05 | global batch size:   512 | lm loss: 1.156113E-01 | loss scale: 65536.0 | grad norm: 0.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.78 | backward-compute: 5488.85 | backward-params-all-reduce: 52.65 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.02 | batch-generator: 12.15
-----------------------------------------------------------------------------------------------
 validation loss at iteration 250 | lm loss value: 1.155503E-01 | lm loss PPL: 1.122491E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      251/    1000 | consumed samples:       128512 | elapsed time per iteration (ms): 25829.2 | learning rate: 3.395E-05 | global batch size:   512 | lm loss: 1.155033E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20188.08 | backward-compute: 5487.41 | backward-params-all-reduce: 52.98 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.98 | batch-generator: 107.01
 iteration      252/    1000 | consumed samples:       129024 | elapsed time per iteration (ms): 7741.6 | learning rate: 3.343E-05 | global batch size:   512 | lm loss: 1.155751E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.08 | backward-compute: 5487.48 | backward-params-all-reduce: 51.74 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.09 | batch-generator: 12.17
 iteration      253/    1000 | consumed samples:       129536 | elapsed time per iteration (ms): 7740.5 | learning rate: 3.291E-05 | global batch size:   512 | lm loss: 1.154558E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.31 | backward-compute: 5487.02 | backward-params-all-reduce: 52.80 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.89 | batch-generator: 11.99
 iteration      254/    1000 | consumed samples:       130048 | elapsed time per iteration (ms): 7742.9 | learning rate: 3.240E-05 | global batch size:   512 | lm loss: 1.153924E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.54 | backward-compute: 5488.28 | backward-params-all-reduce: 52.57 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.98 | batch-generator: 11.99
 iteration      255/    1000 | consumed samples:       130560 | elapsed time per iteration (ms): 7743.6 | learning rate: 3.190E-05 | global batch size:   512 | lm loss: 1.152825E-01 | loss scale: 65536.0 | grad norm: 0.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.24 | backward-compute: 5489.15 | backward-params-all-reduce: 52.76 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.21 | batch-generator: 12.03
 iteration      256/    1000 | consumed samples:       131072 | elapsed time per iteration (ms): 7740.1 | learning rate: 3.139E-05 | global batch size:   512 | lm loss: 1.155627E-01 | loss scale: 65536.0 | grad norm: 0.055 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.08 | backward-compute: 5492.11 | backward-params-all-reduce: 52.57 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.06 | batch-generator: 12.17
 iteration      257/    1000 | consumed samples:       131584 | elapsed time per iteration (ms): 7743.0 | learning rate: 3.090E-05 | global batch size:   512 | lm loss: 1.154701E-01 | loss scale: 65536.0 | grad norm: 0.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.32 | backward-compute: 5484.16 | backward-params-all-reduce: 52.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.98 | batch-generator: 11.94
 iteration      258/    1000 | consumed samples:       132096 | elapsed time per iteration (ms): 7737.2 | learning rate: 3.040E-05 | global batch size:   512 | lm loss: 1.155715E-01 | loss scale: 65536.0 | grad norm: 0.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.11 | backward-compute: 5487.40 | backward-params-all-reduce: 52.49 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.07 | batch-generator: 11.78
 iteration      259/    1000 | consumed samples:       132608 | elapsed time per iteration (ms): 7743.6 | learning rate: 2.992E-05 | global batch size:   512 | lm loss: 1.155364E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.04 | backward-compute: 5487.14 | backward-params-all-reduce: 52.17 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.02 | batch-generator: 11.86
 iteration      260/    1000 | consumed samples:       133120 | elapsed time per iteration (ms): 7739.5 | learning rate: 2.943E-05 | global batch size:   512 | lm loss: 1.154456E-01 | loss scale: 65536.0 | grad norm: 0.047 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.99 | backward-compute: 5482.33 | backward-params-all-reduce: 52.89 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.10 | batch-generator: 12.02
-----------------------------------------------------------------------------------------------
 validation loss at iteration 260 | lm loss value: 1.155758E-01 | lm loss PPL: 1.122520E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      261/    1000 | consumed samples:       133632 | elapsed time per iteration (ms): 25842.0 | learning rate: 2.896E-05 | global batch size:   512 | lm loss: 1.156102E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20204.48 | backward-compute: 5486.20 | backward-params-all-reduce: 52.34 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.94 | batch-generator: 107.25
 iteration      262/    1000 | consumed samples:       134144 | elapsed time per iteration (ms): 7740.6 | learning rate: 2.848E-05 | global batch size:   512 | lm loss: 1.155593E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.61 | backward-compute: 5486.28 | backward-params-all-reduce: 52.42 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.02 | batch-generator: 11.95
 iteration      263/    1000 | consumed samples:       134656 | elapsed time per iteration (ms): 7744.9 | learning rate: 2.802E-05 | global batch size:   512 | lm loss: 1.155381E-01 | loss scale: 65536.0 | grad norm: 0.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.60 | backward-compute: 5486.32 | backward-params-all-reduce: 52.58 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.12 | batch-generator: 11.83
 iteration      264/    1000 | consumed samples:       135168 | elapsed time per iteration (ms): 7744.9 | learning rate: 2.755E-05 | global batch size:   512 | lm loss: 1.155581E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.56 | backward-compute: 5483.85 | backward-params-all-reduce: 52.50 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.84 | batch-generator: 11.86
 iteration      265/    1000 | consumed samples:       135680 | elapsed time per iteration (ms): 7739.3 | learning rate: 2.710E-05 | global batch size:   512 | lm loss: 1.155869E-01 | loss scale: 65536.0 | grad norm: 0.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.33 | backward-compute: 5488.16 | backward-params-all-reduce: 51.77 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.09 | batch-generator: 12.09
 iteration      266/    1000 | consumed samples:       136192 | elapsed time per iteration (ms): 7743.8 | learning rate: 2.665E-05 | global batch size:   512 | lm loss: 1.156310E-01 | loss scale: 65536.0 | grad norm: 0.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.08 | backward-compute: 5491.00 | backward-params-all-reduce: 52.60 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.87 | batch-generator: 12.05
 iteration      267/    1000 | consumed samples:       136704 | elapsed time per iteration (ms): 7740.2 | learning rate: 2.620E-05 | global batch size:   512 | lm loss: 1.155925E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.05 | backward-compute: 5487.12 | backward-params-all-reduce: 52.70 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.06 | batch-generator: 12.29
 iteration      268/    1000 | consumed samples:       137216 | elapsed time per iteration (ms): 7740.1 | learning rate: 2.576E-05 | global batch size:   512 | lm loss: 1.154674E-01 | loss scale: 65536.0 | grad norm: 0.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.83 | backward-compute: 5485.59 | backward-params-all-reduce: 52.47 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.04 | batch-generator: 12.17
 iteration      269/    1000 | consumed samples:       137728 | elapsed time per iteration (ms): 7740.9 | learning rate: 2.532E-05 | global batch size:   512 | lm loss: 1.155235E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.57 | backward-compute: 5487.37 | backward-params-all-reduce: 52.64 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.11 | batch-generator: 11.87
 iteration      270/    1000 | consumed samples:       138240 | elapsed time per iteration (ms): 7743.7 | learning rate: 2.489E-05 | global batch size:   512 | lm loss: 1.155296E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.70 | backward-compute: 5491.73 | backward-params-all-reduce: 52.09 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.01 | batch-generator: 12.02
-----------------------------------------------------------------------------------------------
 validation loss at iteration 270 | lm loss value: 1.155753E-01 | lm loss PPL: 1.122519E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      271/    1000 | consumed samples:       138752 | elapsed time per iteration (ms): 25829.5 | learning rate: 2.447E-05 | global batch size:   512 | lm loss: 1.154728E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20189.87 | backward-compute: 5488.28 | backward-params-all-reduce: 52.34 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.85 | batch-generator: 107.31
 iteration      272/    1000 | consumed samples:       139264 | elapsed time per iteration (ms): 7744.0 | learning rate: 2.405E-05 | global batch size:   512 | lm loss: 1.154775E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.80 | backward-compute: 5486.62 | backward-params-all-reduce: 52.42 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.93 | batch-generator: 12.00
 iteration      273/    1000 | consumed samples:       139776 | elapsed time per iteration (ms): 7741.8 | learning rate: 2.363E-05 | global batch size:   512 | lm loss: 1.154400E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.22 | backward-compute: 5484.62 | backward-params-all-reduce: 52.59 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.09 | batch-generator: 12.03
 iteration      274/    1000 | consumed samples:       140288 | elapsed time per iteration (ms): 7743.2 | learning rate: 2.322E-05 | global batch size:   512 | lm loss: 1.154309E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.91 | backward-compute: 5486.34 | backward-params-all-reduce: 52.84 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 80.03 | batch-generator: 11.86
 iteration      275/    1000 | consumed samples:       140800 | elapsed time per iteration (ms): 7743.7 | learning rate: 2.282E-05 | global batch size:   512 | lm loss: 1.155166E-01 | loss scale: 65536.0 | grad norm: 0.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.00 | backward-compute: 5486.87 | backward-params-all-reduce: 52.57 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.97 | batch-generator: 11.83
 iteration      276/    1000 | consumed samples:       141312 | elapsed time per iteration (ms): 7743.5 | learning rate: 2.242E-05 | global batch size:   512 | lm loss: 1.155066E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.83 | backward-compute: 5491.15 | backward-params-all-reduce: 52.46 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.61 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.85 | batch-generator: 11.91
 iteration      277/    1000 | consumed samples:       141824 | elapsed time per iteration (ms): 7744.3 | learning rate: 2.203E-05 | global batch size:   512 | lm loss: 1.154697E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.61 | backward-compute: 5489.46 | backward-params-all-reduce: 52.19 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.61 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.80 | batch-generator: 11.99
 iteration      278/    1000 | consumed samples:       142336 | elapsed time per iteration (ms): 7748.8 | learning rate: 2.164E-05 | global batch size:   512 | lm loss: 1.154455E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.38 | backward-compute: 5487.55 | backward-params-all-reduce: 52.51 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.12 | batch-generator: 12.11
 iteration      279/    1000 | consumed samples:       142848 | elapsed time per iteration (ms): 7746.8 | learning rate: 2.126E-05 | global batch size:   512 | lm loss: 1.154332E-01 | loss scale: 65536.0 | grad norm: 0.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.81 | backward-compute: 5485.87 | backward-params-all-reduce: 53.00 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.95 | batch-generator: 12.09
 iteration      280/    1000 | consumed samples:       143360 | elapsed time per iteration (ms): 7745.5 | learning rate: 2.089E-05 | global batch size:   512 | lm loss: 1.154688E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.62 | backward-compute: 5485.03 | backward-params-all-reduce: 52.53 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.95 | batch-generator: 11.85
-----------------------------------------------------------------------------------------------
 validation loss at iteration 280 | lm loss value: 1.155597E-01 | lm loss PPL: 1.122501E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      281/    1000 | consumed samples:       143872 | elapsed time per iteration (ms): 25851.8 | learning rate: 2.052E-05 | global batch size:   512 | lm loss: 1.154023E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20208.41 | backward-compute: 5491.03 | backward-params-all-reduce: 53.08 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 80.02 | batch-generator: 108.21
 iteration      282/    1000 | consumed samples:       144384 | elapsed time per iteration (ms): 7744.0 | learning rate: 2.016E-05 | global batch size:   512 | lm loss: 1.154547E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.58 | backward-compute: 5484.96 | backward-params-all-reduce: 52.92 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.26 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.24 | batch-generator: 11.77
 iteration      283/    1000 | consumed samples:       144896 | elapsed time per iteration (ms): 7741.7 | learning rate: 1.980E-05 | global batch size:   512 | lm loss: 1.154840E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.68 | backward-compute: 5491.25 | backward-params-all-reduce: 52.49 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.07 | batch-generator: 12.02
 iteration      284/    1000 | consumed samples:       145408 | elapsed time per iteration (ms): 7744.3 | learning rate: 1.945E-05 | global batch size:   512 | lm loss: 1.154346E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.54 | backward-compute: 5484.37 | backward-params-all-reduce: 53.10 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.03 | batch-generator: 11.87
 iteration      285/    1000 | consumed samples:       145920 | elapsed time per iteration (ms): 7743.1 | learning rate: 1.910E-05 | global batch size:   512 | lm loss: 1.153971E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.79 | backward-compute: 5485.53 | backward-params-all-reduce: 52.62 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.93 | batch-generator: 12.44
 iteration      286/    1000 | consumed samples:       146432 | elapsed time per iteration (ms): 7751.6 | learning rate: 1.876E-05 | global batch size:   512 | lm loss: 1.154920E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.89 | backward-compute: 5483.62 | backward-params-all-reduce: 56.29 | backward-embedding-all-reduce: 0.04 | optimizer-copy-to-main-grad: 11.26 | optimizer-unscale-and-check-inf: 13.15 | optimizer-clip-main-grad: 11.52 | optimizer-copy-main-to-model-params: 11.87 | optimizer: 85.42 | batch-generator: 11.83
 iteration      287/    1000 | consumed samples:       146944 | elapsed time per iteration (ms): 7737.8 | learning rate: 1.843E-05 | global batch size:   512 | lm loss: 1.155136E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.97 | backward-compute: 5484.72 | backward-params-all-reduce: 53.25 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 12.01 | optimizer: 81.16 | batch-generator: 12.75
 iteration      288/    1000 | consumed samples:       147456 | elapsed time per iteration (ms): 7738.8 | learning rate: 1.810E-05 | global batch size:   512 | lm loss: 1.155422E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.69 | backward-compute: 5491.54 | backward-params-all-reduce: 52.53 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.08 | batch-generator: 12.70
 iteration      289/    1000 | consumed samples:       147968 | elapsed time per iteration (ms): 7740.0 | learning rate: 1.778E-05 | global batch size:   512 | lm loss: 1.154392E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.52 | backward-compute: 5487.87 | backward-params-all-reduce: 52.31 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.00 | batch-generator: 12.60
 iteration      290/    1000 | consumed samples:       148480 | elapsed time per iteration (ms): 7740.2 | learning rate: 1.747E-05 | global batch size:   512 | lm loss: 1.155471E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.27 | backward-compute: 5485.10 | backward-params-all-reduce: 52.72 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.83 | batch-generator: 11.97
-----------------------------------------------------------------------------------------------
 validation loss at iteration 290 | lm loss value: 1.155671E-01 | lm loss PPL: 1.122510E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      291/    1000 | consumed samples:       148992 | elapsed time per iteration (ms): 25829.9 | learning rate: 1.716E-05 | global batch size:   512 | lm loss: 1.153886E-01 | loss scale: 65536.0 | grad norm: 0.044 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20192.66 | backward-compute: 5485.03 | backward-params-all-reduce: 52.56 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.06 | batch-generator: 123.29
 iteration      292/    1000 | consumed samples:       149504 | elapsed time per iteration (ms): 7740.9 | learning rate: 1.685E-05 | global batch size:   512 | lm loss: 1.156001E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.13 | backward-compute: 5485.65 | backward-params-all-reduce: 52.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.10 | batch-generator: 12.05
 iteration      293/    1000 | consumed samples:       150016 | elapsed time per iteration (ms): 7743.4 | learning rate: 1.656E-05 | global batch size:   512 | lm loss: 1.155106E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.80 | backward-compute: 5486.72 | backward-params-all-reduce: 52.51 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.12 | batch-generator: 12.08
 iteration      294/    1000 | consumed samples:       150528 | elapsed time per iteration (ms): 7745.1 | learning rate: 1.627E-05 | global batch size:   512 | lm loss: 1.155588E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.23 | backward-compute: 5487.00 | backward-params-all-reduce: 52.66 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.11 | batch-generator: 12.14
 iteration      295/    1000 | consumed samples:       151040 | elapsed time per iteration (ms): 7743.3 | learning rate: 1.598E-05 | global batch size:   512 | lm loss: 1.155597E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.61 | backward-compute: 5488.42 | backward-params-all-reduce: 52.80 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.08 | batch-generator: 12.31
 iteration      296/    1000 | consumed samples:       151552 | elapsed time per iteration (ms): 7742.3 | learning rate: 1.571E-05 | global batch size:   512 | lm loss: 1.155309E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.23 | backward-compute: 5487.26 | backward-params-all-reduce: 52.73 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.95 | batch-generator: 11.96
 iteration      297/    1000 | consumed samples:       152064 | elapsed time per iteration (ms): 7739.6 | learning rate: 1.544E-05 | global batch size:   512 | lm loss: 1.154607E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.77 | backward-compute: 5490.15 | backward-params-all-reduce: 52.56 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.87 | batch-generator: 12.02
 iteration      298/    1000 | consumed samples:       152576 | elapsed time per iteration (ms): 7745.8 | learning rate: 1.517E-05 | global batch size:   512 | lm loss: 1.154011E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.74 | backward-compute: 5488.02 | backward-params-all-reduce: 52.55 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.18 | batch-generator: 12.16
 iteration      299/    1000 | consumed samples:       153088 | elapsed time per iteration (ms): 7747.5 | learning rate: 1.491E-05 | global batch size:   512 | lm loss: 1.153837E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.80 | backward-compute: 5485.33 | backward-params-all-reduce: 53.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.10 | batch-generator: 12.06
 iteration      300/    1000 | consumed samples:       153600 | elapsed time per iteration (ms): 7745.2 | learning rate: 1.466E-05 | global batch size:   512 | lm loss: 1.155397E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.74 | backward-compute: 5484.79 | backward-params-all-reduce: 52.27 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.17 | batch-generator: 12.29
-----------------------------------------------------------------------------------------------
 validation loss at iteration 300 | lm loss value: 1.155713E-01 | lm loss PPL: 1.122515E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      301/    1000 | consumed samples:       154112 | elapsed time per iteration (ms): 25863.4 | learning rate: 1.441E-05 | global batch size:   512 | lm loss: 1.154980E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20227.52 | backward-compute: 5484.25 | backward-params-all-reduce: 52.35 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.85 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 80.13 | batch-generator: 125.65
 iteration      302/    1000 | consumed samples:       154624 | elapsed time per iteration (ms): 7747.5 | learning rate: 1.417E-05 | global batch size:   512 | lm loss: 1.155198E-01 | loss scale: 65536.0 | grad norm: 0.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.04 | backward-compute: 5487.85 | backward-params-all-reduce: 52.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.08 | batch-generator: 12.10
 iteration      303/    1000 | consumed samples:       155136 | elapsed time per iteration (ms): 7745.4 | learning rate: 1.394E-05 | global batch size:   512 | lm loss: 1.154597E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.47 | backward-compute: 5490.49 | backward-params-all-reduce: 51.94 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.08 | batch-generator: 12.30
 iteration      304/    1000 | consumed samples:       155648 | elapsed time per iteration (ms): 7745.0 | learning rate: 1.371E-05 | global batch size:   512 | lm loss: 1.153486E-01 | loss scale: 65536.0 | grad norm: 0.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.76 | backward-compute: 5489.25 | backward-params-all-reduce: 52.76 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.01 | batch-generator: 11.94
 iteration      305/    1000 | consumed samples:       156160 | elapsed time per iteration (ms): 7743.3 | learning rate: 1.350E-05 | global batch size:   512 | lm loss: 1.155213E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.71 | backward-compute: 5488.85 | backward-params-all-reduce: 52.38 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.10 | batch-generator: 12.13
 iteration      306/    1000 | consumed samples:       156672 | elapsed time per iteration (ms): 7743.1 | learning rate: 1.328E-05 | global batch size:   512 | lm loss: 1.154165E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.77 | backward-compute: 5487.14 | backward-params-all-reduce: 53.09 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.88 | batch-generator: 12.27
 iteration      307/    1000 | consumed samples:       157184 | elapsed time per iteration (ms): 7745.6 | learning rate: 1.307E-05 | global batch size:   512 | lm loss: 1.154095E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.67 | backward-compute: 5485.57 | backward-params-all-reduce: 52.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.00 | batch-generator: 12.20
 iteration      308/    1000 | consumed samples:       157696 | elapsed time per iteration (ms): 7749.2 | learning rate: 1.287E-05 | global batch size:   512 | lm loss: 1.155301E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.54 | backward-compute: 5491.69 | backward-params-all-reduce: 53.62 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.08 | batch-generator: 11.97
 iteration      309/    1000 | consumed samples:       158208 | elapsed time per iteration (ms): 7746.9 | learning rate: 1.268E-05 | global batch size:   512 | lm loss: 1.155308E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.09 | backward-compute: 5493.43 | backward-params-all-reduce: 52.92 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.08 | batch-generator: 12.65
 iteration      310/    1000 | consumed samples:       158720 | elapsed time per iteration (ms): 7751.2 | learning rate: 1.249E-05 | global batch size:   512 | lm loss: 1.154868E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2125.49 | backward-compute: 5484.78 | backward-params-all-reduce: 53.50 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.08 | batch-generator: 12.32
-----------------------------------------------------------------------------------------------
 validation loss at iteration 310 | lm loss value: 1.155910E-01 | lm loss PPL: 1.122537E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      311/    1000 | consumed samples:       159232 | elapsed time per iteration (ms): 25842.7 | learning rate: 1.231E-05 | global batch size:   512 | lm loss: 1.154441E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20205.00 | backward-compute: 5485.40 | backward-params-all-reduce: 52.94 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.06 | batch-generator: 125.57
 iteration      312/    1000 | consumed samples:       159744 | elapsed time per iteration (ms): 7742.8 | learning rate: 1.214E-05 | global batch size:   512 | lm loss: 1.153547E-01 | loss scale: 65536.0 | grad norm: 0.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.12 | backward-compute: 5484.32 | backward-params-all-reduce: 53.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.98 | batch-generator: 12.15
 iteration      313/    1000 | consumed samples:       160256 | elapsed time per iteration (ms): 7747.2 | learning rate: 1.197E-05 | global batch size:   512 | lm loss: 1.154469E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2124.57 | backward-compute: 5482.35 | backward-params-all-reduce: 53.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.96 | batch-generator: 12.06
 iteration      314/    1000 | consumed samples:       160768 | elapsed time per iteration (ms): 7740.5 | learning rate: 1.181E-05 | global batch size:   512 | lm loss: 1.154274E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.08 | backward-compute: 5484.16 | backward-params-all-reduce: 53.00 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.02 | batch-generator: 11.95
 iteration      315/    1000 | consumed samples:       161280 | elapsed time per iteration (ms): 7741.9 | learning rate: 1.166E-05 | global batch size:   512 | lm loss: 1.154659E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.15 | backward-compute: 5485.60 | backward-params-all-reduce: 51.98 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.92 | batch-generator: 12.17
 iteration      316/    1000 | consumed samples:       161792 | elapsed time per iteration (ms): 7740.3 | learning rate: 1.151E-05 | global batch size:   512 | lm loss: 1.155101E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.60 | backward-compute: 5485.01 | backward-params-all-reduce: 52.43 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.02 | batch-generator: 12.31
 iteration      317/    1000 | consumed samples:       162304 | elapsed time per iteration (ms): 7746.1 | learning rate: 1.137E-05 | global batch size:   512 | lm loss: 1.155343E-01 | loss scale: 65536.0 | grad norm: 0.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.33 | backward-compute: 5485.58 | backward-params-all-reduce: 52.96 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.96 | batch-generator: 11.94
 iteration      318/    1000 | consumed samples:       162816 | elapsed time per iteration (ms): 7744.8 | learning rate: 1.124E-05 | global batch size:   512 | lm loss: 1.155234E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.97 | backward-compute: 5485.46 | backward-params-all-reduce: 52.90 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.14 | batch-generator: 12.41
 iteration      319/    1000 | consumed samples:       163328 | elapsed time per iteration (ms): 7741.6 | learning rate: 1.111E-05 | global batch size:   512 | lm loss: 1.155177E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.57 | backward-compute: 5486.39 | backward-params-all-reduce: 52.42 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.01 | batch-generator: 12.17
 iteration      320/    1000 | consumed samples:       163840 | elapsed time per iteration (ms): 7747.4 | learning rate: 1.099E-05 | global batch size:   512 | lm loss: 1.154402E-01 | loss scale: 65536.0 | grad norm: 0.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.93 | backward-compute: 5486.74 | backward-params-all-reduce: 52.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.06 | batch-generator: 12.25
-----------------------------------------------------------------------------------------------
 validation loss at iteration 320 | lm loss value: 1.155837E-01 | lm loss PPL: 1.122528E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      321/    1000 | consumed samples:       164352 | elapsed time per iteration (ms): 25834.3 | learning rate: 1.088E-05 | global batch size:   512 | lm loss: 1.154486E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20196.24 | backward-compute: 5486.30 | backward-params-all-reduce: 52.56 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.95 | batch-generator: 118.38
 iteration      322/    1000 | consumed samples:       164864 | elapsed time per iteration (ms): 7741.6 | learning rate: 1.077E-05 | global batch size:   512 | lm loss: 1.155258E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.47 | backward-compute: 5484.94 | backward-params-all-reduce: 51.98 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.93 | batch-generator: 13.85
 iteration      323/    1000 | consumed samples:       165376 | elapsed time per iteration (ms): 7743.2 | learning rate: 1.067E-05 | global batch size:   512 | lm loss: 1.154411E-01 | loss scale: 65536.0 | grad norm: 0.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.88 | backward-compute: 5484.90 | backward-params-all-reduce: 52.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.94 | batch-generator: 13.53
 iteration      324/    1000 | consumed samples:       165888 | elapsed time per iteration (ms): 7739.1 | learning rate: 1.058E-05 | global batch size:   512 | lm loss: 1.155531E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.37 | backward-compute: 5483.93 | backward-params-all-reduce: 52.73 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.82 | batch-generator: 13.68
 iteration      325/    1000 | consumed samples:       166400 | elapsed time per iteration (ms): 7742.5 | learning rate: 1.050E-05 | global batch size:   512 | lm loss: 1.154947E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.75 | backward-compute: 5486.48 | backward-params-all-reduce: 52.85 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.04 | batch-generator: 13.75
 iteration      326/    1000 | consumed samples:       166912 | elapsed time per iteration (ms): 7745.1 | learning rate: 1.042E-05 | global batch size:   512 | lm loss: 1.155424E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.15 | backward-compute: 5487.91 | backward-params-all-reduce: 52.83 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.06 | batch-generator: 13.71
 iteration      327/    1000 | consumed samples:       167424 | elapsed time per iteration (ms): 7744.3 | learning rate: 1.034E-05 | global batch size:   512 | lm loss: 1.155650E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.51 | backward-compute: 5485.67 | backward-params-all-reduce: 52.74 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.99 | batch-generator: 13.59
 iteration      328/    1000 | consumed samples:       167936 | elapsed time per iteration (ms): 7745.7 | learning rate: 1.028E-05 | global batch size:   512 | lm loss: 1.153601E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.43 | backward-compute: 5484.49 | backward-params-all-reduce: 52.63 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.94 | batch-generator: 13.60
 iteration      329/    1000 | consumed samples:       168448 | elapsed time per iteration (ms): 7751.4 | learning rate: 1.022E-05 | global batch size:   512 | lm loss: 1.154621E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2129.58 | backward-compute: 5481.46 | backward-params-all-reduce: 52.95 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.10 | batch-generator: 14.10
 iteration      330/    1000 | consumed samples:       168960 | elapsed time per iteration (ms): 7745.4 | learning rate: 1.017E-05 | global batch size:   512 | lm loss: 1.154410E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.52 | backward-compute: 5483.08 | backward-params-all-reduce: 53.17 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.08 | batch-generator: 13.71
-----------------------------------------------------------------------------------------------
 validation loss at iteration 330 | lm loss value: 1.155762E-01 | lm loss PPL: 1.122520E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      331/    1000 | consumed samples:       169472 | elapsed time per iteration (ms): 25864.6 | learning rate: 1.012E-05 | global batch size:   512 | lm loss: 1.155342E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20226.73 | backward-compute: 5485.73 | backward-params-all-reduce: 52.97 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.95 | batch-generator: 123.30
 iteration      332/    1000 | consumed samples:       169984 | elapsed time per iteration (ms): 7744.8 | learning rate: 1.009E-05 | global batch size:   512 | lm loss: 1.155742E-01 | loss scale: 65536.0 | grad norm: 0.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.10 | backward-compute: 5488.13 | backward-params-all-reduce: 53.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.95 | batch-generator: 13.91
 iteration      333/    1000 | consumed samples:       170496 | elapsed time per iteration (ms): 7750.8 | learning rate: 1.006E-05 | global batch size:   512 | lm loss: 1.155493E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2122.39 | backward-compute: 5487.64 | backward-params-all-reduce: 53.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.07 | batch-generator: 13.71
 iteration      334/    1000 | consumed samples:       171008 | elapsed time per iteration (ms): 7744.7 | learning rate: 1.003E-05 | global batch size:   512 | lm loss: 1.154000E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.83 | backward-compute: 5490.48 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.10 | batch-generator: 13.85
 iteration      335/    1000 | consumed samples:       171520 | elapsed time per iteration (ms): 7748.4 | learning rate: 1.001E-05 | global batch size:   512 | lm loss: 1.154415E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.05 | backward-compute: 5491.30 | backward-params-all-reduce: 52.61 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.08 | batch-generator: 13.64
 iteration      336/    1000 | consumed samples:       172032 | elapsed time per iteration (ms): 7748.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154472E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2124.89 | backward-compute: 5482.42 | backward-params-all-reduce: 53.39 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.03 | batch-generator: 13.72
 iteration      337/    1000 | consumed samples:       172544 | elapsed time per iteration (ms): 7746.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155401E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.04 | backward-compute: 5489.69 | backward-params-all-reduce: 52.40 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.93 | batch-generator: 13.55
 iteration      338/    1000 | consumed samples:       173056 | elapsed time per iteration (ms): 7737.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154234E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.04 | backward-compute: 5486.59 | backward-params-all-reduce: 53.17 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.10 | batch-generator: 14.39
 iteration      339/    1000 | consumed samples:       173568 | elapsed time per iteration (ms): 7736.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154903E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.27 | backward-compute: 5486.47 | backward-params-all-reduce: 52.27 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.20 | batch-generator: 14.01
 iteration      340/    1000 | consumed samples:       174080 | elapsed time per iteration (ms): 7730.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154057E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.67 | backward-compute: 5483.92 | backward-params-all-reduce: 52.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.10 | batch-generator: 13.71
-----------------------------------------------------------------------------------------------
 validation loss at iteration 340 | lm loss value: 1.155803E-01 | lm loss PPL: 1.122525E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      341/    1000 | consumed samples:       174592 | elapsed time per iteration (ms): 25835.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154511E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20200.89 | backward-compute: 5482.69 | backward-params-all-reduce: 53.03 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.85 | batch-generator: 122.99
 iteration      342/    1000 | consumed samples:       175104 | elapsed time per iteration (ms): 7734.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156034E-01 | loss scale: 65536.0 | grad norm: 0.044 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.24 | backward-compute: 5485.80 | backward-params-all-reduce: 52.24 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.98 | batch-generator: 13.62
 iteration      343/    1000 | consumed samples:       175616 | elapsed time per iteration (ms): 7736.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154506E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.51 | backward-compute: 5482.39 | backward-params-all-reduce: 52.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.79 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.19 | batch-generator: 13.58
 iteration      344/    1000 | consumed samples:       176128 | elapsed time per iteration (ms): 7738.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154339E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.74 | backward-compute: 5484.87 | backward-params-all-reduce: 52.80 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.93 | batch-generator: 13.74
 iteration      345/    1000 | consumed samples:       176640 | elapsed time per iteration (ms): 7733.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154947E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.33 | backward-compute: 5491.56 | backward-params-all-reduce: 51.90 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.94 | batch-generator: 13.74
 iteration      346/    1000 | consumed samples:       177152 | elapsed time per iteration (ms): 7725.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154313E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2094.27 | backward-compute: 5490.68 | backward-params-all-reduce: 52.61 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.14 | batch-generator: 13.65
 iteration      347/    1000 | consumed samples:       177664 | elapsed time per iteration (ms): 7716.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154320E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.46 | backward-compute: 5481.16 | backward-params-all-reduce: 52.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.95 | batch-generator: 14.48
 iteration      348/    1000 | consumed samples:       178176 | elapsed time per iteration (ms): 7718.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155519E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2090.44 | backward-compute: 5488.99 | backward-params-all-reduce: 51.63 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.81 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 80.13 | batch-generator: 14.02
 iteration      349/    1000 | consumed samples:       178688 | elapsed time per iteration (ms): 7716.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154312E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2088.36 | backward-compute: 5487.14 | backward-params-all-reduce: 52.11 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.97 | optimizer: 81.04 | batch-generator: 13.75
 iteration      350/    1000 | consumed samples:       179200 | elapsed time per iteration (ms): 7715.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155505E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2097.52 | backward-compute: 5477.10 | backward-params-all-reduce: 52.73 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.96 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.13 | batch-generator: 13.03
-----------------------------------------------------------------------------------------------
 validation loss at iteration 350 | lm loss value: 1.155688E-01 | lm loss PPL: 1.122512E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      351/    1000 | consumed samples:       179712 | elapsed time per iteration (ms): 25686.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155785E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20050.74 | backward-compute: 5484.13 | backward-params-all-reduce: 52.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.09 | batch-generator: 109.65
 iteration      352/    1000 | consumed samples:       180224 | elapsed time per iteration (ms): 7714.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154426E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2092.12 | backward-compute: 5483.42 | backward-params-all-reduce: 51.93 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.97 | batch-generator: 12.58
 iteration      353/    1000 | consumed samples:       180736 | elapsed time per iteration (ms): 7714.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155162E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.77 | backward-compute: 5480.95 | backward-params-all-reduce: 52.66 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.91 | batch-generator: 13.42
 iteration      354/    1000 | consumed samples:       181248 | elapsed time per iteration (ms): 7719.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154473E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2097.32 | backward-compute: 5481.86 | backward-params-all-reduce: 52.41 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.11 | batch-generator: 12.56
 iteration      355/    1000 | consumed samples:       181760 | elapsed time per iteration (ms): 7718.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155211E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.29 | backward-compute: 5484.26 | backward-params-all-reduce: 51.66 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.15 | batch-generator: 12.27
 iteration      356/    1000 | consumed samples:       182272 | elapsed time per iteration (ms): 7715.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155984E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2089.57 | backward-compute: 5486.20 | backward-params-all-reduce: 52.17 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.96 | batch-generator: 13.56
 iteration      357/    1000 | consumed samples:       182784 | elapsed time per iteration (ms): 7717.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155533E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2091.14 | backward-compute: 5487.32 | backward-params-all-reduce: 51.98 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.99 | batch-generator: 13.28
 iteration      358/    1000 | consumed samples:       183296 | elapsed time per iteration (ms): 7716.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155951E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2090.44 | backward-compute: 5486.72 | backward-params-all-reduce: 51.93 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.85 | optimizer: 80.15 | batch-generator: 13.68
 iteration      359/    1000 | consumed samples:       183808 | elapsed time per iteration (ms): 7720.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155098E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.36 | backward-compute: 5480.53 | backward-params-all-reduce: 52.65 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.09 | batch-generator: 12.81
 iteration      360/    1000 | consumed samples:       184320 | elapsed time per iteration (ms): 7719.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155007E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.93 | backward-compute: 5485.85 | backward-params-all-reduce: 52.03 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.92 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.34 | batch-generator: 13.41
-----------------------------------------------------------------------------------------------
 validation loss at iteration 360 | lm loss value: 1.155393E-01 | lm loss PPL: 1.122479E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      361/    1000 | consumed samples:       184832 | elapsed time per iteration (ms): 25762.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155497E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20127.07 | backward-compute: 5483.72 | backward-params-all-reduce: 52.35 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.03 | batch-generator: 109.59
 iteration      362/    1000 | consumed samples:       185344 | elapsed time per iteration (ms): 7731.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154133E-01 | loss scale: 65536.0 | grad norm: 0.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.73 | backward-compute: 5489.84 | backward-params-all-reduce: 51.98 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.86 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.19 | batch-generator: 13.37
 iteration      363/    1000 | consumed samples:       185856 | elapsed time per iteration (ms): 7729.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154473E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.91 | backward-compute: 5488.05 | backward-params-all-reduce: 52.49 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.97 | batch-generator: 13.09
 iteration      364/    1000 | consumed samples:       186368 | elapsed time per iteration (ms): 7731.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153684E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.80 | backward-compute: 5486.26 | backward-params-all-reduce: 52.44 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.77 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.04 | batch-generator: 12.57
 iteration      365/    1000 | consumed samples:       186880 | elapsed time per iteration (ms): 7746.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153532E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.06 | backward-compute: 5485.71 | backward-params-all-reduce: 52.79 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.02 | batch-generator: 12.85
 iteration      366/    1000 | consumed samples:       187392 | elapsed time per iteration (ms): 7750.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154206E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2126.77 | backward-compute: 5484.30 | backward-params-all-reduce: 52.61 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.96 | batch-generator: 12.66
 iteration      367/    1000 | consumed samples:       187904 | elapsed time per iteration (ms): 7755.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155776E-01 | loss scale: 65536.0 | grad norm: 0.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2129.99 | backward-compute: 5484.61 | backward-params-all-reduce: 53.07 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 79.96 | batch-generator: 12.72
 iteration      368/    1000 | consumed samples:       188416 | elapsed time per iteration (ms): 7757.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155008E-01 | loss scale: 65536.0 | grad norm: 0.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2129.00 | backward-compute: 5487.93 | backward-params-all-reduce: 53.22 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.06 | batch-generator: 12.56
 iteration      369/    1000 | consumed samples:       188928 | elapsed time per iteration (ms): 7753.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154431E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2125.41 | backward-compute: 5487.24 | backward-params-all-reduce: 53.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.94 | batch-generator: 12.07
 iteration      370/    1000 | consumed samples:       189440 | elapsed time per iteration (ms): 7752.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154709E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2125.61 | backward-compute: 5485.52 | backward-params-all-reduce: 52.77 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.98 | batch-generator: 11.94
-----------------------------------------------------------------------------------------------
 validation loss at iteration 370 | lm loss value: 1.155518E-01 | lm loss PPL: 1.122493E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      371/    1000 | consumed samples:       189952 | elapsed time per iteration (ms): 25828.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155270E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20189.81 | backward-compute: 5485.97 | backward-params-all-reduce: 53.31 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.94 | batch-generator: 130.83
 iteration      372/    1000 | consumed samples:       190464 | elapsed time per iteration (ms): 7730.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154231E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.00 | backward-compute: 5482.22 | backward-params-all-reduce: 52.29 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.02 | batch-generator: 11.92
 iteration      373/    1000 | consumed samples:       190976 | elapsed time per iteration (ms): 7725.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155106E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.86 | backward-compute: 5481.73 | backward-params-all-reduce: 52.11 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.94 | batch-generator: 11.87
 iteration      374/    1000 | consumed samples:       191488 | elapsed time per iteration (ms): 7723.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154613E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.16 | backward-compute: 5483.95 | backward-params-all-reduce: 52.29 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.58 | optimizer-copy-main-to-model-params: 11.88 | optimizer: 79.93 | batch-generator: 12.10
 iteration      375/    1000 | consumed samples:       192000 | elapsed time per iteration (ms): 7723.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154725E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.40 | backward-compute: 5482.05 | backward-params-all-reduce: 52.52 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.98 | batch-generator: 12.56
 iteration      376/    1000 | consumed samples:       192512 | elapsed time per iteration (ms): 7721.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154041E-01 | loss scale: 65536.0 | grad norm: 0.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2097.43 | backward-compute: 5484.59 | backward-params-all-reduce: 52.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.84 | batch-generator: 12.00
 iteration      377/    1000 | consumed samples:       193024 | elapsed time per iteration (ms): 7725.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154051E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.29 | backward-compute: 5482.35 | backward-params-all-reduce: 51.56 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.89 | optimizer: 80.21 | batch-generator: 12.07
 iteration      378/    1000 | consumed samples:       193536 | elapsed time per iteration (ms): 7721.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156494E-01 | loss scale: 65536.0 | grad norm: 0.047 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.05 | backward-compute: 5483.99 | backward-params-all-reduce: 52.30 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.89 | batch-generator: 11.98
 iteration      379/    1000 | consumed samples:       194048 | elapsed time per iteration (ms): 7727.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156200E-01 | loss scale: 65536.0 | grad norm: 0.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.80 | backward-compute: 5482.94 | backward-params-all-reduce: 52.72 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.14 | batch-generator: 11.91
 iteration      380/    1000 | consumed samples:       194560 | elapsed time per iteration (ms): 7720.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155192E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.92 | backward-compute: 5484.44 | backward-params-all-reduce: 52.01 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.96 | batch-generator: 12.01
-----------------------------------------------------------------------------------------------
 validation loss at iteration 380 | lm loss value: 1.155658E-01 | lm loss PPL: 1.122508E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      381/    1000 | consumed samples:       195072 | elapsed time per iteration (ms): 25814.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155043E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20175.67 | backward-compute: 5485.40 | backward-params-all-reduce: 52.89 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.74 | batch-generator: 121.60
 iteration      382/    1000 | consumed samples:       195584 | elapsed time per iteration (ms): 7740.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155582E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.55 | backward-compute: 5484.03 | backward-params-all-reduce: 53.03 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.97 | optimizer-clip-main-grad: 8.95 | optimizer-copy-main-to-model-params: 11.84 | optimizer: 80.63 | batch-generator: 12.08
 iteration      383/    1000 | consumed samples:       196096 | elapsed time per iteration (ms): 7744.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154554E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.53 | backward-compute: 5486.19 | backward-params-all-reduce: 52.65 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.93 | batch-generator: 11.99
 iteration      384/    1000 | consumed samples:       196608 | elapsed time per iteration (ms): 7746.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154380E-01 | loss scale: 65536.0 | grad norm: 0.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.67 | backward-compute: 5488.40 | backward-params-all-reduce: 52.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.91 | batch-generator: 12.12
 iteration      385/    1000 | consumed samples:       197120 | elapsed time per iteration (ms): 7742.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155405E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.31 | backward-compute: 5483.61 | backward-params-all-reduce: 52.03 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 79.99 | batch-generator: 11.92
 iteration      386/    1000 | consumed samples:       197632 | elapsed time per iteration (ms): 7740.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154549E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.80 | backward-compute: 5481.39 | backward-params-all-reduce: 53.11 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.90 | batch-generator: 12.06
 iteration      387/    1000 | consumed samples:       198144 | elapsed time per iteration (ms): 7742.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155657E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.70 | backward-compute: 5486.47 | backward-params-all-reduce: 52.11 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.91 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.14 | batch-generator: 11.96
 iteration      388/    1000 | consumed samples:       198656 | elapsed time per iteration (ms): 7739.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153739E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.55 | backward-compute: 5486.18 | backward-params-all-reduce: 52.77 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.02 | batch-generator: 12.27
 iteration      389/    1000 | consumed samples:       199168 | elapsed time per iteration (ms): 7735.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154569E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.97 | backward-compute: 5483.91 | backward-params-all-reduce: 52.30 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.78 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 80.23 | batch-generator: 12.18
 iteration      390/    1000 | consumed samples:       199680 | elapsed time per iteration (ms): 7742.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154833E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.08 | backward-compute: 5488.22 | backward-params-all-reduce: 53.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.02 | batch-generator: 12.11
-----------------------------------------------------------------------------------------------
 validation loss at iteration 390 | lm loss value: 1.155640E-01 | lm loss PPL: 1.122506E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      391/    1000 | consumed samples:       200192 | elapsed time per iteration (ms): 25840.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155254E-01 | loss scale: 65536.0 | grad norm: 0.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20200.46 | backward-compute: 5487.88 | backward-params-all-reduce: 52.57 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.09 | batch-generator: 108.30
 iteration      392/    1000 | consumed samples:       200704 | elapsed time per iteration (ms): 7742.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153598E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.59 | backward-compute: 5482.28 | backward-params-all-reduce: 53.32 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.01 | batch-generator: 12.21
 iteration      393/    1000 | consumed samples:       201216 | elapsed time per iteration (ms): 7744.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155597E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.40 | backward-compute: 5485.44 | backward-params-all-reduce: 53.21 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.92 | batch-generator: 12.11
 iteration      394/    1000 | consumed samples:       201728 | elapsed time per iteration (ms): 7749.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154604E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.23 | backward-compute: 5490.42 | backward-params-all-reduce: 52.39 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.84 | batch-generator: 12.01
 iteration      395/    1000 | consumed samples:       202240 | elapsed time per iteration (ms): 7743.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154894E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.42 | backward-compute: 5486.73 | backward-params-all-reduce: 52.97 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.85 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.80 | optimizer: 80.11 | batch-generator: 11.96
 iteration      396/    1000 | consumed samples:       202752 | elapsed time per iteration (ms): 7738.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155123E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.41 | backward-compute: 5484.83 | backward-params-all-reduce: 52.37 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.07 | batch-generator: 11.85
 iteration      397/    1000 | consumed samples:       203264 | elapsed time per iteration (ms): 7737.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154323E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.26 | backward-compute: 5484.20 | backward-params-all-reduce: 52.25 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.01 | batch-generator: 12.63
 iteration      398/    1000 | consumed samples:       203776 | elapsed time per iteration (ms): 7736.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154047E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.33 | backward-compute: 5483.98 | backward-params-all-reduce: 53.11 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.03 | batch-generator: 12.19
 iteration      399/    1000 | consumed samples:       204288 | elapsed time per iteration (ms): 7740.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155147E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.68 | backward-compute: 5483.50 | backward-params-all-reduce: 53.31 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 79.93 | batch-generator: 12.16
 iteration      400/    1000 | consumed samples:       204800 | elapsed time per iteration (ms): 7741.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154720E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.61 | backward-compute: 5485.41 | backward-params-all-reduce: 52.72 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.61 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.95 | batch-generator: 12.16
-----------------------------------------------------------------------------------------------
 validation loss at iteration 400 | lm loss value: 1.155517E-01 | lm loss PPL: 1.122493E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      401/    1000 | consumed samples:       205312 | elapsed time per iteration (ms): 25857.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154967E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20220.51 | backward-compute: 5484.49 | backward-params-all-reduce: 53.35 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 79.99 | batch-generator: 107.21
 iteration      402/    1000 | consumed samples:       205824 | elapsed time per iteration (ms): 7742.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154900E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.22 | backward-compute: 5487.98 | backward-params-all-reduce: 53.17 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.87 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.08 | batch-generator: 12.03
 iteration      403/    1000 | consumed samples:       206336 | elapsed time per iteration (ms): 7741.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154564E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.82 | backward-compute: 5486.44 | backward-params-all-reduce: 53.10 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.00 | batch-generator: 12.01
 iteration      404/    1000 | consumed samples:       206848 | elapsed time per iteration (ms): 7741.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155178E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.74 | backward-compute: 5486.06 | backward-params-all-reduce: 52.49 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.93 | batch-generator: 11.94
 iteration      405/    1000 | consumed samples:       207360 | elapsed time per iteration (ms): 7740.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155282E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.01 | backward-compute: 5484.11 | backward-params-all-reduce: 53.32 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.99 | batch-generator: 12.03
 iteration      406/    1000 | consumed samples:       207872 | elapsed time per iteration (ms): 7743.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155728E-01 | loss scale: 65536.0 | grad norm: 0.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.61 | backward-compute: 5485.84 | backward-params-all-reduce: 53.48 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.92 | batch-generator: 11.90
 iteration      407/    1000 | consumed samples:       208384 | elapsed time per iteration (ms): 7741.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153883E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.67 | backward-compute: 5483.96 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.02 | batch-generator: 12.30
 iteration      408/    1000 | consumed samples:       208896 | elapsed time per iteration (ms): 7744.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.152584E-01 | loss scale: 65536.0 | grad norm: 0.057 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.27 | backward-compute: 5485.43 | backward-params-all-reduce: 53.17 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.85 | optimizer: 80.26 | batch-generator: 12.24
 iteration      409/    1000 | consumed samples:       209408 | elapsed time per iteration (ms): 7744.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154182E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.91 | backward-compute: 5487.43 | backward-params-all-reduce: 52.37 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.98 | batch-generator: 11.97
 iteration      410/    1000 | consumed samples:       209920 | elapsed time per iteration (ms): 7740.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156243E-01 | loss scale: 65536.0 | grad norm: 0.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.22 | backward-compute: 5486.76 | backward-params-all-reduce: 53.46 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.97 | batch-generator: 12.06
-----------------------------------------------------------------------------------------------
 validation loss at iteration 410 | lm loss value: 1.155470E-01 | lm loss PPL: 1.122487E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      411/    1000 | consumed samples:       210432 | elapsed time per iteration (ms): 25858.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154730E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20220.47 | backward-compute: 5484.57 | backward-params-all-reduce: 53.11 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.93 | optimizer: 81.00 | batch-generator: 107.31
 iteration      412/    1000 | consumed samples:       210944 | elapsed time per iteration (ms): 7746.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153773E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.58 | backward-compute: 5486.24 | backward-params-all-reduce: 54.63 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.00 | batch-generator: 12.25
 iteration      413/    1000 | consumed samples:       211456 | elapsed time per iteration (ms): 7739.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154875E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.49 | backward-compute: 5483.83 | backward-params-all-reduce: 52.55 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.80 | optimizer: 80.04 | batch-generator: 11.89
 iteration      414/    1000 | consumed samples:       211968 | elapsed time per iteration (ms): 7747.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155524E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2123.80 | backward-compute: 5483.27 | backward-params-all-reduce: 53.45 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.71 | optimizer-clip-main-grad: 8.58 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.73 | batch-generator: 12.03
 iteration      415/    1000 | consumed samples:       212480 | elapsed time per iteration (ms): 7742.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154525E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.87 | backward-compute: 5483.78 | backward-params-all-reduce: 52.61 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.92 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.16 | batch-generator: 12.10
 iteration      416/    1000 | consumed samples:       212992 | elapsed time per iteration (ms): 7742.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155492E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.81 | backward-compute: 5485.55 | backward-params-all-reduce: 52.97 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.96 | batch-generator: 11.86
 iteration      417/    1000 | consumed samples:       213504 | elapsed time per iteration (ms): 7739.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155017E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.01 | backward-compute: 5486.22 | backward-params-all-reduce: 53.13 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.08 | batch-generator: 12.09
 iteration      418/    1000 | consumed samples:       214016 | elapsed time per iteration (ms): 7740.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153891E-01 | loss scale: 65536.0 | grad norm: 0.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.77 | backward-compute: 5485.62 | backward-params-all-reduce: 52.91 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.09 | batch-generator: 12.20
 iteration      419/    1000 | consumed samples:       214528 | elapsed time per iteration (ms): 7736.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154284E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.01 | backward-compute: 5488.38 | backward-params-all-reduce: 52.69 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.86 | batch-generator: 12.27
 iteration      420/    1000 | consumed samples:       215040 | elapsed time per iteration (ms): 7739.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155326E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.79 | backward-compute: 5486.80 | backward-params-all-reduce: 51.99 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.96 | batch-generator: 11.91
-----------------------------------------------------------------------------------------------
 validation loss at iteration 420 | lm loss value: 1.155750E-01 | lm loss PPL: 1.122519E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      421/    1000 | consumed samples:       215552 | elapsed time per iteration (ms): 25824.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155445E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20184.55 | backward-compute: 5487.70 | backward-params-all-reduce: 53.08 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.87 | batch-generator: 106.35
 iteration      422/    1000 | consumed samples:       216064 | elapsed time per iteration (ms): 7744.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154449E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.51 | backward-compute: 5488.07 | backward-params-all-reduce: 53.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.00 | batch-generator: 12.08
 iteration      423/    1000 | consumed samples:       216576 | elapsed time per iteration (ms): 7746.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154118E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.81 | backward-compute: 5486.90 | backward-params-all-reduce: 53.78 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.98 | batch-generator: 12.06
 iteration      424/    1000 | consumed samples:       217088 | elapsed time per iteration (ms): 7739.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156107E-01 | loss scale: 65536.0 | grad norm: 0.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.68 | backward-compute: 5488.43 | backward-params-all-reduce: 52.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.94 | batch-generator: 12.39
 iteration      425/    1000 | consumed samples:       217600 | elapsed time per iteration (ms): 7742.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154869E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.14 | backward-compute: 5486.93 | backward-params-all-reduce: 52.68 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.12 | batch-generator: 12.50
 iteration      426/    1000 | consumed samples:       218112 | elapsed time per iteration (ms): 7739.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154845E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.48 | backward-compute: 5487.25 | backward-params-all-reduce: 52.45 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.01 | batch-generator: 12.40
 iteration      427/    1000 | consumed samples:       218624 | elapsed time per iteration (ms): 7741.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154159E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.46 | backward-compute: 5488.89 | backward-params-all-reduce: 52.57 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.05 | batch-generator: 12.01
 iteration      428/    1000 | consumed samples:       219136 | elapsed time per iteration (ms): 7737.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154706E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.39 | backward-compute: 5487.55 | backward-params-all-reduce: 52.49 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 80.04 | batch-generator: 12.40
 iteration      429/    1000 | consumed samples:       219648 | elapsed time per iteration (ms): 7736.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154708E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.49 | backward-compute: 5487.89 | backward-params-all-reduce: 51.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.80 | batch-generator: 12.37
 iteration      430/    1000 | consumed samples:       220160 | elapsed time per iteration (ms): 7741.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154802E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.48 | backward-compute: 5493.92 | backward-params-all-reduce: 51.67 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.97 | optimizer-clip-main-grad: 11.59 | optimizer-copy-main-to-model-params: 12.37 | optimizer: 84.85 | batch-generator: 12.37
-----------------------------------------------------------------------------------------------
 validation loss at iteration 430 | lm loss value: 1.155772E-01 | lm loss PPL: 1.122521E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      431/    1000 | consumed samples:       220672 | elapsed time per iteration (ms): 25844.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154298E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20201.78 | backward-compute: 5489.08 | backward-params-all-reduce: 52.47 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.77 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.19 | batch-generator: 109.21
 iteration      432/    1000 | consumed samples:       221184 | elapsed time per iteration (ms): 7739.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155325E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.67 | backward-compute: 5485.38 | backward-params-all-reduce: 53.04 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.99 | batch-generator: 12.18
 iteration      433/    1000 | consumed samples:       221696 | elapsed time per iteration (ms): 7746.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153972E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.45 | backward-compute: 5486.98 | backward-params-all-reduce: 52.52 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.91 | batch-generator: 12.18
 iteration      434/    1000 | consumed samples:       222208 | elapsed time per iteration (ms): 7739.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154169E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.29 | backward-compute: 5487.03 | backward-params-all-reduce: 51.83 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.10 | batch-generator: 11.88
 iteration      435/    1000 | consumed samples:       222720 | elapsed time per iteration (ms): 7741.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154527E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.38 | backward-compute: 5487.74 | backward-params-all-reduce: 52.44 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.10 | batch-generator: 11.74
 iteration      436/    1000 | consumed samples:       223232 | elapsed time per iteration (ms): 7741.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155108E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.12 | backward-compute: 5484.62 | backward-params-all-reduce: 52.65 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.13 | batch-generator: 12.40
 iteration      437/    1000 | consumed samples:       223744 | elapsed time per iteration (ms): 7738.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154522E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.08 | backward-compute: 5485.40 | backward-params-all-reduce: 51.84 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.03 | batch-generator: 12.01
 iteration      438/    1000 | consumed samples:       224256 | elapsed time per iteration (ms): 7741.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154471E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.37 | backward-compute: 5485.92 | backward-params-all-reduce: 52.85 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.05 | batch-generator: 11.72
 iteration      439/    1000 | consumed samples:       224768 | elapsed time per iteration (ms): 7739.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154088E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.98 | backward-compute: 5485.77 | backward-params-all-reduce: 52.35 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.85 | batch-generator: 11.75
 iteration      440/    1000 | consumed samples:       225280 | elapsed time per iteration (ms): 7741.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154670E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.58 | backward-compute: 5484.90 | backward-params-all-reduce: 52.88 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.99 | batch-generator: 11.92
-----------------------------------------------------------------------------------------------
 validation loss at iteration 440 | lm loss value: 1.155790E-01 | lm loss PPL: 1.122523E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      441/    1000 | consumed samples:       225792 | elapsed time per iteration (ms): 25834.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154716E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20197.01 | backward-compute: 5486.24 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.08 | batch-generator: 106.20
 iteration      442/    1000 | consumed samples:       226304 | elapsed time per iteration (ms): 7737.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153557E-01 | loss scale: 65536.0 | grad norm: 0.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.10 | backward-compute: 5488.34 | backward-params-all-reduce: 51.91 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.94 | batch-generator: 12.13
 iteration      443/    1000 | consumed samples:       226816 | elapsed time per iteration (ms): 7744.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155284E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.30 | backward-compute: 5486.70 | backward-params-all-reduce: 52.53 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.06 | batch-generator: 11.94
 iteration      444/    1000 | consumed samples:       227328 | elapsed time per iteration (ms): 7737.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155034E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.20 | backward-compute: 5484.98 | backward-params-all-reduce: 53.01 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.77 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 80.11 | batch-generator: 12.06
 iteration      445/    1000 | consumed samples:       227840 | elapsed time per iteration (ms): 7741.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154464E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.03 | backward-compute: 5484.87 | backward-params-all-reduce: 52.51 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 79.96 | batch-generator: 11.88
 iteration      446/    1000 | consumed samples:       228352 | elapsed time per iteration (ms): 7740.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154182E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.00 | backward-compute: 5486.11 | backward-params-all-reduce: 52.53 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.93 | batch-generator: 12.08
 iteration      447/    1000 | consumed samples:       228864 | elapsed time per iteration (ms): 7744.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154624E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.94 | backward-compute: 5485.93 | backward-params-all-reduce: 52.94 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.12 | batch-generator: 12.64
 iteration      448/    1000 | consumed samples:       229376 | elapsed time per iteration (ms): 7746.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156004E-01 | loss scale: 65536.0 | grad norm: 0.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.42 | backward-compute: 5485.47 | backward-params-all-reduce: 53.25 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.09 | batch-generator: 12.28
 iteration      449/    1000 | consumed samples:       229888 | elapsed time per iteration (ms): 7745.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155834E-01 | loss scale: 65536.0 | grad norm: 0.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.76 | backward-compute: 5483.81 | backward-params-all-reduce: 52.55 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.02 | batch-generator: 12.05
 iteration      450/    1000 | consumed samples:       230400 | elapsed time per iteration (ms): 7740.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155971E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.75 | backward-compute: 5486.16 | backward-params-all-reduce: 52.56 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.00 | batch-generator: 12.17
-----------------------------------------------------------------------------------------------
 validation loss at iteration 450 | lm loss value: 1.155805E-01 | lm loss PPL: 1.122525E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      451/    1000 | consumed samples:       230912 | elapsed time per iteration (ms): 25873.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155369E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20233.12 | backward-compute: 5487.82 | backward-params-all-reduce: 53.10 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.02 | batch-generator: 109.62
 iteration      452/    1000 | consumed samples:       231424 | elapsed time per iteration (ms): 7743.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154454E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.82 | backward-compute: 5484.42 | backward-params-all-reduce: 52.77 | backward-embedding-all-reduce: 0.06 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.85 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.02 | batch-generator: 12.30
 iteration      453/    1000 | consumed samples:       231936 | elapsed time per iteration (ms): 7743.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155170E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.27 | backward-compute: 5488.17 | backward-params-all-reduce: 52.45 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.70 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.91 | batch-generator: 12.32
 iteration      454/    1000 | consumed samples:       232448 | elapsed time per iteration (ms): 7747.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154370E-01 | loss scale: 65536.0 | grad norm: 0.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.88 | backward-compute: 5485.90 | backward-params-all-reduce: 53.49 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.00 | batch-generator: 12.26
 iteration      455/    1000 | consumed samples:       232960 | elapsed time per iteration (ms): 7747.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154612E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2124.68 | backward-compute: 5482.53 | backward-params-all-reduce: 52.63 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.59 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.98 | batch-generator: 12.55
 iteration      456/    1000 | consumed samples:       233472 | elapsed time per iteration (ms): 7740.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155859E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.96 | backward-compute: 5487.99 | backward-params-all-reduce: 53.07 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.02 | batch-generator: 12.45
 iteration      457/    1000 | consumed samples:       233984 | elapsed time per iteration (ms): 7739.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155613E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.55 | backward-compute: 5485.59 | backward-params-all-reduce: 53.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.02 | batch-generator: 12.70
 iteration      458/    1000 | consumed samples:       234496 | elapsed time per iteration (ms): 7741.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154364E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.47 | backward-compute: 5486.56 | backward-params-all-reduce: 53.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.03 | batch-generator: 12.38
 iteration      459/    1000 | consumed samples:       235008 | elapsed time per iteration (ms): 7743.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154549E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.53 | backward-compute: 5485.37 | backward-params-all-reduce: 53.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.96 | batch-generator: 12.50
 iteration      460/    1000 | consumed samples:       235520 | elapsed time per iteration (ms): 7742.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154166E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.85 | backward-compute: 5483.02 | backward-params-all-reduce: 52.42 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.00 | batch-generator: 11.97
-----------------------------------------------------------------------------------------------
 validation loss at iteration 460 | lm loss value: 1.155609E-01 | lm loss PPL: 1.122503E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      461/    1000 | consumed samples:       236032 | elapsed time per iteration (ms): 25869.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154112E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20233.63 | backward-compute: 5483.27 | backward-params-all-reduce: 53.39 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.00 | batch-generator: 109.09
 iteration      462/    1000 | consumed samples:       236544 | elapsed time per iteration (ms): 7741.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154658E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.02 | backward-compute: 5482.53 | backward-params-all-reduce: 53.48 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.07 | batch-generator: 12.40
 iteration      463/    1000 | consumed samples:       237056 | elapsed time per iteration (ms): 7742.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155377E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.85 | backward-compute: 5486.86 | backward-params-all-reduce: 52.64 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.98 | batch-generator: 12.23
 iteration      464/    1000 | consumed samples:       237568 | elapsed time per iteration (ms): 7743.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154072E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.35 | backward-compute: 5487.12 | backward-params-all-reduce: 52.18 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.60 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.98 | batch-generator: 12.44
 iteration      465/    1000 | consumed samples:       238080 | elapsed time per iteration (ms): 7739.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155405E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.54 | backward-compute: 5486.09 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.01 | batch-generator: 12.39
 iteration      466/    1000 | consumed samples:       238592 | elapsed time per iteration (ms): 7739.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155214E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.85 | backward-compute: 5486.19 | backward-params-all-reduce: 52.78 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.09 | batch-generator: 12.13
 iteration      467/    1000 | consumed samples:       239104 | elapsed time per iteration (ms): 7740.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.152978E-01 | loss scale: 65536.0 | grad norm: 0.057 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.42 | backward-compute: 5483.88 | backward-params-all-reduce: 52.84 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.07 | batch-generator: 12.12
 iteration      468/    1000 | consumed samples:       239616 | elapsed time per iteration (ms): 7747.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156432E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.80 | backward-compute: 5485.00 | backward-params-all-reduce: 53.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.01 | batch-generator: 12.25
 iteration      469/    1000 | consumed samples:       240128 | elapsed time per iteration (ms): 7745.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154726E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.67 | backward-compute: 5491.57 | backward-params-all-reduce: 52.41 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.12 | batch-generator: 12.70
 iteration      470/    1000 | consumed samples:       240640 | elapsed time per iteration (ms): 7741.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155950E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.65 | backward-compute: 5491.03 | backward-params-all-reduce: 53.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.14 | batch-generator: 12.57
-----------------------------------------------------------------------------------------------
 validation loss at iteration 470 | lm loss value: 1.155756E-01 | lm loss PPL: 1.122519E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      471/    1000 | consumed samples:       241152 | elapsed time per iteration (ms): 25864.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155725E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20224.90 | backward-compute: 5487.01 | backward-params-all-reduce: 52.43 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.06 | batch-generator: 108.11
 iteration      472/    1000 | consumed samples:       241664 | elapsed time per iteration (ms): 7740.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154595E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.58 | backward-compute: 5487.58 | backward-params-all-reduce: 53.15 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.18 | batch-generator: 12.28
 iteration      473/    1000 | consumed samples:       242176 | elapsed time per iteration (ms): 7743.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155209E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.06 | backward-compute: 5489.43 | backward-params-all-reduce: 52.44 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 12.02 | optimizer: 81.58 | batch-generator: 12.30
 iteration      474/    1000 | consumed samples:       242688 | elapsed time per iteration (ms): 7742.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155856E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.69 | backward-compute: 5488.74 | backward-params-all-reduce: 51.81 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.97 | batch-generator: 12.77
 iteration      475/    1000 | consumed samples:       243200 | elapsed time per iteration (ms): 7751.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154350E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2122.47 | backward-compute: 5489.42 | backward-params-all-reduce: 52.50 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.88 | batch-generator: 12.50
 iteration      476/    1000 | consumed samples:       243712 | elapsed time per iteration (ms): 7743.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155545E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.23 | backward-compute: 5487.74 | backward-params-all-reduce: 52.80 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.06 | batch-generator: 12.26
 iteration      477/    1000 | consumed samples:       244224 | elapsed time per iteration (ms): 7742.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155324E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.11 | backward-compute: 5489.06 | backward-params-all-reduce: 52.85 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 80.23 | batch-generator: 12.23
 iteration      478/    1000 | consumed samples:       244736 | elapsed time per iteration (ms): 7744.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154652E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.49 | backward-compute: 5486.03 | backward-params-all-reduce: 53.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.93 | batch-generator: 12.25
 iteration      479/    1000 | consumed samples:       245248 | elapsed time per iteration (ms): 7742.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.152912E-01 | loss scale: 65536.0 | grad norm: 0.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.66 | backward-compute: 5487.37 | backward-params-all-reduce: 52.90 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.98 | batch-generator: 12.17
 iteration      480/    1000 | consumed samples:       245760 | elapsed time per iteration (ms): 7742.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155086E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.71 | backward-compute: 5488.12 | backward-params-all-reduce: 52.27 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.16 | batch-generator: 12.74
-----------------------------------------------------------------------------------------------
 validation loss at iteration 480 | lm loss value: 1.155610E-01 | lm loss PPL: 1.122503E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      481/    1000 | consumed samples:       246272 | elapsed time per iteration (ms): 25871.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155057E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20229.02 | backward-compute: 5489.51 | backward-params-all-reduce: 53.65 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.02 | batch-generator: 109.67
 iteration      482/    1000 | consumed samples:       246784 | elapsed time per iteration (ms): 7742.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154505E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.85 | backward-compute: 5488.26 | backward-params-all-reduce: 53.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 80.02 | batch-generator: 12.27
 iteration      483/    1000 | consumed samples:       247296 | elapsed time per iteration (ms): 7745.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154017E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.62 | backward-compute: 5489.01 | backward-params-all-reduce: 53.95 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.86 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.85 | optimizer: 80.30 | batch-generator: 12.29
 iteration      484/    1000 | consumed samples:       247808 | elapsed time per iteration (ms): 7742.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153501E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.55 | backward-compute: 5484.80 | backward-params-all-reduce: 54.30 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.03 | batch-generator: 12.68
 iteration      485/    1000 | consumed samples:       248320 | elapsed time per iteration (ms): 7739.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155232E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.68 | backward-compute: 5484.29 | backward-params-all-reduce: 54.09 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.06 | batch-generator: 12.33
 iteration      486/    1000 | consumed samples:       248832 | elapsed time per iteration (ms): 7738.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154601E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.50 | backward-compute: 5490.87 | backward-params-all-reduce: 53.86 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.03 | batch-generator: 12.13
 iteration      487/    1000 | consumed samples:       249344 | elapsed time per iteration (ms): 7743.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154337E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.90 | backward-compute: 5487.27 | backward-params-all-reduce: 54.30 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.07 | batch-generator: 12.35
 iteration      488/    1000 | consumed samples:       249856 | elapsed time per iteration (ms): 7739.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154313E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.73 | backward-compute: 5490.11 | backward-params-all-reduce: 54.04 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.04 | batch-generator: 12.36
 iteration      489/    1000 | consumed samples:       250368 | elapsed time per iteration (ms): 7743.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154442E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.43 | backward-compute: 5484.05 | backward-params-all-reduce: 54.94 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.10 | batch-generator: 12.43
 iteration      490/    1000 | consumed samples:       250880 | elapsed time per iteration (ms): 7751.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154639E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2123.66 | backward-compute: 5486.38 | backward-params-all-reduce: 53.84 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.80 | optimizer: 80.20 | batch-generator: 12.53
-----------------------------------------------------------------------------------------------
 validation loss at iteration 490 | lm loss value: 1.155846E-01 | lm loss PPL: 1.122529E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      491/    1000 | consumed samples:       251392 | elapsed time per iteration (ms): 25860.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155399E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20219.84 | backward-compute: 5486.75 | backward-params-all-reduce: 54.47 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.85 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.80 | optimizer: 80.20 | batch-generator: 109.57
 iteration      492/    1000 | consumed samples:       251904 | elapsed time per iteration (ms): 7736.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155755E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.12 | backward-compute: 5487.22 | backward-params-all-reduce: 54.15 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.12 | batch-generator: 12.27
 iteration      493/    1000 | consumed samples:       252416 | elapsed time per iteration (ms): 7738.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155839E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.43 | backward-compute: 5486.23 | backward-params-all-reduce: 53.86 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.02 | batch-generator: 12.35
 iteration      494/    1000 | consumed samples:       252928 | elapsed time per iteration (ms): 7736.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154874E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.19 | backward-compute: 5485.61 | backward-params-all-reduce: 54.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.26 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.94 | batch-generator: 12.28
 iteration      495/    1000 | consumed samples:       253440 | elapsed time per iteration (ms): 7740.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156122E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.07 | backward-compute: 5491.22 | backward-params-all-reduce: 54.17 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.13 | batch-generator: 12.59
 iteration      496/    1000 | consumed samples:       253952 | elapsed time per iteration (ms): 7743.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155584E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.52 | backward-compute: 5489.15 | backward-params-all-reduce: 53.87 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.82 | optimizer: 80.19 | batch-generator: 12.25
 iteration      497/    1000 | consumed samples:       254464 | elapsed time per iteration (ms): 7741.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155557E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.01 | backward-compute: 5485.82 | backward-params-all-reduce: 54.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.00 | batch-generator: 12.17
 iteration      498/    1000 | consumed samples:       254976 | elapsed time per iteration (ms): 7742.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155561E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.49 | backward-compute: 5489.40 | backward-params-all-reduce: 54.56 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.10 | batch-generator: 12.16
 iteration      499/    1000 | consumed samples:       255488 | elapsed time per iteration (ms): 7735.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154782E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.97 | backward-compute: 5490.33 | backward-params-all-reduce: 54.47 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.97 | batch-generator: 12.32
 iteration      500/    1000 | consumed samples:       256000 | elapsed time per iteration (ms): 7744.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154705E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.01 | backward-compute: 5493.38 | backward-params-all-reduce: 53.54 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 80.04 | batch-generator: 12.24
-----------------------------------------------------------------------------------------------
 validation loss at iteration 500 | lm loss value: 1.155709E-01 | lm loss PPL: 1.122514E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      501/    1000 | consumed samples:       256512 | elapsed time per iteration (ms): 25876.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156257E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20231.43 | backward-compute: 5491.07 | backward-params-all-reduce: 53.92 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.06 | batch-generator: 110.19
 iteration      502/    1000 | consumed samples:       257024 | elapsed time per iteration (ms): 7747.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155446E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.46 | backward-compute: 5489.67 | backward-params-all-reduce: 54.07 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.97 | batch-generator: 12.08
 iteration      503/    1000 | consumed samples:       257536 | elapsed time per iteration (ms): 7741.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154727E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.39 | backward-compute: 5488.90 | backward-params-all-reduce: 53.60 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.01 | batch-generator: 12.73
 iteration      504/    1000 | consumed samples:       258048 | elapsed time per iteration (ms): 7745.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154777E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.25 | backward-compute: 5486.43 | backward-params-all-reduce: 53.93 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.15 | batch-generator: 12.31
 iteration      505/    1000 | consumed samples:       258560 | elapsed time per iteration (ms): 7745.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156011E-01 | loss scale: 65536.0 | grad norm: 0.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.02 | backward-compute: 5484.71 | backward-params-all-reduce: 54.08 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.99 | batch-generator: 11.87
 iteration      506/    1000 | consumed samples:       259072 | elapsed time per iteration (ms): 7748.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155434E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.27 | backward-compute: 5488.49 | backward-params-all-reduce: 53.74 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.01 | batch-generator: 12.56
 iteration      507/    1000 | consumed samples:       259584 | elapsed time per iteration (ms): 7743.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155886E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.60 | backward-compute: 5488.38 | backward-params-all-reduce: 53.56 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.01 | batch-generator: 12.47
 iteration      508/    1000 | consumed samples:       260096 | elapsed time per iteration (ms): 7745.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154714E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.97 | backward-compute: 5485.78 | backward-params-all-reduce: 53.43 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.11 | batch-generator: 12.36
 iteration      509/    1000 | consumed samples:       260608 | elapsed time per iteration (ms): 7741.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155383E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.52 | backward-compute: 5486.55 | backward-params-all-reduce: 53.85 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.87 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.10 | batch-generator: 12.15
 iteration      510/    1000 | consumed samples:       261120 | elapsed time per iteration (ms): 7744.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154488E-01 | loss scale: 65536.0 | grad norm: 0.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.57 | backward-compute: 5484.07 | backward-params-all-reduce: 54.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.97 | batch-generator: 12.33
-----------------------------------------------------------------------------------------------
 validation loss at iteration 510 | lm loss value: 1.156197E-01 | lm loss PPL: 1.122569E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      511/    1000 | consumed samples:       261632 | elapsed time per iteration (ms): 25867.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154032E-01 | loss scale: 65536.0 | grad norm: 0.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20225.54 | backward-compute: 5488.84 | backward-params-all-reduce: 53.76 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.14 | batch-generator: 109.88
 iteration      512/    1000 | consumed samples:       262144 | elapsed time per iteration (ms): 7744.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155599E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.95 | backward-compute: 5487.61 | backward-params-all-reduce: 54.19 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.08 | batch-generator: 12.45
 iteration      513/    1000 | consumed samples:       262656 | elapsed time per iteration (ms): 7743.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155647E-01 | loss scale: 65536.0 | grad norm: 0.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.45 | backward-compute: 5489.09 | backward-params-all-reduce: 53.89 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.07 | batch-generator: 12.66
 iteration      514/    1000 | consumed samples:       263168 | elapsed time per iteration (ms): 7745.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155407E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.92 | backward-compute: 5484.99 | backward-params-all-reduce: 53.70 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.07 | batch-generator: 12.61
 iteration      515/    1000 | consumed samples:       263680 | elapsed time per iteration (ms): 7743.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154476E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.59 | backward-compute: 5483.35 | backward-params-all-reduce: 54.49 | backward-embedding-all-reduce: 0.04 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.05 | batch-generator: 12.27
 iteration      516/    1000 | consumed samples:       264192 | elapsed time per iteration (ms): 7745.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155806E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.68 | backward-compute: 5486.00 | backward-params-all-reduce: 54.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.03 | batch-generator: 12.26
 iteration      517/    1000 | consumed samples:       264704 | elapsed time per iteration (ms): 7745.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154598E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.44 | backward-compute: 5486.63 | backward-params-all-reduce: 54.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.99 | batch-generator: 12.36
 iteration      518/    1000 | consumed samples:       265216 | elapsed time per iteration (ms): 7737.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154074E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.10 | backward-compute: 5485.62 | backward-params-all-reduce: 54.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.79 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.14 | batch-generator: 12.39
 iteration      519/    1000 | consumed samples:       265728 | elapsed time per iteration (ms): 7737.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155244E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.18 | backward-compute: 5488.57 | backward-params-all-reduce: 53.87 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.84 | optimizer: 80.22 | batch-generator: 12.33
 iteration      520/    1000 | consumed samples:       266240 | elapsed time per iteration (ms): 7741.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154425E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.07 | backward-compute: 5485.78 | backward-params-all-reduce: 54.35 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.07 | batch-generator: 12.30
-----------------------------------------------------------------------------------------------
 validation loss at iteration 520 | lm loss value: 1.155915E-01 | lm loss PPL: 1.122537E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      521/    1000 | consumed samples:       266752 | elapsed time per iteration (ms): 25870.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155703E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20231.91 | backward-compute: 5486.76 | backward-params-all-reduce: 52.41 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.88 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.24 | batch-generator: 108.08
 iteration      522/    1000 | consumed samples:       267264 | elapsed time per iteration (ms): 7742.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156274E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.36 | backward-compute: 5486.02 | backward-params-all-reduce: 53.01 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.96 | batch-generator: 12.17
 iteration      523/    1000 | consumed samples:       267776 | elapsed time per iteration (ms): 7739.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155294E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.55 | backward-compute: 5484.99 | backward-params-all-reduce: 52.65 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.88 | batch-generator: 12.22
 iteration      524/    1000 | consumed samples:       268288 | elapsed time per iteration (ms): 7744.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155135E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.64 | backward-compute: 5487.24 | backward-params-all-reduce: 52.52 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 80.05 | batch-generator: 12.13
 iteration      525/    1000 | consumed samples:       268800 | elapsed time per iteration (ms): 7743.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154007E-01 | loss scale: 65536.0 | grad norm: 0.044 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.12 | backward-compute: 5484.45 | backward-params-all-reduce: 52.86 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.81 | optimizer-copy-main-to-model-params: 11.82 | optimizer: 80.20 | batch-generator: 12.09
 iteration      526/    1000 | consumed samples:       269312 | elapsed time per iteration (ms): 7741.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154083E-01 | loss scale: 65536.0 | grad norm: 0.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.57 | backward-compute: 5483.00 | backward-params-all-reduce: 53.53 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.04 | batch-generator: 12.58
 iteration      527/    1000 | consumed samples:       269824 | elapsed time per iteration (ms): 7739.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155139E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.69 | backward-compute: 5485.19 | backward-params-all-reduce: 52.68 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.07 | batch-generator: 12.56
 iteration      528/    1000 | consumed samples:       270336 | elapsed time per iteration (ms): 7741.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154516E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.08 | backward-compute: 5483.31 | backward-params-all-reduce: 53.03 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.93 | batch-generator: 12.25
 iteration      529/    1000 | consumed samples:       270848 | elapsed time per iteration (ms): 7743.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154633E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.81 | backward-compute: 5483.45 | backward-params-all-reduce: 53.22 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.94 | batch-generator: 12.26
 iteration      530/    1000 | consumed samples:       271360 | elapsed time per iteration (ms): 7743.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153723E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.95 | backward-compute: 5483.00 | backward-params-all-reduce: 52.13 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.00 | batch-generator: 12.30
-----------------------------------------------------------------------------------------------
 validation loss at iteration 530 | lm loss value: 1.155758E-01 | lm loss PPL: 1.122520E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      531/    1000 | consumed samples:       271872 | elapsed time per iteration (ms): 25841.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155617E-01 | loss scale: 65536.0 | grad norm: 0.042 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20205.82 | backward-compute: 5483.03 | backward-params-all-reduce: 52.54 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.06 | batch-generator: 123.39
 iteration      532/    1000 | consumed samples:       272384 | elapsed time per iteration (ms): 7740.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155584E-01 | loss scale: 65536.0 | grad norm: 0.037 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.34 | backward-compute: 5485.58 | backward-params-all-reduce: 52.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.91 | batch-generator: 12.15
 iteration      533/    1000 | consumed samples:       272896 | elapsed time per iteration (ms): 7743.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155513E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2116.75 | backward-compute: 5487.44 | backward-params-all-reduce: 52.38 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.11 | batch-generator: 12.37
 iteration      534/    1000 | consumed samples:       273408 | elapsed time per iteration (ms): 7737.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153660E-01 | loss scale: 65536.0 | grad norm: 0.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.39 | backward-compute: 5492.19 | backward-params-all-reduce: 52.55 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.98 | batch-generator: 12.02
 iteration      535/    1000 | consumed samples:       273920 | elapsed time per iteration (ms): 7738.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155225E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.76 | backward-compute: 5486.52 | backward-params-all-reduce: 52.09 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.97 | optimizer: 81.03 | batch-generator: 12.37
 iteration      536/    1000 | consumed samples:       274432 | elapsed time per iteration (ms): 7741.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154037E-01 | loss scale: 65536.0 | grad norm: 0.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.38 | backward-compute: 5487.46 | backward-params-all-reduce: 53.39 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.96 | batch-generator: 12.23
 iteration      537/    1000 | consumed samples:       274944 | elapsed time per iteration (ms): 7737.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154506E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.94 | backward-compute: 5488.92 | backward-params-all-reduce: 52.69 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.04 | batch-generator: 12.42
 iteration      538/    1000 | consumed samples:       275456 | elapsed time per iteration (ms): 7737.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154519E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.86 | backward-compute: 5485.53 | backward-params-all-reduce: 52.91 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.96 | batch-generator: 12.15
 iteration      539/    1000 | consumed samples:       275968 | elapsed time per iteration (ms): 7743.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154321E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.79 | backward-compute: 5484.88 | backward-params-all-reduce: 52.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.78 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.12 | batch-generator: 12.12
 iteration      540/    1000 | consumed samples:       276480 | elapsed time per iteration (ms): 7734.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155736E-01 | loss scale: 65536.0 | grad norm: 0.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.74 | backward-compute: 5485.09 | backward-params-all-reduce: 52.93 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.91 | batch-generator: 12.08
-----------------------------------------------------------------------------------------------
 validation loss at iteration 540 | lm loss value: 1.156029E-01 | lm loss PPL: 1.122550E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      541/    1000 | consumed samples:       276992 | elapsed time per iteration (ms): 25802.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154463E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20168.26 | backward-compute: 5482.33 | backward-params-all-reduce: 52.36 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.02 | batch-generator: 118.53
 iteration      542/    1000 | consumed samples:       277504 | elapsed time per iteration (ms): 7721.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155595E-01 | loss scale: 65536.0 | grad norm: 0.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.62 | backward-compute: 5485.41 | backward-params-all-reduce: 52.58 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.94 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.16 | batch-generator: 12.12
 iteration      543/    1000 | consumed samples:       278016 | elapsed time per iteration (ms): 7714.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155497E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2094.40 | backward-compute: 5480.24 | backward-params-all-reduce: 52.37 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.85 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.16 | batch-generator: 12.05
 iteration      544/    1000 | consumed samples:       278528 | elapsed time per iteration (ms): 7716.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155102E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.85 | backward-compute: 5482.90 | backward-params-all-reduce: 52.18 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.94 | batch-generator: 12.02
 iteration      545/    1000 | consumed samples:       279040 | elapsed time per iteration (ms): 7717.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154367E-01 | loss scale: 65536.0 | grad norm: 0.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2092.31 | backward-compute: 5485.97 | backward-params-all-reduce: 51.90 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.60 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 79.93 | batch-generator: 12.05
 iteration      546/    1000 | consumed samples:       279552 | elapsed time per iteration (ms): 7715.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155039E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2088.14 | backward-compute: 5488.31 | backward-params-all-reduce: 51.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.21 | batch-generator: 12.28
 iteration      547/    1000 | consumed samples:       280064 | elapsed time per iteration (ms): 7718.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155648E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.04 | backward-compute: 5485.67 | backward-params-all-reduce: 51.98 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.88 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.82 | optimizer: 80.19 | batch-generator: 12.01
 iteration      548/    1000 | consumed samples:       280576 | elapsed time per iteration (ms): 7721.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153958E-01 | loss scale: 65536.0 | grad norm: 0.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.56 | backward-compute: 5483.72 | backward-params-all-reduce: 51.79 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.00 | batch-generator: 12.79
 iteration      549/    1000 | consumed samples:       281088 | elapsed time per iteration (ms): 7722.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153849E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.55 | backward-compute: 5487.33 | backward-params-all-reduce: 52.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.02 | batch-generator: 12.32
 iteration      550/    1000 | consumed samples:       281600 | elapsed time per iteration (ms): 7717.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155068E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2092.65 | backward-compute: 5484.89 | backward-params-all-reduce: 52.19 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.97 | batch-generator: 12.24
-----------------------------------------------------------------------------------------------
 validation loss at iteration 550 | lm loss value: 1.155940E-01 | lm loss PPL: 1.122540E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      551/    1000 | consumed samples:       282112 | elapsed time per iteration (ms): 25719.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154744E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20082.43 | backward-compute: 5485.26 | backward-params-all-reduce: 52.62 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.98 | batch-generator: 108.52
 iteration      552/    1000 | consumed samples:       282624 | elapsed time per iteration (ms): 7722.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155663E-01 | loss scale: 65536.0 | grad norm: 0.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.70 | backward-compute: 5486.87 | backward-params-all-reduce: 52.18 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.03 | batch-generator: 12.08
 iteration      553/    1000 | consumed samples:       283136 | elapsed time per iteration (ms): 7728.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155248E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.12 | backward-compute: 5485.64 | backward-params-all-reduce: 51.65 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.90 | batch-generator: 12.19
 iteration      554/    1000 | consumed samples:       283648 | elapsed time per iteration (ms): 7722.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154761E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.41 | backward-compute: 5484.29 | backward-params-all-reduce: 51.91 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.07 | batch-generator: 11.88
 iteration      555/    1000 | consumed samples:       284160 | elapsed time per iteration (ms): 7729.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153797E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.62 | backward-compute: 5483.10 | backward-params-all-reduce: 52.29 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.00 | batch-generator: 12.11
 iteration      556/    1000 | consumed samples:       284672 | elapsed time per iteration (ms): 7725.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154644E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.84 | backward-compute: 5487.07 | backward-params-all-reduce: 51.67 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 80.21 | batch-generator: 12.02
 iteration      557/    1000 | consumed samples:       285184 | elapsed time per iteration (ms): 7725.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154551E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.24 | backward-compute: 5487.18 | backward-params-all-reduce: 52.06 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.02 | batch-generator: 12.41
 iteration      558/    1000 | consumed samples:       285696 | elapsed time per iteration (ms): 7730.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155081E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.93 | backward-compute: 5484.01 | backward-params-all-reduce: 52.17 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.92 | batch-generator: 12.62
 iteration      559/    1000 | consumed samples:       286208 | elapsed time per iteration (ms): 7732.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154691E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.07 | backward-compute: 5487.63 | backward-params-all-reduce: 52.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.97 | batch-generator: 12.15
 iteration      560/    1000 | consumed samples:       286720 | elapsed time per iteration (ms): 7740.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155708E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.61 | backward-compute: 5486.95 | backward-params-all-reduce: 52.54 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.87 | batch-generator: 11.85
-----------------------------------------------------------------------------------------------
 validation loss at iteration 560 | lm loss value: 1.155526E-01 | lm loss PPL: 1.122494E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      561/    1000 | consumed samples:       287232 | elapsed time per iteration (ms): 25914.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155006E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20271.92 | backward-compute: 5488.15 | backward-params-all-reduce: 54.64 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.04 | batch-generator: 107.70
 iteration      562/    1000 | consumed samples:       287744 | elapsed time per iteration (ms): 7757.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154571E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2129.18 | backward-compute: 5487.76 | backward-params-all-reduce: 53.57 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.91 | batch-generator: 12.08
 iteration      563/    1000 | consumed samples:       288256 | elapsed time per iteration (ms): 7751.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155721E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2125.48 | backward-compute: 5485.89 | backward-params-all-reduce: 53.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.02 | batch-generator: 12.12
 iteration      564/    1000 | consumed samples:       288768 | elapsed time per iteration (ms): 7747.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154980E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.45 | backward-compute: 5488.12 | backward-params-all-reduce: 52.03 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.00 | batch-generator: 12.03
 iteration      565/    1000 | consumed samples:       289280 | elapsed time per iteration (ms): 7741.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154924E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.22 | backward-compute: 5487.15 | backward-params-all-reduce: 52.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 79.92 | batch-generator: 12.26
 iteration      566/    1000 | consumed samples:       289792 | elapsed time per iteration (ms): 7735.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155394E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.74 | backward-compute: 5487.72 | backward-params-all-reduce: 52.27 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.85 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 80.07 | batch-generator: 12.19
 iteration      567/    1000 | consumed samples:       290304 | elapsed time per iteration (ms): 7737.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154831E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.43 | backward-compute: 5485.46 | backward-params-all-reduce: 52.38 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.02 | batch-generator: 12.33
 iteration      568/    1000 | consumed samples:       290816 | elapsed time per iteration (ms): 7738.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155074E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.10 | backward-compute: 5484.11 | backward-params-all-reduce: 53.46 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.15 | batch-generator: 12.19
 iteration      569/    1000 | consumed samples:       291328 | elapsed time per iteration (ms): 7733.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155464E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.61 | backward-compute: 5484.79 | backward-params-all-reduce: 52.11 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.04 | batch-generator: 11.96
 iteration      570/    1000 | consumed samples:       291840 | elapsed time per iteration (ms): 7726.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155692E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.61 | backward-compute: 5482.93 | backward-params-all-reduce: 52.56 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.00 | batch-generator: 11.95
-----------------------------------------------------------------------------------------------
 validation loss at iteration 570 | lm loss value: 1.155526E-01 | lm loss PPL: 1.122494E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      571/    1000 | consumed samples:       292352 | elapsed time per iteration (ms): 25801.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154879E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20168.19 | backward-compute: 5482.26 | backward-params-all-reduce: 51.81 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.98 | batch-generator: 106.99
 iteration      572/    1000 | consumed samples:       292864 | elapsed time per iteration (ms): 7731.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154442E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.83 | backward-compute: 5487.96 | backward-params-all-reduce: 52.29 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.03 | batch-generator: 12.08
 iteration      573/    1000 | consumed samples:       293376 | elapsed time per iteration (ms): 7728.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156343E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.59 | backward-compute: 5489.77 | backward-params-all-reduce: 52.20 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.89 | batch-generator: 11.99
 iteration      574/    1000 | consumed samples:       293888 | elapsed time per iteration (ms): 7728.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154142E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.28 | backward-compute: 5481.49 | backward-params-all-reduce: 52.46 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.95 | batch-generator: 12.06
 iteration      575/    1000 | consumed samples:       294400 | elapsed time per iteration (ms): 7729.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155031E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.18 | backward-compute: 5489.39 | backward-params-all-reduce: 51.95 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.90 | batch-generator: 11.88
 iteration      576/    1000 | consumed samples:       294912 | elapsed time per iteration (ms): 7728.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154019E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.69 | backward-compute: 5483.79 | backward-params-all-reduce: 52.15 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.71 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 79.87 | batch-generator: 12.00
 iteration      577/    1000 | consumed samples:       295424 | elapsed time per iteration (ms): 7730.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155384E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.32 | backward-compute: 5486.10 | backward-params-all-reduce: 52.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.05 | batch-generator: 12.00
 iteration      578/    1000 | consumed samples:       295936 | elapsed time per iteration (ms): 7722.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155390E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.22 | backward-compute: 5486.61 | backward-params-all-reduce: 52.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 79.95 | batch-generator: 12.61
 iteration      579/    1000 | consumed samples:       296448 | elapsed time per iteration (ms): 7727.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155372E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.88 | backward-compute: 5483.38 | backward-params-all-reduce: 52.32 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.92 | batch-generator: 12.33
 iteration      580/    1000 | consumed samples:       296960 | elapsed time per iteration (ms): 7728.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155152E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.18 | backward-compute: 5486.93 | backward-params-all-reduce: 51.93 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.70 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.69 | optimizer: 79.86 | batch-generator: 12.32
-----------------------------------------------------------------------------------------------
 validation loss at iteration 580 | lm loss value: 1.155597E-01 | lm loss PPL: 1.122502E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      581/    1000 | consumed samples:       297472 | elapsed time per iteration (ms): 25799.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155711E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20158.76 | backward-compute: 5489.19 | backward-params-all-reduce: 52.30 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.04 | batch-generator: 106.91
 iteration      582/    1000 | consumed samples:       297984 | elapsed time per iteration (ms): 7732.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154123E-01 | loss scale: 65536.0 | grad norm: 0.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.41 | backward-compute: 5484.15 | backward-params-all-reduce: 52.58 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 79.85 | batch-generator: 11.87
 iteration      583/    1000 | consumed samples:       298496 | elapsed time per iteration (ms): 7732.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154596E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.50 | backward-compute: 5484.68 | backward-params-all-reduce: 51.76 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.01 | batch-generator: 12.22
 iteration      584/    1000 | consumed samples:       299008 | elapsed time per iteration (ms): 7730.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154096E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.78 | backward-compute: 5485.92 | backward-params-all-reduce: 52.70 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.84 | optimizer: 80.20 | batch-generator: 13.05
 iteration      585/    1000 | consumed samples:       299520 | elapsed time per iteration (ms): 7731.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155727E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.33 | backward-compute: 5486.18 | backward-params-all-reduce: 52.68 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.93 | batch-generator: 12.39
 iteration      586/    1000 | consumed samples:       300032 | elapsed time per iteration (ms): 7727.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154261E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.47 | backward-compute: 5486.77 | backward-params-all-reduce: 51.80 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 8.84 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.06 | batch-generator: 11.95
 iteration      587/    1000 | consumed samples:       300544 | elapsed time per iteration (ms): 7728.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156667E-01 | loss scale: 65536.0 | grad norm: 0.054 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.43 | backward-compute: 5485.35 | backward-params-all-reduce: 52.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.06 | batch-generator: 12.43
 iteration      588/    1000 | consumed samples:       301056 | elapsed time per iteration (ms): 7728.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155042E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.60 | backward-compute: 5483.18 | backward-params-all-reduce: 52.81 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.80 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.11 | batch-generator: 12.13
 iteration      589/    1000 | consumed samples:       301568 | elapsed time per iteration (ms): 7725.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156389E-01 | loss scale: 65536.0 | grad norm: 0.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.38 | backward-compute: 5485.99 | backward-params-all-reduce: 52.15 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.87 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.99 | batch-generator: 12.10
 iteration      590/    1000 | consumed samples:       302080 | elapsed time per iteration (ms): 7722.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154426E-01 | loss scale: 65536.0 | grad norm: 0.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.34 | backward-compute: 5483.46 | backward-params-all-reduce: 51.91 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.59 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.83 | batch-generator: 12.34
-----------------------------------------------------------------------------------------------
 validation loss at iteration 590 | lm loss value: 1.155842E-01 | lm loss PPL: 1.122529E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      591/    1000 | consumed samples:       302592 | elapsed time per iteration (ms): 25709.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154875E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20073.23 | backward-compute: 5485.74 | backward-params-all-reduce: 51.92 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.96 | batch-generator: 106.64
 iteration      592/    1000 | consumed samples:       303104 | elapsed time per iteration (ms): 7713.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154817E-01 | loss scale: 65536.0 | grad norm: 0.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2091.41 | backward-compute: 5482.96 | backward-params-all-reduce: 51.84 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.97 | batch-generator: 12.06
 iteration      593/    1000 | consumed samples:       303616 | elapsed time per iteration (ms): 7714.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155315E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2090.92 | backward-compute: 5483.75 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.98 | batch-generator: 11.78
 iteration      594/    1000 | consumed samples:       304128 | elapsed time per iteration (ms): 7712.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154038E-01 | loss scale: 65536.0 | grad norm: 0.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2085.48 | backward-compute: 5487.68 | backward-params-all-reduce: 51.97 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.95 | batch-generator: 12.00
 iteration      595/    1000 | consumed samples:       304640 | elapsed time per iteration (ms): 7714.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154562E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2086.14 | backward-compute: 5488.79 | backward-params-all-reduce: 52.20 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.98 | batch-generator: 12.04
 iteration      596/    1000 | consumed samples:       305152 | elapsed time per iteration (ms): 7718.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155209E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.84 | backward-compute: 5480.74 | backward-params-all-reduce: 52.19 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.03 | batch-generator: 11.86
 iteration      597/    1000 | consumed samples:       305664 | elapsed time per iteration (ms): 7719.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155895E-01 | loss scale: 65536.0 | grad norm: 0.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.56 | backward-compute: 5482.86 | backward-params-all-reduce: 51.91 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 10.75 | optimizer-copy-main-to-model-params: 11.99 | optimizer: 84.04 | batch-generator: 12.20
 iteration      598/    1000 | consumed samples:       306176 | elapsed time per iteration (ms): 7722.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155494E-01 | loss scale: 65536.0 | grad norm: 0.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.21 | backward-compute: 5484.15 | backward-params-all-reduce: 51.71 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.96 | batch-generator: 12.04
 iteration      599/    1000 | consumed samples:       306688 | elapsed time per iteration (ms): 7726.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154312E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.82 | backward-compute: 5486.40 | backward-params-all-reduce: 52.04 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 80.03 | batch-generator: 12.01
 iteration      600/    1000 | consumed samples:       307200 | elapsed time per iteration (ms): 7716.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154675E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2090.29 | backward-compute: 5486.92 | backward-params-all-reduce: 52.27 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.26 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.07 | batch-generator: 11.99
-----------------------------------------------------------------------------------------------
 validation loss at iteration 600 | lm loss value: 1.155875E-01 | lm loss PPL: 1.122533E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      601/    1000 | consumed samples:       307712 | elapsed time per iteration (ms): 25755.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154428E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20118.94 | backward-compute: 5485.16 | backward-params-all-reduce: 52.07 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.06 | batch-generator: 108.10
 iteration      602/    1000 | consumed samples:       308224 | elapsed time per iteration (ms): 7730.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155146E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.96 | backward-compute: 5484.52 | backward-params-all-reduce: 53.13 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.00 | batch-generator: 11.83
 iteration      603/    1000 | consumed samples:       308736 | elapsed time per iteration (ms): 7726.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154456E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.35 | backward-compute: 5483.32 | backward-params-all-reduce: 52.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.97 | batch-generator: 12.06
 iteration      604/    1000 | consumed samples:       309248 | elapsed time per iteration (ms): 7727.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155191E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.62 | backward-compute: 5486.82 | backward-params-all-reduce: 51.86 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.80 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 80.02 | batch-generator: 12.11
 iteration      605/    1000 | consumed samples:       309760 | elapsed time per iteration (ms): 7727.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154562E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.19 | backward-compute: 5487.78 | backward-params-all-reduce: 53.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.88 | batch-generator: 11.85
 iteration      606/    1000 | consumed samples:       310272 | elapsed time per iteration (ms): 7741.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153500E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.92 | backward-compute: 5489.69 | backward-params-all-reduce: 52.59 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.91 | batch-generator: 12.07
 iteration      607/    1000 | consumed samples:       310784 | elapsed time per iteration (ms): 7750.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155625E-01 | loss scale: 65536.0 | grad norm: 0.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2119.68 | backward-compute: 5491.23 | backward-params-all-reduce: 52.78 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.89 | batch-generator: 12.12
 iteration      608/    1000 | consumed samples:       311296 | elapsed time per iteration (ms): 7748.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154996E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.93 | backward-compute: 5487.93 | backward-params-all-reduce: 52.68 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.71 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 79.81 | batch-generator: 11.85
 iteration      609/    1000 | consumed samples:       311808 | elapsed time per iteration (ms): 7754.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154881E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2124.48 | backward-compute: 5488.55 | backward-params-all-reduce: 54.21 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.95 | batch-generator: 12.55
 iteration      610/    1000 | consumed samples:       312320 | elapsed time per iteration (ms): 7756.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154484E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2127.59 | backward-compute: 5488.39 | backward-params-all-reduce: 53.31 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.05 | batch-generator: 12.22
-----------------------------------------------------------------------------------------------
 validation loss at iteration 610 | lm loss value: 1.156201E-01 | lm loss PPL: 1.122569E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      611/    1000 | consumed samples:       312832 | elapsed time per iteration (ms): 25885.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155133E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20245.35 | backward-compute: 5488.43 | backward-params-all-reduce: 52.22 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.92 | batch-generator: 122.36
 iteration      612/    1000 | consumed samples:       313344 | elapsed time per iteration (ms): 7739.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154473E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.38 | backward-compute: 5488.25 | backward-params-all-reduce: 52.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.94 | batch-generator: 12.13
 iteration      613/    1000 | consumed samples:       313856 | elapsed time per iteration (ms): 7737.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154881E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.42 | backward-compute: 5484.97 | backward-params-all-reduce: 53.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.94 | batch-generator: 11.83
 iteration      614/    1000 | consumed samples:       314368 | elapsed time per iteration (ms): 7736.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154626E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.89 | backward-compute: 5485.47 | backward-params-all-reduce: 52.79 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.93 | batch-generator: 12.34
 iteration      615/    1000 | consumed samples:       314880 | elapsed time per iteration (ms): 7733.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155068E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.28 | backward-compute: 5484.42 | backward-params-all-reduce: 52.38 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.98 | batch-generator: 11.98
 iteration      616/    1000 | consumed samples:       315392 | elapsed time per iteration (ms): 7731.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154079E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.73 | backward-compute: 5486.92 | backward-params-all-reduce: 51.92 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.98 | batch-generator: 12.01
 iteration      617/    1000 | consumed samples:       315904 | elapsed time per iteration (ms): 7730.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154445E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.53 | backward-compute: 5485.99 | backward-params-all-reduce: 52.35 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.87 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.10 | batch-generator: 12.06
 iteration      618/    1000 | consumed samples:       316416 | elapsed time per iteration (ms): 7735.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155136E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.19 | backward-compute: 5485.79 | backward-params-all-reduce: 52.09 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.03 | batch-generator: 12.03
 iteration      619/    1000 | consumed samples:       316928 | elapsed time per iteration (ms): 7730.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154729E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.60 | backward-compute: 5482.94 | backward-params-all-reduce: 52.66 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.03 | batch-generator: 12.53
 iteration      620/    1000 | consumed samples:       317440 | elapsed time per iteration (ms): 7729.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154740E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.03 | backward-compute: 5487.05 | backward-params-all-reduce: 52.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.85 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 80.28 | batch-generator: 12.22
-----------------------------------------------------------------------------------------------
 validation loss at iteration 620 | lm loss value: 1.155654E-01 | lm loss PPL: 1.122508E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      621/    1000 | consumed samples:       317952 | elapsed time per iteration (ms): 25801.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154380E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20164.02 | backward-compute: 5485.76 | backward-params-all-reduce: 52.25 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.03 | batch-generator: 121.88
 iteration      622/    1000 | consumed samples:       318464 | elapsed time per iteration (ms): 7723.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155020E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.94 | backward-compute: 5483.73 | backward-params-all-reduce: 52.88 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.07 | batch-generator: 12.40
 iteration      623/    1000 | consumed samples:       318976 | elapsed time per iteration (ms): 7727.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154923E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.76 | backward-compute: 5483.54 | backward-params-all-reduce: 51.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.94 | batch-generator: 12.34
 iteration      624/    1000 | consumed samples:       319488 | elapsed time per iteration (ms): 7732.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155266E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.03 | backward-compute: 5486.30 | backward-params-all-reduce: 52.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.97 | batch-generator: 12.30
 iteration      625/    1000 | consumed samples:       320000 | elapsed time per iteration (ms): 7729.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154824E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.27 | backward-compute: 5486.74 | backward-params-all-reduce: 52.13 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.01 | batch-generator: 12.36
 iteration      626/    1000 | consumed samples:       320512 | elapsed time per iteration (ms): 7726.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155069E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.03 | backward-compute: 5486.53 | backward-params-all-reduce: 52.45 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.92 | batch-generator: 12.54
 iteration      627/    1000 | consumed samples:       321024 | elapsed time per iteration (ms): 7730.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154384E-01 | loss scale: 65536.0 | grad norm: 0.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.13 | backward-compute: 5481.50 | backward-params-all-reduce: 52.27 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.01 | batch-generator: 12.06
 iteration      628/    1000 | consumed samples:       321536 | elapsed time per iteration (ms): 7731.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154044E-01 | loss scale: 65536.0 | grad norm: 0.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.77 | backward-compute: 5484.04 | backward-params-all-reduce: 51.91 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.69 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.86 | batch-generator: 12.38
 iteration      629/    1000 | consumed samples:       322048 | elapsed time per iteration (ms): 7734.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155495E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.26 | backward-compute: 5482.92 | backward-params-all-reduce: 52.42 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.97 | batch-generator: 12.08
 iteration      630/    1000 | consumed samples:       322560 | elapsed time per iteration (ms): 7730.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155436E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.11 | backward-compute: 5483.82 | backward-params-all-reduce: 52.09 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.79 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.05 | batch-generator: 12.22
-----------------------------------------------------------------------------------------------
 validation loss at iteration 630 | lm loss value: 1.155637E-01 | lm loss PPL: 1.122506E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      631/    1000 | consumed samples:       323072 | elapsed time per iteration (ms): 25802.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155947E-01 | loss scale: 65536.0 | grad norm: 0.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20165.63 | backward-compute: 5485.95 | backward-params-all-reduce: 51.50 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.98 | batch-generator: 113.95
 iteration      632/    1000 | consumed samples:       323584 | elapsed time per iteration (ms): 7728.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154295E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.87 | backward-compute: 5484.53 | backward-params-all-reduce: 52.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.85 | batch-generator: 12.11
 iteration      633/    1000 | consumed samples:       324096 | elapsed time per iteration (ms): 7726.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153936E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.07 | backward-compute: 5485.82 | backward-params-all-reduce: 51.89 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.90 | batch-generator: 12.28
 iteration      634/    1000 | consumed samples:       324608 | elapsed time per iteration (ms): 7730.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155279E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.39 | backward-compute: 5487.06 | backward-params-all-reduce: 51.62 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 80.06 | batch-generator: 12.02
 iteration      635/    1000 | consumed samples:       325120 | elapsed time per iteration (ms): 7728.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154966E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.00 | backward-compute: 5491.32 | backward-params-all-reduce: 51.81 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.85 | batch-generator: 12.02
 iteration      636/    1000 | consumed samples:       325632 | elapsed time per iteration (ms): 7725.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155927E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.57 | backward-compute: 5485.96 | backward-params-all-reduce: 52.15 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.89 | batch-generator: 12.29
 iteration      637/    1000 | consumed samples:       326144 | elapsed time per iteration (ms): 7730.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155474E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.23 | backward-compute: 5486.76 | backward-params-all-reduce: 52.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.71 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.97 | batch-generator: 11.95
 iteration      638/    1000 | consumed samples:       326656 | elapsed time per iteration (ms): 7734.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154690E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.35 | backward-compute: 5487.32 | backward-params-all-reduce: 51.86 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.90 | batch-generator: 12.14
 iteration      639/    1000 | consumed samples:       327168 | elapsed time per iteration (ms): 7734.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154756E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.21 | backward-compute: 5484.58 | backward-params-all-reduce: 52.60 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.95 | batch-generator: 12.64
 iteration      640/    1000 | consumed samples:       327680 | elapsed time per iteration (ms): 7733.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154675E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.62 | backward-compute: 5487.83 | backward-params-all-reduce: 52.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.04 | batch-generator: 12.10
-----------------------------------------------------------------------------------------------
 validation loss at iteration 640 | lm loss value: 1.155803E-01 | lm loss PPL: 1.122525E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      641/    1000 | consumed samples:       328192 | elapsed time per iteration (ms): 25838.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155577E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20198.36 | backward-compute: 5488.30 | backward-params-all-reduce: 53.15 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.93 | batch-generator: 106.91
 iteration      642/    1000 | consumed samples:       328704 | elapsed time per iteration (ms): 7736.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153823E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.03 | backward-compute: 5487.84 | backward-params-all-reduce: 52.04 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.92 | batch-generator: 12.06
 iteration      643/    1000 | consumed samples:       329216 | elapsed time per iteration (ms): 7733.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155336E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.58 | backward-compute: 5487.47 | backward-params-all-reduce: 52.78 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.98 | batch-generator: 11.84
 iteration      644/    1000 | consumed samples:       329728 | elapsed time per iteration (ms): 7733.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154732E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.86 | backward-compute: 5485.95 | backward-params-all-reduce: 53.69 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.95 | batch-generator: 11.87
 iteration      645/    1000 | consumed samples:       330240 | elapsed time per iteration (ms): 7734.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154977E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.50 | backward-compute: 5486.13 | backward-params-all-reduce: 51.84 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.84 | optimizer: 80.12 | batch-generator: 11.97
 iteration      646/    1000 | consumed samples:       330752 | elapsed time per iteration (ms): 7733.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154469E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.17 | backward-compute: 5487.81 | backward-params-all-reduce: 52.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.89 | batch-generator: 11.85
 iteration      647/    1000 | consumed samples:       331264 | elapsed time per iteration (ms): 7729.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154845E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.70 | backward-compute: 5487.79 | backward-params-all-reduce: 52.52 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.99 | batch-generator: 11.83
 iteration      648/    1000 | consumed samples:       331776 | elapsed time per iteration (ms): 7730.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154817E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.77 | backward-compute: 5491.35 | backward-params-all-reduce: 51.76 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.98 | batch-generator: 11.92
 iteration      649/    1000 | consumed samples:       332288 | elapsed time per iteration (ms): 7735.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154017E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.73 | backward-compute: 5488.05 | backward-params-all-reduce: 52.50 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.07 | batch-generator: 12.15
 iteration      650/    1000 | consumed samples:       332800 | elapsed time per iteration (ms): 7735.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154923E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.64 | backward-compute: 5486.05 | backward-params-all-reduce: 53.34 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.12 | batch-generator: 12.13
-----------------------------------------------------------------------------------------------
 validation loss at iteration 650 | lm loss value: 1.155551E-01 | lm loss PPL: 1.122496E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      651/    1000 | consumed samples:       333312 | elapsed time per iteration (ms): 25833.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154197E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20195.55 | backward-compute: 5486.04 | backward-params-all-reduce: 52.39 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.94 | batch-generator: 106.96
 iteration      652/    1000 | consumed samples:       333824 | elapsed time per iteration (ms): 7733.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154080E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.85 | backward-compute: 5485.51 | backward-params-all-reduce: 53.15 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.95 | batch-generator: 11.75
 iteration      653/    1000 | consumed samples:       334336 | elapsed time per iteration (ms): 7729.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156219E-01 | loss scale: 65536.0 | grad norm: 0.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.06 | backward-compute: 5486.44 | backward-params-all-reduce: 52.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.93 | batch-generator: 11.91
 iteration      654/    1000 | consumed samples:       334848 | elapsed time per iteration (ms): 7733.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155001E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.50 | backward-compute: 5487.39 | backward-params-all-reduce: 51.90 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.98 | batch-generator: 12.10
 iteration      655/    1000 | consumed samples:       335360 | elapsed time per iteration (ms): 7727.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154469E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.97 | backward-compute: 5487.61 | backward-params-all-reduce: 51.93 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.94 | batch-generator: 11.97
 iteration      656/    1000 | consumed samples:       335872 | elapsed time per iteration (ms): 7730.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154338E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.41 | backward-compute: 5486.52 | backward-params-all-reduce: 52.88 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.85 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 80.15 | batch-generator: 11.86
 iteration      657/    1000 | consumed samples:       336384 | elapsed time per iteration (ms): 7738.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154238E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.43 | backward-compute: 5486.44 | backward-params-all-reduce: 53.36 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.97 | batch-generator: 11.93
 iteration      658/    1000 | consumed samples:       336896 | elapsed time per iteration (ms): 7732.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155630E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.86 | backward-compute: 5486.60 | backward-params-all-reduce: 52.27 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.90 | batch-generator: 12.01
 iteration      659/    1000 | consumed samples:       337408 | elapsed time per iteration (ms): 7736.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156034E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.91 | backward-compute: 5484.70 | backward-params-all-reduce: 52.89 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.96 | optimizer: 81.19 | batch-generator: 11.78
 iteration      660/    1000 | consumed samples:       337920 | elapsed time per iteration (ms): 7731.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154630E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.94 | backward-compute: 5487.36 | backward-params-all-reduce: 52.35 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.19 | batch-generator: 12.25
-----------------------------------------------------------------------------------------------
 validation loss at iteration 660 | lm loss value: 1.155640E-01 | lm loss PPL: 1.122506E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      661/    1000 | consumed samples:       338432 | elapsed time per iteration (ms): 25833.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155611E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20194.85 | backward-compute: 5487.67 | backward-params-all-reduce: 52.43 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.82 | batch-generator: 107.63
 iteration      662/    1000 | consumed samples:       338944 | elapsed time per iteration (ms): 7735.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154346E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.72 | backward-compute: 5486.05 | backward-params-all-reduce: 52.30 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 80.10 | batch-generator: 11.90
 iteration      663/    1000 | consumed samples:       339456 | elapsed time per iteration (ms): 7731.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156112E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.24 | backward-compute: 5487.09 | backward-params-all-reduce: 51.87 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.05 | batch-generator: 11.90
 iteration      664/    1000 | consumed samples:       339968 | elapsed time per iteration (ms): 7733.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154323E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.66 | backward-compute: 5486.08 | backward-params-all-reduce: 52.45 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.95 | batch-generator: 12.02
 iteration      665/    1000 | consumed samples:       340480 | elapsed time per iteration (ms): 7732.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154235E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.23 | backward-compute: 5485.61 | backward-params-all-reduce: 53.07 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.92 | batch-generator: 12.04
 iteration      666/    1000 | consumed samples:       340992 | elapsed time per iteration (ms): 7731.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154585E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.14 | backward-compute: 5484.38 | backward-params-all-reduce: 52.21 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 79.88 | batch-generator: 12.00
 iteration      667/    1000 | consumed samples:       341504 | elapsed time per iteration (ms): 7732.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155057E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.35 | backward-compute: 5483.78 | backward-params-all-reduce: 52.87 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.81 | batch-generator: 12.11
 iteration      668/    1000 | consumed samples:       342016 | elapsed time per iteration (ms): 7735.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155733E-01 | loss scale: 65536.0 | grad norm: 0.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.34 | backward-compute: 5486.41 | backward-params-all-reduce: 51.95 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.00 | batch-generator: 11.93
 iteration      669/    1000 | consumed samples:       342528 | elapsed time per iteration (ms): 7733.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153783E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.27 | backward-compute: 5484.40 | backward-params-all-reduce: 52.56 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.85 | batch-generator: 11.84
 iteration      670/    1000 | consumed samples:       343040 | elapsed time per iteration (ms): 7733.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153356E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.50 | backward-compute: 5484.64 | backward-params-all-reduce: 52.29 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.95 | batch-generator: 12.05
-----------------------------------------------------------------------------------------------
 validation loss at iteration 670 | lm loss value: 1.155638E-01 | lm loss PPL: 1.122506E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      671/    1000 | consumed samples:       343552 | elapsed time per iteration (ms): 25846.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154568E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20207.03 | backward-compute: 5485.37 | backward-params-all-reduce: 54.92 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.07 | batch-generator: 106.86
 iteration      672/    1000 | consumed samples:       344064 | elapsed time per iteration (ms): 7737.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154740E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.56 | backward-compute: 5482.34 | backward-params-all-reduce: 54.32 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.00 | batch-generator: 11.88
 iteration      673/    1000 | consumed samples:       344576 | elapsed time per iteration (ms): 7737.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153862E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.93 | backward-compute: 5479.38 | backward-params-all-reduce: 54.95 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.10 | batch-generator: 11.97
 iteration      674/    1000 | consumed samples:       345088 | elapsed time per iteration (ms): 7734.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155676E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.22 | backward-compute: 5485.53 | backward-params-all-reduce: 54.47 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.09 | batch-generator: 12.06
 iteration      675/    1000 | consumed samples:       345600 | elapsed time per iteration (ms): 7740.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154850E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.87 | backward-compute: 5485.84 | backward-params-all-reduce: 54.52 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.91 | batch-generator: 12.27
 iteration      676/    1000 | consumed samples:       346112 | elapsed time per iteration (ms): 7741.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156254E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.27 | backward-compute: 5487.20 | backward-params-all-reduce: 54.63 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.90 | batch-generator: 12.17
 iteration      677/    1000 | consumed samples:       346624 | elapsed time per iteration (ms): 7737.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153842E-01 | loss scale: 65536.0 | grad norm: 0.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.12 | backward-compute: 5485.07 | backward-params-all-reduce: 53.44 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.02 | batch-generator: 12.17
 iteration      678/    1000 | consumed samples:       347136 | elapsed time per iteration (ms): 7734.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155343E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.35 | backward-compute: 5483.72 | backward-params-all-reduce: 54.32 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.82 | optimizer: 80.05 | batch-generator: 12.57
 iteration      679/    1000 | consumed samples:       347648 | elapsed time per iteration (ms): 7736.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155287E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.45 | backward-compute: 5483.49 | backward-params-all-reduce: 54.64 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.03 | batch-generator: 12.22
 iteration      680/    1000 | consumed samples:       348160 | elapsed time per iteration (ms): 7740.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155400E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.71 | backward-compute: 5484.01 | backward-params-all-reduce: 54.54 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.97 | batch-generator: 12.02
-----------------------------------------------------------------------------------------------
 validation loss at iteration 680 | lm loss value: 1.155575E-01 | lm loss PPL: 1.122499E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      681/    1000 | consumed samples:       348672 | elapsed time per iteration (ms): 25837.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155863E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20198.30 | backward-compute: 5485.19 | backward-params-all-reduce: 54.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 79.99 | batch-generator: 107.83
 iteration      682/    1000 | consumed samples:       349184 | elapsed time per iteration (ms): 7735.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155323E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.88 | backward-compute: 5483.27 | backward-params-all-reduce: 54.10 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.06 | batch-generator: 11.99
 iteration      683/    1000 | consumed samples:       349696 | elapsed time per iteration (ms): 7739.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154666E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.76 | backward-compute: 5486.86 | backward-params-all-reduce: 54.30 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.02 | batch-generator: 12.07
 iteration      684/    1000 | consumed samples:       350208 | elapsed time per iteration (ms): 7736.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154689E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.53 | backward-compute: 5483.20 | backward-params-all-reduce: 54.52 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.06 | batch-generator: 12.22
 iteration      685/    1000 | consumed samples:       350720 | elapsed time per iteration (ms): 7737.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154114E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2113.85 | backward-compute: 5482.87 | backward-params-all-reduce: 54.20 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.96 | batch-generator: 11.98
 iteration      686/    1000 | consumed samples:       351232 | elapsed time per iteration (ms): 7742.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156225E-01 | loss scale: 65536.0 | grad norm: 0.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.90 | backward-compute: 5484.34 | backward-params-all-reduce: 54.45 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.09 | batch-generator: 12.75
 iteration      687/    1000 | consumed samples:       351744 | elapsed time per iteration (ms): 7736.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155163E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.50 | backward-compute: 5484.02 | backward-params-all-reduce: 54.21 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.85 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 80.31 | batch-generator: 12.39
 iteration      688/    1000 | consumed samples:       352256 | elapsed time per iteration (ms): 7743.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154709E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.21 | backward-compute: 5483.65 | backward-params-all-reduce: 54.55 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.96 | batch-generator: 11.91
 iteration      689/    1000 | consumed samples:       352768 | elapsed time per iteration (ms): 7736.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155492E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.59 | backward-compute: 5483.86 | backward-params-all-reduce: 55.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.03 | batch-generator: 12.05
 iteration      690/    1000 | consumed samples:       353280 | elapsed time per iteration (ms): 7748.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153238E-01 | loss scale: 65536.0 | grad norm: 0.051 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.05 | backward-compute: 5485.19 | backward-params-all-reduce: 67.79 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.26 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.03 | batch-generator: 12.13
-----------------------------------------------------------------------------------------------
 validation loss at iteration 690 | lm loss value: 1.155877E-01 | lm loss PPL: 1.122533E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      691/    1000 | consumed samples:       353792 | elapsed time per iteration (ms): 25825.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154220E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20190.22 | backward-compute: 5481.99 | backward-params-all-reduce: 54.43 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 79.91 | batch-generator: 108.33
 iteration      692/    1000 | consumed samples:       354304 | elapsed time per iteration (ms): 7733.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.152805E-01 | loss scale: 65536.0 | grad norm: 0.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.57 | backward-compute: 5484.00 | backward-params-all-reduce: 54.65 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.09 | batch-generator: 12.25
 iteration      693/    1000 | consumed samples:       354816 | elapsed time per iteration (ms): 7736.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156174E-01 | loss scale: 65536.0 | grad norm: 0.059 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.85 | backward-compute: 5482.80 | backward-params-all-reduce: 54.22 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.77 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.09 | batch-generator: 12.22
 iteration      694/    1000 | consumed samples:       355328 | elapsed time per iteration (ms): 7736.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155340E-01 | loss scale: 65536.0 | grad norm: 0.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.19 | backward-compute: 5490.26 | backward-params-all-reduce: 54.28 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.02 | batch-generator: 12.26
 iteration      695/    1000 | consumed samples:       355840 | elapsed time per iteration (ms): 7735.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155114E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.01 | backward-compute: 5485.73 | backward-params-all-reduce: 54.13 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.07 | batch-generator: 12.23
 iteration      696/    1000 | consumed samples:       356352 | elapsed time per iteration (ms): 7733.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155989E-01 | loss scale: 65536.0 | grad norm: 0.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.70 | backward-compute: 5485.07 | backward-params-all-reduce: 54.52 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.19 | batch-generator: 12.44
 iteration      697/    1000 | consumed samples:       356864 | elapsed time per iteration (ms): 7736.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153857E-01 | loss scale: 65536.0 | grad norm: 0.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.63 | backward-compute: 5486.03 | backward-params-all-reduce: 54.38 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.11 | batch-generator: 12.46
 iteration      698/    1000 | consumed samples:       357376 | elapsed time per iteration (ms): 7738.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154497E-01 | loss scale: 65536.0 | grad norm: 0.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.25 | backward-compute: 5486.51 | backward-params-all-reduce: 54.22 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 8.82 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.03 | batch-generator: 12.21
 iteration      699/    1000 | consumed samples:       357888 | elapsed time per iteration (ms): 7738.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154746E-01 | loss scale: 65536.0 | grad norm: 0.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.97 | backward-compute: 5485.73 | backward-params-all-reduce: 54.40 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.10 | batch-generator: 12.14
 iteration      700/    1000 | consumed samples:       358400 | elapsed time per iteration (ms): 7732.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154731E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.01 | backward-compute: 5485.44 | backward-params-all-reduce: 54.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.97 | batch-generator: 12.27
-----------------------------------------------------------------------------------------------
 validation loss at iteration 700 | lm loss value: 1.156014E-01 | lm loss PPL: 1.122548E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      701/    1000 | consumed samples:       358912 | elapsed time per iteration (ms): 25825.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155640E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20188.21 | backward-compute: 5485.12 | backward-params-all-reduce: 52.38 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.05 | batch-generator: 112.15
 iteration      702/    1000 | consumed samples:       359424 | elapsed time per iteration (ms): 7733.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156002E-01 | loss scale: 65536.0 | grad norm: 0.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.57 | backward-compute: 5486.91 | backward-params-all-reduce: 52.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.13 | batch-generator: 12.21
 iteration      703/    1000 | consumed samples:       359936 | elapsed time per iteration (ms): 7734.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154672E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.65 | backward-compute: 5487.04 | backward-params-all-reduce: 52.45 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.00 | batch-generator: 12.09
 iteration      704/    1000 | consumed samples:       360448 | elapsed time per iteration (ms): 7736.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154042E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.66 | backward-compute: 5491.61 | backward-params-all-reduce: 52.04 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.92 | batch-generator: 12.67
 iteration      705/    1000 | consumed samples:       360960 | elapsed time per iteration (ms): 7735.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156806E-01 | loss scale: 65536.0 | grad norm: 0.055 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.01 | backward-compute: 5491.87 | backward-params-all-reduce: 52.27 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.08 | batch-generator: 12.39
 iteration      706/    1000 | consumed samples:       361472 | elapsed time per iteration (ms): 7735.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155544E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.49 | backward-compute: 5485.00 | backward-params-all-reduce: 52.37 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 80.15 | batch-generator: 12.13
 iteration      707/    1000 | consumed samples:       361984 | elapsed time per iteration (ms): 7734.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155558E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.22 | backward-compute: 5486.84 | backward-params-all-reduce: 52.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.99 | batch-generator: 12.73
 iteration      708/    1000 | consumed samples:       362496 | elapsed time per iteration (ms): 7732.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155312E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.26 | backward-compute: 5485.25 | backward-params-all-reduce: 52.53 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.82 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.23 | batch-generator: 12.62
 iteration      709/    1000 | consumed samples:       363008 | elapsed time per iteration (ms): 7732.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154633E-01 | loss scale: 65536.0 | grad norm: 0.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.01 | backward-compute: 5484.93 | backward-params-all-reduce: 53.46 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.18 | batch-generator: 12.03
 iteration      710/    1000 | consumed samples:       363520 | elapsed time per iteration (ms): 7731.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156293E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.03 | backward-compute: 5485.72 | backward-params-all-reduce: 52.72 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.98 | batch-generator: 12.04
-----------------------------------------------------------------------------------------------
 validation loss at iteration 710 | lm loss value: 1.155764E-01 | lm loss PPL: 1.122520E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      711/    1000 | consumed samples:       364032 | elapsed time per iteration (ms): 25846.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154711E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20207.84 | backward-compute: 5486.88 | backward-params-all-reduce: 52.80 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.99 | batch-generator: 111.44
 iteration      712/    1000 | consumed samples:       364544 | elapsed time per iteration (ms): 7731.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155323E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.32 | backward-compute: 5486.00 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.86 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.93 | optimizer: 80.46 | batch-generator: 12.06
 iteration      713/    1000 | consumed samples:       365056 | elapsed time per iteration (ms): 7733.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154967E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.26 | backward-compute: 5484.71 | backward-params-all-reduce: 52.94 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.92 | batch-generator: 12.15
 iteration      714/    1000 | consumed samples:       365568 | elapsed time per iteration (ms): 7729.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155892E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.81 | backward-compute: 5485.01 | backward-params-all-reduce: 52.50 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.11 | batch-generator: 12.32
 iteration      715/    1000 | consumed samples:       366080 | elapsed time per iteration (ms): 7730.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154726E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.87 | backward-compute: 5488.50 | backward-params-all-reduce: 52.27 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.86 | batch-generator: 12.31
 iteration      716/    1000 | consumed samples:       366592 | elapsed time per iteration (ms): 7732.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155399E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.40 | backward-compute: 5486.53 | backward-params-all-reduce: 52.35 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.05 | batch-generator: 12.48
 iteration      717/    1000 | consumed samples:       367104 | elapsed time per iteration (ms): 7732.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155221E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.80 | backward-compute: 5487.05 | backward-params-all-reduce: 51.70 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.93 | batch-generator: 12.37
 iteration      718/    1000 | consumed samples:       367616 | elapsed time per iteration (ms): 7731.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154485E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.93 | backward-compute: 5488.21 | backward-params-all-reduce: 52.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.06 | batch-generator: 12.40
 iteration      719/    1000 | consumed samples:       368128 | elapsed time per iteration (ms): 7731.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154156E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.89 | backward-compute: 5485.55 | backward-params-all-reduce: 51.67 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.95 | batch-generator: 12.25
 iteration      720/    1000 | consumed samples:       368640 | elapsed time per iteration (ms): 7736.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155545E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.41 | backward-compute: 5484.95 | backward-params-all-reduce: 52.13 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.01 | batch-generator: 12.68
-----------------------------------------------------------------------------------------------
 validation loss at iteration 720 | lm loss value: 1.155643E-01 | lm loss PPL: 1.122507E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      721/    1000 | consumed samples:       369152 | elapsed time per iteration (ms): 25846.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155134E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20204.94 | backward-compute: 5487.72 | backward-params-all-reduce: 52.40 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.97 | optimizer: 81.84 | batch-generator: 111.92
 iteration      722/    1000 | consumed samples:       369664 | elapsed time per iteration (ms): 7730.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155385E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.09 | backward-compute: 5487.75 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.95 | batch-generator: 12.56
 iteration      723/    1000 | consumed samples:       370176 | elapsed time per iteration (ms): 7734.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155476E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.11 | backward-compute: 5488.08 | backward-params-all-reduce: 52.69 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.04 | batch-generator: 12.60
 iteration      724/    1000 | consumed samples:       370688 | elapsed time per iteration (ms): 7736.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155313E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.97 | backward-compute: 5483.49 | backward-params-all-reduce: 53.36 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.01 | batch-generator: 12.25
 iteration      725/    1000 | consumed samples:       371200 | elapsed time per iteration (ms): 7735.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156175E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.19 | backward-compute: 5488.01 | backward-params-all-reduce: 52.18 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.04 | batch-generator: 12.35
 iteration      726/    1000 | consumed samples:       371712 | elapsed time per iteration (ms): 7731.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154917E-01 | loss scale: 65536.0 | grad norm: 0.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.72 | backward-compute: 5487.07 | backward-params-all-reduce: 51.97 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.10 | batch-generator: 12.46
 iteration      727/    1000 | consumed samples:       372224 | elapsed time per iteration (ms): 7732.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155009E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.01 | backward-compute: 5485.39 | backward-params-all-reduce: 52.44 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 79.93 | batch-generator: 12.42
 iteration      728/    1000 | consumed samples:       372736 | elapsed time per iteration (ms): 7731.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155451E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.09 | backward-compute: 5487.61 | backward-params-all-reduce: 52.39 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.27 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.06 | batch-generator: 12.38
 iteration      729/    1000 | consumed samples:       373248 | elapsed time per iteration (ms): 7730.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154390E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.68 | backward-compute: 5487.24 | backward-params-all-reduce: 51.95 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.04 | batch-generator: 12.44
 iteration      730/    1000 | consumed samples:       373760 | elapsed time per iteration (ms): 7733.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156055E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.25 | backward-compute: 5483.83 | backward-params-all-reduce: 52.36 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.07 | batch-generator: 12.24
-----------------------------------------------------------------------------------------------
 validation loss at iteration 730 | lm loss value: 1.156061E-01 | lm loss PPL: 1.122554E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      731/    1000 | consumed samples:       374272 | elapsed time per iteration (ms): 25834.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154993E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20198.50 | backward-compute: 5482.79 | backward-params-all-reduce: 52.06 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.02 | batch-generator: 111.61
 iteration      732/    1000 | consumed samples:       374784 | elapsed time per iteration (ms): 7734.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154524E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.94 | backward-compute: 5485.79 | backward-params-all-reduce: 51.91 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.80 | optimizer: 80.11 | batch-generator: 12.34
 iteration      733/    1000 | consumed samples:       375296 | elapsed time per iteration (ms): 7732.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155054E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.65 | backward-compute: 5484.34 | backward-params-all-reduce: 52.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.98 | batch-generator: 12.60
 iteration      734/    1000 | consumed samples:       375808 | elapsed time per iteration (ms): 7734.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154250E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.19 | backward-compute: 5485.38 | backward-params-all-reduce: 52.96 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.87 | optimizer: 80.13 | batch-generator: 12.45
 iteration      735/    1000 | consumed samples:       376320 | elapsed time per iteration (ms): 7733.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.157195E-01 | loss scale: 65536.0 | grad norm: 0.058 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.47 | backward-compute: 5485.43 | backward-params-all-reduce: 52.04 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.91 | batch-generator: 12.23
 iteration      736/    1000 | consumed samples:       376832 | elapsed time per iteration (ms): 7733.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155060E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.34 | backward-compute: 5486.96 | backward-params-all-reduce: 52.49 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.05 | batch-generator: 12.46
 iteration      737/    1000 | consumed samples:       377344 | elapsed time per iteration (ms): 7738.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154938E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.74 | backward-compute: 5486.48 | backward-params-all-reduce: 52.67 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.99 | batch-generator: 12.34
 iteration      738/    1000 | consumed samples:       377856 | elapsed time per iteration (ms): 7737.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155080E-01 | loss scale: 65536.0 | grad norm: 0.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.89 | backward-compute: 5489.28 | backward-params-all-reduce: 52.39 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.07 | batch-generator: 12.23
 iteration      739/    1000 | consumed samples:       378368 | elapsed time per iteration (ms): 7739.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155510E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.48 | backward-compute: 5491.40 | backward-params-all-reduce: 51.99 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.71 | optimizer: 80.01 | batch-generator: 12.56
 iteration      740/    1000 | consumed samples:       378880 | elapsed time per iteration (ms): 7729.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154458E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.33 | backward-compute: 5485.34 | backward-params-all-reduce: 52.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.06 | batch-generator: 12.18
-----------------------------------------------------------------------------------------------
 validation loss at iteration 740 | lm loss value: 1.155627E-01 | lm loss PPL: 1.122505E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      741/    1000 | consumed samples:       379392 | elapsed time per iteration (ms): 25824.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155650E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20187.02 | backward-compute: 5485.99 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.95 | batch-generator: 112.27
 iteration      742/    1000 | consumed samples:       379904 | elapsed time per iteration (ms): 7736.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154371E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.52 | backward-compute: 5485.40 | backward-params-all-reduce: 52.37 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.10 | batch-generator: 12.64
 iteration      743/    1000 | consumed samples:       380416 | elapsed time per iteration (ms): 7729.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154198E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.61 | backward-compute: 5486.97 | backward-params-all-reduce: 51.75 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.84 | optimizer: 80.11 | batch-generator: 12.47
 iteration      744/    1000 | consumed samples:       380928 | elapsed time per iteration (ms): 7732.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155357E-01 | loss scale: 65536.0 | grad norm: 0.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.48 | backward-compute: 5486.27 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.09 | batch-generator: 12.42
 iteration      745/    1000 | consumed samples:       381440 | elapsed time per iteration (ms): 7733.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154645E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.16 | backward-compute: 5487.11 | backward-params-all-reduce: 52.22 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.96 | batch-generator: 12.36
 iteration      746/    1000 | consumed samples:       381952 | elapsed time per iteration (ms): 7730.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154973E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.40 | backward-compute: 5486.45 | backward-params-all-reduce: 52.50 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.05 | batch-generator: 12.28
 iteration      747/    1000 | consumed samples:       382464 | elapsed time per iteration (ms): 7731.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153569E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.92 | backward-compute: 5487.21 | backward-params-all-reduce: 51.92 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.16 | batch-generator: 12.27
 iteration      748/    1000 | consumed samples:       382976 | elapsed time per iteration (ms): 7730.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154552E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.40 | backward-compute: 5485.08 | backward-params-all-reduce: 52.97 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.01 | batch-generator: 12.63
 iteration      749/    1000 | consumed samples:       383488 | elapsed time per iteration (ms): 7727.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156000E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.63 | backward-compute: 5487.15 | backward-params-all-reduce: 51.97 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.07 | batch-generator: 12.26
 iteration      750/    1000 | consumed samples:       384000 | elapsed time per iteration (ms): 7725.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154468E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.36 | backward-compute: 5484.74 | backward-params-all-reduce: 52.36 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.09 | batch-generator: 12.11
-----------------------------------------------------------------------------------------------
 validation loss at iteration 750 | lm loss value: 1.155300E-01 | lm loss PPL: 1.122468E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      751/    1000 | consumed samples:       384512 | elapsed time per iteration (ms): 25818.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156029E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20182.46 | backward-compute: 5483.71 | backward-params-all-reduce: 52.79 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.78 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.16 | batch-generator: 111.44
 iteration      752/    1000 | consumed samples:       385024 | elapsed time per iteration (ms): 7732.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155334E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.77 | backward-compute: 5485.57 | backward-params-all-reduce: 53.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.10 | batch-generator: 12.19
 iteration      753/    1000 | consumed samples:       385536 | elapsed time per iteration (ms): 7727.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154144E-01 | loss scale: 65536.0 | grad norm: 0.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.29 | backward-compute: 5484.17 | backward-params-all-reduce: 52.70 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.08 | batch-generator: 12.51
 iteration      754/    1000 | consumed samples:       386048 | elapsed time per iteration (ms): 7733.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154961E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.92 | backward-compute: 5486.39 | backward-params-all-reduce: 51.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.17 | batch-generator: 12.41
 iteration      755/    1000 | consumed samples:       386560 | elapsed time per iteration (ms): 7734.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154725E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.73 | backward-compute: 5488.97 | backward-params-all-reduce: 52.64 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.11 | batch-generator: 12.24
 iteration      756/    1000 | consumed samples:       387072 | elapsed time per iteration (ms): 7728.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154883E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.12 | backward-compute: 5483.50 | backward-params-all-reduce: 52.43 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.11 | batch-generator: 12.27
 iteration      757/    1000 | consumed samples:       387584 | elapsed time per iteration (ms): 7734.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155828E-01 | loss scale: 65536.0 | grad norm: 0.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.04 | backward-compute: 5485.85 | backward-params-all-reduce: 52.40 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.08 | batch-generator: 12.37
 iteration      758/    1000 | consumed samples:       388096 | elapsed time per iteration (ms): 7734.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154534E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.64 | backward-compute: 5486.97 | backward-params-all-reduce: 51.97 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.78 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.18 | batch-generator: 12.29
 iteration      759/    1000 | consumed samples:       388608 | elapsed time per iteration (ms): 7737.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154893E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.72 | backward-compute: 5486.55 | backward-params-all-reduce: 53.13 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 80.16 | batch-generator: 12.22
 iteration      760/    1000 | consumed samples:       389120 | elapsed time per iteration (ms): 7735.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154695E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.46 | backward-compute: 5486.98 | backward-params-all-reduce: 51.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.71 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.81 | batch-generator: 12.34
-----------------------------------------------------------------------------------------------
 validation loss at iteration 760 | lm loss value: 1.155647E-01 | lm loss PPL: 1.122507E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      761/    1000 | consumed samples:       389632 | elapsed time per iteration (ms): 25837.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154230E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20197.58 | backward-compute: 5488.20 | backward-params-all-reduce: 52.46 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.07 | batch-generator: 111.29
 iteration      762/    1000 | consumed samples:       390144 | elapsed time per iteration (ms): 7732.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153808E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.06 | backward-compute: 5484.37 | backward-params-all-reduce: 52.39 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.92 | batch-generator: 12.10
 iteration      763/    1000 | consumed samples:       390656 | elapsed time per iteration (ms): 7732.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154658E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.67 | backward-compute: 5486.78 | backward-params-all-reduce: 52.69 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.79 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.13 | batch-generator: 12.34
 iteration      764/    1000 | consumed samples:       391168 | elapsed time per iteration (ms): 7737.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154233E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.89 | backward-compute: 5487.96 | backward-params-all-reduce: 52.53 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.02 | batch-generator: 12.28
 iteration      765/    1000 | consumed samples:       391680 | elapsed time per iteration (ms): 7732.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154969E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.40 | backward-compute: 5488.08 | backward-params-all-reduce: 52.25 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 79.95 | batch-generator: 12.03
 iteration      766/    1000 | consumed samples:       392192 | elapsed time per iteration (ms): 7733.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154621E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.85 | backward-compute: 5486.52 | backward-params-all-reduce: 52.35 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.96 | batch-generator: 12.38
 iteration      767/    1000 | consumed samples:       392704 | elapsed time per iteration (ms): 7731.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154895E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.68 | backward-compute: 5487.08 | backward-params-all-reduce: 51.99 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.93 | batch-generator: 12.44
 iteration      768/    1000 | consumed samples:       393216 | elapsed time per iteration (ms): 7731.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154380E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.62 | backward-compute: 5485.19 | backward-params-all-reduce: 52.22 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.80 | optimizer: 80.02 | batch-generator: 12.20
 iteration      769/    1000 | consumed samples:       393728 | elapsed time per iteration (ms): 7729.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156392E-01 | loss scale: 65536.0 | grad norm: 0.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.05 | backward-compute: 5484.86 | backward-params-all-reduce: 52.45 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.02 | batch-generator: 12.11
 iteration      770/    1000 | consumed samples:       394240 | elapsed time per iteration (ms): 7728.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155943E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.47 | backward-compute: 5485.69 | backward-params-all-reduce: 51.91 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.97 | batch-generator: 12.24
-----------------------------------------------------------------------------------------------
 validation loss at iteration 770 | lm loss value: 1.155792E-01 | lm loss PPL: 1.122523E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      771/    1000 | consumed samples:       394752 | elapsed time per iteration (ms): 25843.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155273E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20205.49 | backward-compute: 5486.88 | backward-params-all-reduce: 51.94 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.98 | batch-generator: 111.77
 iteration      772/    1000 | consumed samples:       395264 | elapsed time per iteration (ms): 7733.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154130E-01 | loss scale: 65536.0 | grad norm: 0.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.22 | backward-compute: 5484.25 | backward-params-all-reduce: 52.83 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.27 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.17 | batch-generator: 12.26
 iteration      773/    1000 | consumed samples:       395776 | elapsed time per iteration (ms): 7739.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155201E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.93 | backward-compute: 5487.00 | backward-params-all-reduce: 52.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.14 | batch-generator: 12.12
 iteration      774/    1000 | consumed samples:       396288 | elapsed time per iteration (ms): 7732.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154530E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.33 | backward-compute: 5486.49 | backward-params-all-reduce: 52.19 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.97 | batch-generator: 12.23
 iteration      775/    1000 | consumed samples:       396800 | elapsed time per iteration (ms): 7730.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156360E-01 | loss scale: 65536.0 | grad norm: 0.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.70 | backward-compute: 5488.66 | backward-params-all-reduce: 51.79 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.60 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.89 | batch-generator: 12.33
 iteration      776/    1000 | consumed samples:       397312 | elapsed time per iteration (ms): 7733.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155525E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.32 | backward-compute: 5486.59 | backward-params-all-reduce: 52.25 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.07 | batch-generator: 12.54
 iteration      777/    1000 | consumed samples:       397824 | elapsed time per iteration (ms): 7731.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154053E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.08 | backward-compute: 5486.19 | backward-params-all-reduce: 52.00 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.11 | batch-generator: 12.31
 iteration      778/    1000 | consumed samples:       398336 | elapsed time per iteration (ms): 7729.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156352E-01 | loss scale: 65536.0 | grad norm: 0.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.42 | backward-compute: 5481.59 | backward-params-all-reduce: 52.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.92 | batch-generator: 12.24
 iteration      779/    1000 | consumed samples:       398848 | elapsed time per iteration (ms): 7738.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153469E-01 | loss scale: 65536.0 | grad norm: 0.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.98 | backward-compute: 5485.54 | backward-params-all-reduce: 52.55 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.14 | batch-generator: 12.29
 iteration      780/    1000 | consumed samples:       399360 | elapsed time per iteration (ms): 7736.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156071E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.87 | backward-compute: 5486.94 | backward-params-all-reduce: 53.31 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.80 | optimizer: 79.98 | batch-generator: 12.16
-----------------------------------------------------------------------------------------------
 validation loss at iteration 780 | lm loss value: 1.155585E-01 | lm loss PPL: 1.122500E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      781/    1000 | consumed samples:       399872 | elapsed time per iteration (ms): 25836.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154967E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20199.01 | backward-compute: 5486.33 | backward-params-all-reduce: 51.90 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.79 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.05 | batch-generator: 111.97
 iteration      782/    1000 | consumed samples:       400384 | elapsed time per iteration (ms): 7727.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156126E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.21 | backward-compute: 5484.25 | backward-params-all-reduce: 52.67 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.61 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.90 | batch-generator: 12.24
 iteration      783/    1000 | consumed samples:       400896 | elapsed time per iteration (ms): 7736.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155360E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.92 | backward-compute: 5485.32 | backward-params-all-reduce: 52.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.97 | optimizer: 81.55 | batch-generator: 12.07
 iteration      784/    1000 | consumed samples:       401408 | elapsed time per iteration (ms): 7732.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155535E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.71 | backward-compute: 5486.36 | backward-params-all-reduce: 51.88 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.04 | batch-generator: 12.29
 iteration      785/    1000 | consumed samples:       401920 | elapsed time per iteration (ms): 7733.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155388E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.99 | backward-compute: 5486.90 | backward-params-all-reduce: 52.66 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.15 | batch-generator: 12.36
 iteration      786/    1000 | consumed samples:       402432 | elapsed time per iteration (ms): 7726.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153705E-01 | loss scale: 65536.0 | grad norm: 0.054 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.60 | backward-compute: 5487.16 | backward-params-all-reduce: 53.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.77 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.20 | batch-generator: 12.22
 iteration      787/    1000 | consumed samples:       402944 | elapsed time per iteration (ms): 7729.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153731E-01 | loss scale: 65536.0 | grad norm: 0.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.07 | backward-compute: 5485.49 | backward-params-all-reduce: 52.48 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.94 | batch-generator: 12.21
 iteration      788/    1000 | consumed samples:       403456 | elapsed time per iteration (ms): 7730.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154822E-01 | loss scale: 65536.0 | grad norm: 0.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.94 | backward-compute: 5488.60 | backward-params-all-reduce: 51.96 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.93 | batch-generator: 12.77
 iteration      789/    1000 | consumed samples:       403968 | elapsed time per iteration (ms): 7733.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154267E-01 | loss scale: 65536.0 | grad norm: 0.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.24 | backward-compute: 5484.23 | backward-params-all-reduce: 52.84 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.16 | batch-generator: 12.35
 iteration      790/    1000 | consumed samples:       404480 | elapsed time per iteration (ms): 7730.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154158E-01 | loss scale: 65536.0 | grad norm: 0.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.76 | backward-compute: 5485.92 | backward-params-all-reduce: 52.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.94 | batch-generator: 12.28
-----------------------------------------------------------------------------------------------
 validation loss at iteration 790 | lm loss value: 1.155949E-01 | lm loss PPL: 1.122541E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      791/    1000 | consumed samples:       404992 | elapsed time per iteration (ms): 25835.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153688E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20198.71 | backward-compute: 5484.94 | backward-params-all-reduce: 52.19 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.59 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.97 | batch-generator: 112.31
 iteration      792/    1000 | consumed samples:       405504 | elapsed time per iteration (ms): 7733.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156142E-01 | loss scale: 65536.0 | grad norm: 0.057 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.76 | backward-compute: 5488.26 | backward-params-all-reduce: 52.71 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 80.10 | batch-generator: 12.23
 iteration      793/    1000 | consumed samples:       406016 | elapsed time per iteration (ms): 7732.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154287E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.62 | backward-compute: 5484.82 | backward-params-all-reduce: 51.85 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.07 | batch-generator: 12.25
 iteration      794/    1000 | consumed samples:       406528 | elapsed time per iteration (ms): 7731.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154985E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.25 | backward-compute: 5486.05 | backward-params-all-reduce: 52.64 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.84 | batch-generator: 12.22
 iteration      795/    1000 | consumed samples:       407040 | elapsed time per iteration (ms): 7733.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154063E-01 | loss scale: 65536.0 | grad norm: 0.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.66 | backward-compute: 5484.69 | backward-params-all-reduce: 52.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 80.01 | batch-generator: 12.24
 iteration      796/    1000 | consumed samples:       407552 | elapsed time per iteration (ms): 7734.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154158E-01 | loss scale: 65536.0 | grad norm: 0.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.67 | backward-compute: 5482.49 | backward-params-all-reduce: 52.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.95 | batch-generator: 12.31
 iteration      797/    1000 | consumed samples:       408064 | elapsed time per iteration (ms): 7731.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154350E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.01 | backward-compute: 5485.69 | backward-params-all-reduce: 52.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.89 | batch-generator: 12.72
 iteration      798/    1000 | consumed samples:       408576 | elapsed time per iteration (ms): 7734.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154638E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.78 | backward-compute: 5487.67 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.99 | batch-generator: 12.32
 iteration      799/    1000 | consumed samples:       409088 | elapsed time per iteration (ms): 7728.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154190E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.75 | backward-compute: 5488.14 | backward-params-all-reduce: 51.82 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.06 | batch-generator: 12.20
 iteration      800/    1000 | consumed samples:       409600 | elapsed time per iteration (ms): 7725.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154630E-01 | loss scale: 65536.0 | grad norm: 0.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.55 | backward-compute: 5481.48 | backward-params-all-reduce: 52.92 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.61 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.92 | batch-generator: 12.05
-----------------------------------------------------------------------------------------------
 validation loss at iteration 800 | lm loss value: 1.155771E-01 | lm loss PPL: 1.122521E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      801/    1000 | consumed samples:       410112 | elapsed time per iteration (ms): 25840.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154679E-01 | loss scale: 65536.0 | grad norm: 0.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20203.20 | backward-compute: 5484.29 | backward-params-all-reduce: 53.53 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.11 | batch-generator: 111.79
 iteration      802/    1000 | consumed samples:       410624 | elapsed time per iteration (ms): 7733.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154922E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.06 | backward-compute: 5485.30 | backward-params-all-reduce: 52.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.00 | batch-generator: 12.15
 iteration      803/    1000 | consumed samples:       411136 | elapsed time per iteration (ms): 7734.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154642E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.42 | backward-compute: 5489.10 | backward-params-all-reduce: 52.80 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.61 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.00 | batch-generator: 12.28
 iteration      804/    1000 | consumed samples:       411648 | elapsed time per iteration (ms): 7735.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155247E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2106.67 | backward-compute: 5489.12 | backward-params-all-reduce: 52.00 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.10 | batch-generator: 12.05
 iteration      805/    1000 | consumed samples:       412160 | elapsed time per iteration (ms): 7734.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155048E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2110.42 | backward-compute: 5484.09 | backward-params-all-reduce: 52.93 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.82 | optimizer: 80.10 | batch-generator: 12.06
 iteration      806/    1000 | consumed samples:       412672 | elapsed time per iteration (ms): 7736.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154924E-01 | loss scale: 65536.0 | grad norm: 0.042 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.61 | backward-compute: 5483.35 | backward-params-all-reduce: 53.24 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.99 | batch-generator: 12.22
 iteration      807/    1000 | consumed samples:       413184 | elapsed time per iteration (ms): 7731.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155680E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.19 | backward-compute: 5482.37 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.02 | batch-generator: 12.38
 iteration      808/    1000 | consumed samples:       413696 | elapsed time per iteration (ms): 7726.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155096E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.72 | backward-compute: 5483.19 | backward-params-all-reduce: 52.40 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.09 | batch-generator: 12.68
 iteration      809/    1000 | consumed samples:       414208 | elapsed time per iteration (ms): 7729.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154965E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.71 | backward-compute: 5484.48 | backward-params-all-reduce: 52.01 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.78 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.11 | batch-generator: 12.55
 iteration      810/    1000 | consumed samples:       414720 | elapsed time per iteration (ms): 7729.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155094E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.74 | backward-compute: 5486.63 | backward-params-all-reduce: 52.59 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.98 | batch-generator: 12.29
-----------------------------------------------------------------------------------------------
 validation loss at iteration 810 | lm loss value: 1.155911E-01 | lm loss PPL: 1.122537E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      811/    1000 | consumed samples:       415232 | elapsed time per iteration (ms): 25808.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155049E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20168.83 | backward-compute: 5488.63 | backward-params-all-reduce: 51.69 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.84 | batch-generator: 111.40
 iteration      812/    1000 | consumed samples:       415744 | elapsed time per iteration (ms): 7717.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154351E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.03 | backward-compute: 5482.41 | backward-params-all-reduce: 52.28 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.00 | batch-generator: 12.18
 iteration      813/    1000 | consumed samples:       416256 | elapsed time per iteration (ms): 7721.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154822E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.44 | backward-compute: 5485.34 | backward-params-all-reduce: 51.89 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.16 | batch-generator: 12.27
 iteration      814/    1000 | consumed samples:       416768 | elapsed time per iteration (ms): 7720.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154216E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.41 | backward-compute: 5482.27 | backward-params-all-reduce: 51.89 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.94 | optimizer: 80.30 | batch-generator: 12.03
 iteration      815/    1000 | consumed samples:       417280 | elapsed time per iteration (ms): 7713.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153285E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2089.33 | backward-compute: 5482.29 | backward-params-all-reduce: 53.68 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.98 | batch-generator: 12.42
 iteration      816/    1000 | consumed samples:       417792 | elapsed time per iteration (ms): 7713.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154041E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2091.73 | backward-compute: 5481.99 | backward-params-all-reduce: 52.43 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.98 | batch-generator: 12.30
 iteration      817/    1000 | consumed samples:       418304 | elapsed time per iteration (ms): 7708.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155491E-01 | loss scale: 65536.0 | grad norm: 0.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2089.72 | backward-compute: 5479.02 | backward-params-all-reduce: 52.41 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 80.12 | batch-generator: 12.66
 iteration      818/    1000 | consumed samples:       418816 | elapsed time per iteration (ms): 7711.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154847E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2089.65 | backward-compute: 5482.80 | backward-params-all-reduce: 52.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.98 | batch-generator: 12.65
 iteration      819/    1000 | consumed samples:       419328 | elapsed time per iteration (ms): 7718.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154950E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2094.03 | backward-compute: 5484.73 | backward-params-all-reduce: 51.96 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.00 | batch-generator: 12.39
 iteration      820/    1000 | consumed samples:       419840 | elapsed time per iteration (ms): 7711.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153522E-01 | loss scale: 65536.0 | grad norm: 0.037 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2088.64 | backward-compute: 5482.73 | backward-params-all-reduce: 52.55 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.00 | batch-generator: 12.14
-----------------------------------------------------------------------------------------------
 validation loss at iteration 820 | lm loss value: 1.155745E-01 | lm loss PPL: 1.122518E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      821/    1000 | consumed samples:       420352 | elapsed time per iteration (ms): 25687.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154773E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20052.13 | backward-compute: 5483.72 | backward-params-all-reduce: 52.28 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.90 | batch-generator: 112.51
 iteration      822/    1000 | consumed samples:       420864 | elapsed time per iteration (ms): 7715.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153236E-01 | loss scale: 65536.0 | grad norm: 0.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2090.26 | backward-compute: 5485.90 | backward-params-all-reduce: 52.04 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.10 | batch-generator: 12.17
 iteration      823/    1000 | consumed samples:       421376 | elapsed time per iteration (ms): 7711.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155431E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2086.71 | backward-compute: 5485.59 | backward-params-all-reduce: 51.75 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.96 | batch-generator: 12.07
 iteration      824/    1000 | consumed samples:       421888 | elapsed time per iteration (ms): 7710.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155041E-01 | loss scale: 65536.0 | grad norm: 0.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2088.44 | backward-compute: 5483.44 | backward-params-all-reduce: 51.84 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.94 | batch-generator: 12.28
 iteration      825/    1000 | consumed samples:       422400 | elapsed time per iteration (ms): 7719.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154941E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.31 | backward-compute: 5484.09 | backward-params-all-reduce: 52.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.92 | batch-generator: 12.25
 iteration      826/    1000 | consumed samples:       422912 | elapsed time per iteration (ms): 7721.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153796E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.20 | backward-compute: 5482.81 | backward-params-all-reduce: 52.21 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.03 | batch-generator: 12.26
 iteration      827/    1000 | consumed samples:       423424 | elapsed time per iteration (ms): 7716.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155266E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2092.85 | backward-compute: 5483.61 | backward-params-all-reduce: 51.96 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.06 | batch-generator: 12.34
 iteration      828/    1000 | consumed samples:       423936 | elapsed time per iteration (ms): 7721.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154205E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.51 | backward-compute: 5485.72 | backward-params-all-reduce: 51.83 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.98 | batch-generator: 12.12
 iteration      829/    1000 | consumed samples:       424448 | elapsed time per iteration (ms): 7726.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154818E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.22 | backward-compute: 5482.64 | backward-params-all-reduce: 52.86 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.05 | batch-generator: 12.14
 iteration      830/    1000 | consumed samples:       424960 | elapsed time per iteration (ms): 7726.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154538E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.75 | backward-compute: 5488.70 | backward-params-all-reduce: 51.90 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.07 | batch-generator: 12.12
-----------------------------------------------------------------------------------------------
 validation loss at iteration 830 | lm loss value: 1.155424E-01 | lm loss PPL: 1.122482E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      831/    1000 | consumed samples:       425472 | elapsed time per iteration (ms): 25822.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155989E-01 | loss scale: 65536.0 | grad norm: 0.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20178.92 | backward-compute: 5491.61 | backward-params-all-reduce: 52.06 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.20 | batch-generator: 111.41
 iteration      832/    1000 | consumed samples:       425984 | elapsed time per iteration (ms): 7746.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155544E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.98 | backward-compute: 5492.36 | backward-params-all-reduce: 52.07 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.87 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 80.23 | batch-generator: 12.28
 iteration      833/    1000 | consumed samples:       426496 | elapsed time per iteration (ms): 7751.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154703E-01 | loss scale: 65536.0 | grad norm: 0.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.77 | backward-compute: 5491.10 | backward-params-all-reduce: 54.60 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.98 | batch-generator: 12.06
 iteration      834/    1000 | consumed samples:       427008 | elapsed time per iteration (ms): 7755.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154776E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2126.91 | backward-compute: 5487.66 | backward-params-all-reduce: 53.25 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.88 | batch-generator: 12.25
 iteration      835/    1000 | consumed samples:       427520 | elapsed time per iteration (ms): 7755.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154976E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2128.81 | backward-compute: 5485.60 | backward-params-all-reduce: 53.52 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.11 | batch-generator: 12.25
 iteration      836/    1000 | consumed samples:       428032 | elapsed time per iteration (ms): 7760.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153920E-01 | loss scale: 65536.0 | grad norm: 0.028 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2131.68 | backward-compute: 5487.71 | backward-params-all-reduce: 53.63 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.04 | batch-generator: 12.05
 iteration      837/    1000 | consumed samples:       428544 | elapsed time per iteration (ms): 7746.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154882E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.20 | backward-compute: 5488.82 | backward-params-all-reduce: 51.99 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.00 | batch-generator: 12.29
 iteration      838/    1000 | consumed samples:       429056 | elapsed time per iteration (ms): 7744.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154382E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.59 | backward-compute: 5489.28 | backward-params-all-reduce: 52.39 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.05 | batch-generator: 12.35
 iteration      839/    1000 | consumed samples:       429568 | elapsed time per iteration (ms): 7743.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155572E-01 | loss scale: 65536.0 | grad norm: 0.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.74 | backward-compute: 5487.99 | backward-params-all-reduce: 52.39 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.13 | batch-generator: 12.31
 iteration      840/    1000 | consumed samples:       430080 | elapsed time per iteration (ms): 7741.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153715E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.77 | backward-compute: 5483.84 | backward-params-all-reduce: 52.66 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.03 | batch-generator: 12.03
-----------------------------------------------------------------------------------------------
 validation loss at iteration 840 | lm loss value: 1.155495E-01 | lm loss PPL: 1.122490E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      841/    1000 | consumed samples:       430592 | elapsed time per iteration (ms): 25829.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154260E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20187.56 | backward-compute: 5490.50 | backward-params-all-reduce: 52.44 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.87 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.12 | batch-generator: 110.98
 iteration      842/    1000 | consumed samples:       431104 | elapsed time per iteration (ms): 7723.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155051E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.01 | backward-compute: 5489.37 | backward-params-all-reduce: 52.10 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.95 | batch-generator: 12.25
 iteration      843/    1000 | consumed samples:       431616 | elapsed time per iteration (ms): 7716.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155640E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2091.35 | backward-compute: 5486.05 | backward-params-all-reduce: 51.84 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.90 | batch-generator: 12.28
 iteration      844/    1000 | consumed samples:       432128 | elapsed time per iteration (ms): 7715.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154873E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2094.10 | backward-compute: 5481.54 | backward-params-all-reduce: 52.34 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.98 | batch-generator: 12.48
 iteration      845/    1000 | consumed samples:       432640 | elapsed time per iteration (ms): 7713.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153586E-01 | loss scale: 65536.0 | grad norm: 0.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2087.56 | backward-compute: 5484.41 | backward-params-all-reduce: 51.98 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 12.02 | optimizer: 81.74 | batch-generator: 12.60
 iteration      846/    1000 | consumed samples:       433152 | elapsed time per iteration (ms): 7714.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155917E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2091.90 | backward-compute: 5483.19 | backward-params-all-reduce: 51.94 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.95 | batch-generator: 12.68
 iteration      847/    1000 | consumed samples:       433664 | elapsed time per iteration (ms): 7711.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153640E-01 | loss scale: 65536.0 | grad norm: 0.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2090.61 | backward-compute: 5481.23 | backward-params-all-reduce: 51.78 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.00 | batch-generator: 12.41
 iteration      848/    1000 | consumed samples:       434176 | elapsed time per iteration (ms): 7721.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154188E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.51 | backward-compute: 5481.27 | backward-params-all-reduce: 52.56 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.94 | batch-generator: 12.24
 iteration      849/    1000 | consumed samples:       434688 | elapsed time per iteration (ms): 7720.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154421E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2097.44 | backward-compute: 5484.12 | backward-params-all-reduce: 52.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.01 | batch-generator: 12.22
 iteration      850/    1000 | consumed samples:       435200 | elapsed time per iteration (ms): 7713.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153855E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2091.48 | backward-compute: 5482.60 | backward-params-all-reduce: 51.88 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.10 | batch-generator: 12.35
-----------------------------------------------------------------------------------------------
 validation loss at iteration 850 | lm loss value: 1.155501E-01 | lm loss PPL: 1.122491E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      851/    1000 | consumed samples:       435712 | elapsed time per iteration (ms): 25693.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.157065E-01 | loss scale: 65536.0 | grad norm: 0.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20058.48 | backward-compute: 5483.97 | backward-params-all-reduce: 51.77 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.04 | batch-generator: 114.84
 iteration      852/    1000 | consumed samples:       436224 | elapsed time per iteration (ms): 7717.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154279E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.96 | backward-compute: 5483.75 | backward-params-all-reduce: 52.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.00 | batch-generator: 12.54
 iteration      853/    1000 | consumed samples:       436736 | elapsed time per iteration (ms): 7715.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154998E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2085.19 | backward-compute: 5491.11 | backward-params-all-reduce: 52.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.60 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.93 | batch-generator: 12.22
 iteration      854/    1000 | consumed samples:       437248 | elapsed time per iteration (ms): 7722.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154702E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2092.81 | backward-compute: 5489.77 | backward-params-all-reduce: 52.10 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.14 | batch-generator: 12.12
 iteration      855/    1000 | consumed samples:       437760 | elapsed time per iteration (ms): 7725.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154273E-01 | loss scale: 65536.0 | grad norm: 0.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.62 | backward-compute: 5484.31 | backward-params-all-reduce: 52.73 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.08 | batch-generator: 12.23
 iteration      856/    1000 | consumed samples:       438272 | elapsed time per iteration (ms): 7709.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154826E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2087.01 | backward-compute: 5483.64 | backward-params-all-reduce: 51.83 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.08 | batch-generator: 12.13
 iteration      857/    1000 | consumed samples:       438784 | elapsed time per iteration (ms): 7710.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154707E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2083.26 | backward-compute: 5487.11 | backward-params-all-reduce: 52.94 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.07 | batch-generator: 12.47
 iteration      858/    1000 | consumed samples:       439296 | elapsed time per iteration (ms): 7717.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154273E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.58 | backward-compute: 5481.21 | backward-params-all-reduce: 51.95 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.08 | batch-generator: 12.51
 iteration      859/    1000 | consumed samples:       439808 | elapsed time per iteration (ms): 7708.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154635E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2087.81 | backward-compute: 5481.53 | backward-params-all-reduce: 51.73 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.03 | batch-generator: 12.10
 iteration      860/    1000 | consumed samples:       440320 | elapsed time per iteration (ms): 7715.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155078E-01 | loss scale: 65536.0 | grad norm: 0.037 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.72 | backward-compute: 5478.59 | backward-params-all-reduce: 53.59 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.11 | batch-generator: 11.99
-----------------------------------------------------------------------------------------------
 validation loss at iteration 860 | lm loss value: 1.155957E-01 | lm loss PPL: 1.122542E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      861/    1000 | consumed samples:       440832 | elapsed time per iteration (ms): 25673.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154835E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20040.77 | backward-compute: 5481.20 | backward-params-all-reduce: 51.83 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.86 | batch-generator: 107.17
 iteration      862/    1000 | consumed samples:       441344 | elapsed time per iteration (ms): 7716.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154811E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.17 | backward-compute: 5480.97 | backward-params-all-reduce: 52.49 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.09 | batch-generator: 12.06
 iteration      863/    1000 | consumed samples:       441856 | elapsed time per iteration (ms): 7716.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155120E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.29 | backward-compute: 5481.56 | backward-params-all-reduce: 52.36 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.92 | batch-generator: 12.12
 iteration      864/    1000 | consumed samples:       442368 | elapsed time per iteration (ms): 7716.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155074E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.80 | backward-compute: 5480.70 | backward-params-all-reduce: 51.80 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.70 | optimizer: 79.90 | batch-generator: 12.29
 iteration      865/    1000 | consumed samples:       442880 | elapsed time per iteration (ms): 7716.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155102E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2094.01 | backward-compute: 5483.06 | backward-params-all-reduce: 52.09 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.70 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.90 | batch-generator: 12.28
 iteration      866/    1000 | consumed samples:       443392 | elapsed time per iteration (ms): 7714.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153640E-01 | loss scale: 65536.0 | grad norm: 0.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2094.41 | backward-compute: 5480.33 | backward-params-all-reduce: 52.57 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.12 | batch-generator: 12.16
 iteration      867/    1000 | consumed samples:       443904 | elapsed time per iteration (ms): 7718.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154703E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.30 | backward-compute: 5484.41 | backward-params-all-reduce: 51.90 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.01 | batch-generator: 12.85
 iteration      868/    1000 | consumed samples:       444416 | elapsed time per iteration (ms): 7718.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155436E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2094.68 | backward-compute: 5484.29 | backward-params-all-reduce: 52.38 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.96 | batch-generator: 12.37
 iteration      869/    1000 | consumed samples:       444928 | elapsed time per iteration (ms): 7725.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154982E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.00 | backward-compute: 5484.94 | backward-params-all-reduce: 52.61 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.09 | batch-generator: 12.12
 iteration      870/    1000 | consumed samples:       445440 | elapsed time per iteration (ms): 7725.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155670E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2097.60 | backward-compute: 5488.53 | backward-params-all-reduce: 51.70 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.06 | batch-generator: 12.25
-----------------------------------------------------------------------------------------------
 validation loss at iteration 870 | lm loss value: 1.155882E-01 | lm loss PPL: 1.122533E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      871/    1000 | consumed samples:       445952 | elapsed time per iteration (ms): 25774.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154142E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20137.83 | backward-compute: 5484.80 | backward-params-all-reduce: 53.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.10 | batch-generator: 107.82
 iteration      872/    1000 | consumed samples:       446464 | elapsed time per iteration (ms): 7725.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155163E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.96 | backward-compute: 5487.02 | backward-params-all-reduce: 52.40 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.92 | batch-generator: 12.26
 iteration      873/    1000 | consumed samples:       446976 | elapsed time per iteration (ms): 7740.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154104E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.74 | backward-compute: 5484.87 | backward-params-all-reduce: 52.96 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.91 | batch-generator: 12.41
 iteration      874/    1000 | consumed samples:       447488 | elapsed time per iteration (ms): 7745.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154993E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.71 | backward-compute: 5487.22 | backward-params-all-reduce: 53.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.85 | batch-generator: 12.37
 iteration      875/    1000 | consumed samples:       448000 | elapsed time per iteration (ms): 7751.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153863E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.45 | backward-compute: 5489.25 | backward-params-all-reduce: 52.74 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.84 | optimizer: 80.20 | batch-generator: 12.30
 iteration      876/    1000 | consumed samples:       448512 | elapsed time per iteration (ms): 7756.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155104E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2128.64 | backward-compute: 5487.74 | backward-params-all-reduce: 53.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.96 | batch-generator: 12.10
 iteration      877/    1000 | consumed samples:       449024 | elapsed time per iteration (ms): 7759.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154337E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2130.77 | backward-compute: 5487.92 | backward-params-all-reduce: 53.74 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.93 | batch-generator: 12.64
 iteration      878/    1000 | consumed samples:       449536 | elapsed time per iteration (ms): 7762.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155304E-01 | loss scale: 65536.0 | grad norm: 0.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2132.49 | backward-compute: 5489.20 | backward-params-all-reduce: 53.00 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 80.06 | batch-generator: 12.30
 iteration      879/    1000 | consumed samples:       450048 | elapsed time per iteration (ms): 7753.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153966E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2125.40 | backward-compute: 5487.75 | backward-params-all-reduce: 53.02 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.08 | batch-generator: 12.40
 iteration      880/    1000 | consumed samples:       450560 | elapsed time per iteration (ms): 7747.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153870E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.70 | backward-compute: 5486.74 | backward-params-all-reduce: 52.68 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.10 | batch-generator: 12.16
-----------------------------------------------------------------------------------------------
 validation loss at iteration 880 | lm loss value: 1.155371E-01 | lm loss PPL: 1.122476E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      881/    1000 | consumed samples:       451072 | elapsed time per iteration (ms): 25848.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154371E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20209.53 | backward-compute: 5487.61 | backward-params-all-reduce: 52.11 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.82 | optimizer: 80.25 | batch-generator: 107.41
 iteration      882/    1000 | consumed samples:       451584 | elapsed time per iteration (ms): 7732.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155514E-01 | loss scale: 65536.0 | grad norm: 0.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.34 | backward-compute: 5487.19 | backward-params-all-reduce: 52.51 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.03 | batch-generator: 12.12
 iteration      883/    1000 | consumed samples:       452096 | elapsed time per iteration (ms): 7737.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154201E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.55 | backward-compute: 5488.23 | backward-params-all-reduce: 51.92 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.05 | batch-generator: 12.15
 iteration      884/    1000 | consumed samples:       452608 | elapsed time per iteration (ms): 7726.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154619E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.70 | backward-compute: 5487.98 | backward-params-all-reduce: 52.20 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.16 | batch-generator: 12.03
 iteration      885/    1000 | consumed samples:       453120 | elapsed time per iteration (ms): 7730.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154614E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.32 | backward-compute: 5489.65 | backward-params-all-reduce: 52.00 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.11 | batch-generator: 12.13
 iteration      886/    1000 | consumed samples:       453632 | elapsed time per iteration (ms): 7728.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153731E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.34 | backward-compute: 5488.56 | backward-params-all-reduce: 52.06 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.07 | batch-generator: 12.33
 iteration      887/    1000 | consumed samples:       454144 | elapsed time per iteration (ms): 7727.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155176E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.31 | backward-compute: 5488.45 | backward-params-all-reduce: 52.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.99 | batch-generator: 12.15
 iteration      888/    1000 | consumed samples:       454656 | elapsed time per iteration (ms): 7725.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155541E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.46 | backward-compute: 5486.45 | backward-params-all-reduce: 51.94 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.26 | optimizer-unscale-and-check-inf: 11.71 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.97 | batch-generator: 12.14
 iteration      889/    1000 | consumed samples:       455168 | elapsed time per iteration (ms): 7726.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154377E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.61 | backward-compute: 5491.18 | backward-params-all-reduce: 51.97 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.03 | batch-generator: 12.73
 iteration      890/    1000 | consumed samples:       455680 | elapsed time per iteration (ms): 7724.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153795E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.41 | backward-compute: 5486.39 | backward-params-all-reduce: 52.31 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.13 | batch-generator: 12.47
-----------------------------------------------------------------------------------------------
 validation loss at iteration 890 | lm loss value: 1.155791E-01 | lm loss PPL: 1.122523E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      891/    1000 | consumed samples:       456192 | elapsed time per iteration (ms): 25794.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155456E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20155.33 | backward-compute: 5488.23 | backward-params-all-reduce: 51.80 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.96 | batch-generator: 107.60
 iteration      892/    1000 | consumed samples:       456704 | elapsed time per iteration (ms): 7725.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154077E-01 | loss scale: 65536.0 | grad norm: 0.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.27 | backward-compute: 5485.30 | backward-params-all-reduce: 51.89 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.03 | batch-generator: 12.24
 iteration      893/    1000 | consumed samples:       457216 | elapsed time per iteration (ms): 7728.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154750E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.00 | backward-compute: 5489.02 | backward-params-all-reduce: 52.41 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.99 | batch-generator: 12.05
 iteration      894/    1000 | consumed samples:       457728 | elapsed time per iteration (ms): 7728.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154492E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.30 | backward-compute: 5487.95 | backward-params-all-reduce: 52.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.96 | batch-generator: 12.28
 iteration      895/    1000 | consumed samples:       458240 | elapsed time per iteration (ms): 7727.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153316E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.95 | backward-compute: 5486.75 | backward-params-all-reduce: 52.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.94 | batch-generator: 12.23
 iteration      896/    1000 | consumed samples:       458752 | elapsed time per iteration (ms): 7727.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154440E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.44 | backward-compute: 5490.30 | backward-params-all-reduce: 51.78 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.06 | batch-generator: 12.20
 iteration      897/    1000 | consumed samples:       459264 | elapsed time per iteration (ms): 7724.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155033E-01 | loss scale: 65536.0 | grad norm: 0.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.78 | backward-compute: 5484.62 | backward-params-all-reduce: 51.84 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.82 | optimizer: 80.22 | batch-generator: 12.11
 iteration      898/    1000 | consumed samples:       459776 | elapsed time per iteration (ms): 7724.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154335E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.69 | backward-compute: 5486.25 | backward-params-all-reduce: 51.88 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.92 | batch-generator: 12.39
 iteration      899/    1000 | consumed samples:       460288 | elapsed time per iteration (ms): 7723.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154961E-01 | loss scale: 65536.0 | grad norm: 0.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.33 | backward-compute: 5484.83 | backward-params-all-reduce: 51.75 | backward-embedding-all-reduce: 0.04 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.08 | batch-generator: 12.08
 iteration      900/    1000 | consumed samples:       460800 | elapsed time per iteration (ms): 7723.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155955E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.49 | backward-compute: 5484.26 | backward-params-all-reduce: 52.30 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.14 | batch-generator: 12.35
-----------------------------------------------------------------------------------------------
 validation loss at iteration 900 | lm loss value: 1.155513E-01 | lm loss PPL: 1.122492E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      901/    1000 | consumed samples:       461312 | elapsed time per iteration (ms): 25676.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154565E-01 | loss scale: 65536.0 | grad norm: 0.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20041.26 | backward-compute: 5483.48 | backward-params-all-reduce: 52.34 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.03 | batch-generator: 109.64
 iteration      902/    1000 | consumed samples:       461824 | elapsed time per iteration (ms): 7717.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155003E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.89 | backward-compute: 5483.60 | backward-params-all-reduce: 52.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.77 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.17 | batch-generator: 12.08
 iteration      903/    1000 | consumed samples:       462336 | elapsed time per iteration (ms): 7716.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155482E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2089.61 | backward-compute: 5487.61 | backward-params-all-reduce: 51.71 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.96 | batch-generator: 12.17
 iteration      904/    1000 | consumed samples:       462848 | elapsed time per iteration (ms): 7711.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155887E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2089.03 | backward-compute: 5482.59 | backward-params-all-reduce: 52.28 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.13 | batch-generator: 12.24
 iteration      905/    1000 | consumed samples:       463360 | elapsed time per iteration (ms): 7712.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155249E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2088.02 | backward-compute: 5485.21 | backward-params-all-reduce: 51.94 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.10 | batch-generator: 11.78
 iteration      906/    1000 | consumed samples:       463872 | elapsed time per iteration (ms): 7718.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155294E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.07 | backward-compute: 5483.85 | backward-params-all-reduce: 51.80 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.26 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.12 | batch-generator: 12.03
 iteration      907/    1000 | consumed samples:       464384 | elapsed time per iteration (ms): 7721.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154080E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.74 | backward-compute: 5487.17 | backward-params-all-reduce: 51.85 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 12.02 | optimizer: 81.68 | batch-generator: 12.05
 iteration      908/    1000 | consumed samples:       464896 | elapsed time per iteration (ms): 7722.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155019E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.79 | backward-compute: 5488.46 | backward-params-all-reduce: 52.00 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.11 | batch-generator: 12.42
 iteration      909/    1000 | consumed samples:       465408 | elapsed time per iteration (ms): 7721.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154136E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.07 | backward-compute: 5483.36 | backward-params-all-reduce: 52.47 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 79.99 | batch-generator: 12.24
 iteration      910/    1000 | consumed samples:       465920 | elapsed time per iteration (ms): 7726.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155541E-01 | loss scale: 65536.0 | grad norm: 0.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.73 | backward-compute: 5486.90 | backward-params-all-reduce: 52.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.10 | batch-generator: 12.22
-----------------------------------------------------------------------------------------------
 validation loss at iteration 910 | lm loss value: 1.155915E-01 | lm loss PPL: 1.122537E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      911/    1000 | consumed samples:       466432 | elapsed time per iteration (ms): 25744.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154497E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20108.32 | backward-compute: 5484.21 | backward-params-all-reduce: 52.52 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.80 | optimizer: 80.07 | batch-generator: 109.19
 iteration      912/    1000 | consumed samples:       466944 | elapsed time per iteration (ms): 7726.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154350E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.46 | backward-compute: 5485.92 | backward-params-all-reduce: 51.74 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.90 | batch-generator: 12.14
 iteration      913/    1000 | consumed samples:       467456 | elapsed time per iteration (ms): 7724.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155591E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2097.85 | backward-compute: 5487.59 | backward-params-all-reduce: 51.92 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.99 | batch-generator: 12.03
 iteration      914/    1000 | consumed samples:       467968 | elapsed time per iteration (ms): 7733.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.152833E-01 | loss scale: 65536.0 | grad norm: 0.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.63 | backward-compute: 5485.19 | backward-params-all-reduce: 52.34 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.92 | batch-generator: 12.98
 iteration      915/    1000 | consumed samples:       468480 | elapsed time per iteration (ms): 7728.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155028E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.91 | backward-compute: 5486.08 | backward-params-all-reduce: 52.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 80.20 | batch-generator: 12.36
 iteration      916/    1000 | consumed samples:       468992 | elapsed time per iteration (ms): 7733.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155142E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.36 | backward-compute: 5485.89 | backward-params-all-reduce: 52.07 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.96 | batch-generator: 12.14
 iteration      917/    1000 | consumed samples:       469504 | elapsed time per iteration (ms): 7741.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154424E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.74 | backward-compute: 5485.36 | backward-params-all-reduce: 52.67 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.10 | batch-generator: 12.08
 iteration      918/    1000 | consumed samples:       470016 | elapsed time per iteration (ms): 7745.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154862E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2115.82 | backward-compute: 5489.36 | backward-params-all-reduce: 52.73 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.03 | batch-generator: 11.90
 iteration      919/    1000 | consumed samples:       470528 | elapsed time per iteration (ms): 7750.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154529E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2120.09 | backward-compute: 5490.03 | backward-params-all-reduce: 53.23 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.03 | batch-generator: 12.09
 iteration      920/    1000 | consumed samples:       471040 | elapsed time per iteration (ms): 7759.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155685E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2127.33 | backward-compute: 5491.42 | backward-params-all-reduce: 53.18 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.97 | batch-generator: 12.38
-----------------------------------------------------------------------------------------------
 validation loss at iteration 920 | lm loss value: 1.155567E-01 | lm loss PPL: 1.122498E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      921/    1000 | consumed samples:       471552 | elapsed time per iteration (ms): 25909.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155683E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20266.92 | backward-compute: 5489.97 | backward-params-all-reduce: 52.89 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.84 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.80 | optimizer: 80.05 | batch-generator: 109.61
 iteration      922/    1000 | consumed samples:       472064 | elapsed time per iteration (ms): 7746.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154744E-01 | loss scale: 65536.0 | grad norm: 0.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.14 | backward-compute: 5490.06 | backward-params-all-reduce: 51.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.93 | batch-generator: 11.93
 iteration      923/    1000 | consumed samples:       472576 | elapsed time per iteration (ms): 7740.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154330E-01 | loss scale: 65536.0 | grad norm: 0.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.74 | backward-compute: 5488.43 | backward-params-all-reduce: 52.46 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.06 | batch-generator: 12.07
 iteration      924/    1000 | consumed samples:       473088 | elapsed time per iteration (ms): 7736.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155248E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2112.92 | backward-compute: 5482.84 | backward-params-all-reduce: 53.04 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.72 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.94 | batch-generator: 12.10
 iteration      925/    1000 | consumed samples:       473600 | elapsed time per iteration (ms): 7725.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155044E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.18 | backward-compute: 5483.95 | backward-params-all-reduce: 52.06 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.06 | batch-generator: 12.10
 iteration      926/    1000 | consumed samples:       474112 | elapsed time per iteration (ms): 7721.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153259E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.43 | backward-compute: 5482.46 | backward-params-all-reduce: 51.84 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.77 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.04 | batch-generator: 12.28
 iteration      927/    1000 | consumed samples:       474624 | elapsed time per iteration (ms): 7722.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155604E-01 | loss scale: 65536.0 | grad norm: 0.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.06 | backward-compute: 5482.32 | backward-params-all-reduce: 52.66 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.20 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.07 | batch-generator: 12.51
 iteration      928/    1000 | consumed samples:       475136 | elapsed time per iteration (ms): 7720.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154332E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.14 | backward-compute: 5481.86 | backward-params-all-reduce: 52.18 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.88 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.85 | optimizer: 80.37 | batch-generator: 12.39
 iteration      929/    1000 | consumed samples:       475648 | elapsed time per iteration (ms): 7713.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155789E-01 | loss scale: 65536.0 | grad norm: 0.042 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2092.39 | backward-compute: 5481.50 | backward-params-all-reduce: 52.00 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.10 | batch-generator: 12.41
 iteration      930/    1000 | consumed samples:       476160 | elapsed time per iteration (ms): 7714.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155018E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2090.76 | backward-compute: 5484.15 | backward-params-all-reduce: 52.13 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.02 | batch-generator: 12.04
-----------------------------------------------------------------------------------------------
 validation loss at iteration 930 | lm loss value: 1.155328E-01 | lm loss PPL: 1.122471E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      931/    1000 | consumed samples:       476672 | elapsed time per iteration (ms): 25702.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155277E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20064.56 | backward-compute: 5486.24 | backward-params-all-reduce: 52.01 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 79.98 | batch-generator: 109.45
 iteration      932/    1000 | consumed samples:       477184 | elapsed time per iteration (ms): 7721.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155927E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.02 | backward-compute: 5486.27 | backward-params-all-reduce: 52.15 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.04 | batch-generator: 12.09
 iteration      933/    1000 | consumed samples:       477696 | elapsed time per iteration (ms): 7718.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154873E-01 | loss scale: 65536.0 | grad norm: 0.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2089.46 | backward-compute: 5489.58 | backward-params-all-reduce: 52.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.75 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.18 | batch-generator: 12.10
 iteration      934/    1000 | consumed samples:       478208 | elapsed time per iteration (ms): 7717.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154739E-01 | loss scale: 65536.0 | grad norm: 0.047 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2091.85 | backward-compute: 5486.11 | backward-params-all-reduce: 51.79 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 80.12 | batch-generator: 12.06
 iteration      935/    1000 | consumed samples:       478720 | elapsed time per iteration (ms): 7716.9 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155047E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2091.78 | backward-compute: 5485.72 | backward-params-all-reduce: 52.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.02 | batch-generator: 12.30
 iteration      936/    1000 | consumed samples:       479232 | elapsed time per iteration (ms): 7721.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154598E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.65 | backward-compute: 5485.10 | backward-params-all-reduce: 52.20 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.05 | batch-generator: 12.09
 iteration      937/    1000 | consumed samples:       479744 | elapsed time per iteration (ms): 7719.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155746E-01 | loss scale: 65536.0 | grad norm: 0.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2094.36 | backward-compute: 5485.52 | backward-params-all-reduce: 51.78 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.86 | optimizer: 80.14 | batch-generator: 12.61
 iteration      938/    1000 | consumed samples:       480256 | elapsed time per iteration (ms): 7722.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154327E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.00 | backward-compute: 5484.27 | backward-params-all-reduce: 51.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.12 | batch-generator: 12.38
 iteration      939/    1000 | consumed samples:       480768 | elapsed time per iteration (ms): 7725.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155185E-01 | loss scale: 65536.0 | grad norm: 0.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.55 | backward-compute: 5484.89 | backward-params-all-reduce: 51.98 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.11 | batch-generator: 12.30
 iteration      940/    1000 | consumed samples:       481280 | elapsed time per iteration (ms): 7722.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154686E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.90 | backward-compute: 5486.74 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.03 | batch-generator: 12.15
-----------------------------------------------------------------------------------------------
 validation loss at iteration 940 | lm loss value: 1.155796E-01 | lm loss PPL: 1.122524E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      941/    1000 | consumed samples:       481792 | elapsed time per iteration (ms): 25783.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154874E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20145.58 | backward-compute: 5486.81 | backward-params-all-reduce: 51.80 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.01 | batch-generator: 111.28
 iteration      942/    1000 | consumed samples:       482304 | elapsed time per iteration (ms): 7723.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155030E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.11 | backward-compute: 5485.75 | backward-params-all-reduce: 52.19 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.06 | batch-generator: 12.17
 iteration      943/    1000 | consumed samples:       482816 | elapsed time per iteration (ms): 7718.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154632E-01 | loss scale: 65536.0 | grad norm: 0.037 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.40 | backward-compute: 5485.98 | backward-params-all-reduce: 51.81 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.05 | batch-generator: 12.32
 iteration      944/    1000 | consumed samples:       483328 | elapsed time per iteration (ms): 7715.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155000E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2092.39 | backward-compute: 5484.09 | backward-params-all-reduce: 51.72 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.03 | batch-generator: 12.39
 iteration      945/    1000 | consumed samples:       483840 | elapsed time per iteration (ms): 7716.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154142E-01 | loss scale: 65536.0 | grad norm: 0.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2093.01 | backward-compute: 5484.62 | backward-params-all-reduce: 51.94 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.06 | batch-generator: 12.30
 iteration      946/    1000 | consumed samples:       484352 | elapsed time per iteration (ms): 7716.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154658E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.19 | backward-compute: 5481.72 | backward-params-all-reduce: 51.86 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.85 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 80.32 | batch-generator: 12.27
 iteration      947/    1000 | consumed samples:       484864 | elapsed time per iteration (ms): 7718.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153876E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.91 | backward-compute: 5481.89 | backward-params-all-reduce: 51.87 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.06 | batch-generator: 12.76
 iteration      948/    1000 | consumed samples:       485376 | elapsed time per iteration (ms): 7712.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154712E-01 | loss scale: 65536.0 | grad norm: 0.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2087.11 | backward-compute: 5485.85 | backward-params-all-reduce: 52.06 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.04 | batch-generator: 12.34
 iteration      949/    1000 | consumed samples:       485888 | elapsed time per iteration (ms): 7712.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155481E-01 | loss scale: 65536.0 | grad norm: 0.051 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2086.13 | backward-compute: 5486.68 | backward-params-all-reduce: 52.61 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.05 | batch-generator: 12.36
 iteration      950/    1000 | consumed samples:       486400 | elapsed time per iteration (ms): 7711.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154415E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2088.37 | backward-compute: 5484.28 | backward-params-all-reduce: 51.95 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.00 | batch-generator: 12.14
-----------------------------------------------------------------------------------------------
 validation loss at iteration 950 | lm loss value: 1.155907E-01 | lm loss PPL: 1.122536E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      951/    1000 | consumed samples:       486912 | elapsed time per iteration (ms): 25731.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154359E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20096.28 | backward-compute: 5483.79 | backward-params-all-reduce: 52.12 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.77 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.10 | batch-generator: 109.83
 iteration      952/    1000 | consumed samples:       487424 | elapsed time per iteration (ms): 7715.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154254E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2088.55 | backward-compute: 5487.56 | backward-params-all-reduce: 51.94 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.93 | batch-generator: 12.42
 iteration      953/    1000 | consumed samples:       487936 | elapsed time per iteration (ms): 7720.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154597E-01 | loss scale: 65536.0 | grad norm: 0.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.71 | backward-compute: 5485.72 | backward-params-all-reduce: 51.76 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.71 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.95 | batch-generator: 12.46
 iteration      954/    1000 | consumed samples:       488448 | elapsed time per iteration (ms): 7724.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153941E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.97 | backward-compute: 5483.28 | backward-params-all-reduce: 51.93 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.03 | batch-generator: 12.28
 iteration      955/    1000 | consumed samples:       488960 | elapsed time per iteration (ms): 7726.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154941E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.61 | backward-compute: 5482.43 | backward-params-all-reduce: 52.34 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.73 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.99 | batch-generator: 12.30
 iteration      956/    1000 | consumed samples:       489472 | elapsed time per iteration (ms): 7727.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156112E-01 | loss scale: 65536.0 | grad norm: 0.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.01 | backward-compute: 5486.61 | backward-params-all-reduce: 52.68 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.77 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.06 | batch-generator: 12.41
 iteration      957/    1000 | consumed samples:       489984 | elapsed time per iteration (ms): 7727.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154793E-01 | loss scale: 65536.0 | grad norm: 0.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2100.48 | backward-compute: 5487.36 | backward-params-all-reduce: 52.31 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.83 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.10 | batch-generator: 12.53
 iteration      958/    1000 | consumed samples:       490496 | elapsed time per iteration (ms): 7733.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154523E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.81 | backward-compute: 5488.02 | backward-params-all-reduce: 52.15 | backward-embedding-all-reduce: 0.03 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.19 | batch-generator: 12.48
 iteration      959/    1000 | consumed samples:       491008 | elapsed time per iteration (ms): 7729.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154101E-01 | loss scale: 65536.0 | grad norm: 0.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.41 | backward-compute: 5491.35 | backward-params-all-reduce: 51.85 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.99 | batch-generator: 12.29
 iteration      960/    1000 | consumed samples:       491520 | elapsed time per iteration (ms): 7734.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153463E-01 | loss scale: 65536.0 | grad norm: 0.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.39 | backward-compute: 5485.80 | backward-params-all-reduce: 51.78 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.09 | batch-generator: 12.21
-----------------------------------------------------------------------------------------------
 validation loss at iteration 960 | lm loss value: 1.155657E-01 | lm loss PPL: 1.122508E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      961/    1000 | consumed samples:       492032 | elapsed time per iteration (ms): 25888.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154314E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20249.94 | backward-compute: 5484.84 | backward-params-all-reduce: 54.51 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.00 | batch-generator: 109.63
 iteration      962/    1000 | consumed samples:       492544 | elapsed time per iteration (ms): 7754.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155897E-01 | loss scale: 65536.0 | grad norm: 0.051 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2123.81 | backward-compute: 5490.01 | backward-params-all-reduce: 53.28 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.08 | batch-generator: 12.36
 iteration      963/    1000 | consumed samples:       493056 | elapsed time per iteration (ms): 7756.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154633E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2127.12 | backward-compute: 5489.67 | backward-params-all-reduce: 52.35 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.02 | batch-generator: 12.00
 iteration      964/    1000 | consumed samples:       493568 | elapsed time per iteration (ms): 7748.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154877E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2121.45 | backward-compute: 5487.06 | backward-params-all-reduce: 52.40 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.63 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.97 | batch-generator: 12.14
 iteration      965/    1000 | consumed samples:       494080 | elapsed time per iteration (ms): 7745.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155706E-01 | loss scale: 65536.0 | grad norm: 0.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2117.55 | backward-compute: 5487.90 | backward-params-all-reduce: 52.60 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.61 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.02 | batch-generator: 12.37
 iteration      966/    1000 | consumed samples:       494592 | elapsed time per iteration (ms): 7744.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155445E-01 | loss scale: 65536.0 | grad norm: 0.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2118.42 | backward-compute: 5485.38 | backward-params-all-reduce: 53.03 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.91 | batch-generator: 12.11
 iteration      967/    1000 | consumed samples:       495104 | elapsed time per iteration (ms): 7742.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155424E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2114.63 | backward-compute: 5487.65 | backward-params-all-reduce: 52.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.07 | batch-generator: 12.84
 iteration      968/    1000 | consumed samples:       495616 | elapsed time per iteration (ms): 7731.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155587E-01 | loss scale: 65536.0 | grad norm: 0.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.28 | backward-compute: 5483.46 | backward-params-all-reduce: 52.43 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.79 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.04 | batch-generator: 12.63
 iteration      969/    1000 | consumed samples:       496128 | elapsed time per iteration (ms): 7733.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154147E-01 | loss scale: 65536.0 | grad norm: 0.057 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2104.40 | backward-compute: 5487.59 | backward-params-all-reduce: 52.14 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 12.00 | optimizer: 81.51 | batch-generator: 12.34
 iteration      970/    1000 | consumed samples:       496640 | elapsed time per iteration (ms): 7725.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154653E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.93 | backward-compute: 5487.02 | backward-params-all-reduce: 52.16 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.86 | batch-generator: 12.46
-----------------------------------------------------------------------------------------------
 validation loss at iteration 970 | lm loss value: 1.155956E-01 | lm loss PPL: 1.122542E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      971/    1000 | consumed samples:       497152 | elapsed time per iteration (ms): 25796.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155099E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20157.12 | backward-compute: 5488.22 | backward-params-all-reduce: 51.99 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.00 | batch-generator: 109.79
 iteration      972/    1000 | consumed samples:       497664 | elapsed time per iteration (ms): 7726.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154255E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.36 | backward-compute: 5488.76 | backward-params-all-reduce: 52.33 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.65 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 79.97 | batch-generator: 12.14
 iteration      973/    1000 | consumed samples:       498176 | elapsed time per iteration (ms): 7724.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154751E-01 | loss scale: 65536.0 | grad norm: 0.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.00 | backward-compute: 5485.53 | backward-params-all-reduce: 52.15 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.21 | batch-generator: 12.33
 iteration      974/    1000 | consumed samples:       498688 | elapsed time per iteration (ms): 7732.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154953E-01 | loss scale: 65536.0 | grad norm: 0.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2108.74 | backward-compute: 5484.92 | backward-params-all-reduce: 51.80 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.03 | batch-generator: 12.15
 iteration      975/    1000 | consumed samples:       499200 | elapsed time per iteration (ms): 7729.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155433E-01 | loss scale: 65536.0 | grad norm: 0.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.29 | backward-compute: 5487.68 | backward-params-all-reduce: 52.13 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.00 | batch-generator: 12.13
 iteration      976/    1000 | consumed samples:       499712 | elapsed time per iteration (ms): 7724.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153739E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2097.58 | backward-compute: 5487.79 | backward-params-all-reduce: 51.70 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.01 | batch-generator: 12.30
 iteration      977/    1000 | consumed samples:       500224 | elapsed time per iteration (ms): 7723.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155282E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.89 | backward-compute: 5487.59 | backward-params-all-reduce: 51.94 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.06 | batch-generator: 12.84
 iteration      978/    1000 | consumed samples:       500736 | elapsed time per iteration (ms): 7729.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154916E-01 | loss scale: 65536.0 | grad norm: 0.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.05 | backward-compute: 5482.09 | backward-params-all-reduce: 52.64 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.26 | optimizer-unscale-and-check-inf: 11.82 | optimizer-clip-main-grad: 8.74 | optimizer-copy-main-to-model-params: 11.85 | optimizer: 80.28 | batch-generator: 12.42
 iteration      979/    1000 | consumed samples:       501248 | elapsed time per iteration (ms): 7734.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154943E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.59 | backward-compute: 5483.37 | backward-params-all-reduce: 51.85 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.78 | optimizer-copy-main-to-model-params: 11.75 | optimizer: 80.02 | batch-generator: 12.39
 iteration      980/    1000 | consumed samples:       501760 | elapsed time per iteration (ms): 7727.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155873E-01 | loss scale: 65536.0 | grad norm: 0.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.38 | backward-compute: 5486.71 | backward-params-all-reduce: 51.95 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.62 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.01 | batch-generator: 12.20
-----------------------------------------------------------------------------------------------
 validation loss at iteration 980 | lm loss value: 1.155726E-01 | lm loss PPL: 1.122516E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      981/    1000 | consumed samples:       502272 | elapsed time per iteration (ms): 25795.2 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155224E-01 | loss scale: 65536.0 | grad norm: 0.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20156.04 | backward-compute: 5488.08 | backward-params-all-reduce: 51.82 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.79 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.08 | batch-generator: 109.31
 iteration      982/    1000 | consumed samples:       502784 | elapsed time per iteration (ms): 7726.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154466E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.36 | backward-compute: 5488.39 | backward-params-all-reduce: 51.93 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.95 | batch-generator: 12.27
 iteration      983/    1000 | consumed samples:       503296 | elapsed time per iteration (ms): 7727.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155100E-01 | loss scale: 65536.0 | grad norm: 0.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2101.56 | backward-compute: 5486.60 | backward-params-all-reduce: 51.77 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.86 | optimizer-clip-main-grad: 8.71 | optimizer-copy-main-to-model-params: 11.83 | optimizer: 80.30 | batch-generator: 12.00
 iteration      984/    1000 | consumed samples:       503808 | elapsed time per iteration (ms): 7728.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155328E-01 | loss scale: 65536.0 | grad norm: 0.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2103.23 | backward-compute: 5484.80 | backward-params-all-reduce: 52.77 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.80 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 80.16 | batch-generator: 12.04
 iteration      985/    1000 | consumed samples:       504320 | elapsed time per iteration (ms): 7729.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154786E-01 | loss scale: 65536.0 | grad norm: 0.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.00 | backward-compute: 5487.88 | backward-params-all-reduce: 52.08 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 79.99 | batch-generator: 12.08
 iteration      986/    1000 | consumed samples:       504832 | elapsed time per iteration (ms): 7728.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154148E-01 | loss scale: 65536.0 | grad norm: 0.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.48 | backward-compute: 5483.25 | backward-params-all-reduce: 52.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.13 | batch-generator: 11.97
 iteration      987/    1000 | consumed samples:       505344 | elapsed time per iteration (ms): 7733.5 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154973E-01 | loss scale: 65536.0 | grad norm: 0.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2109.68 | backward-compute: 5483.56 | backward-params-all-reduce: 52.99 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.25 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.66 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.97 | batch-generator: 12.30
 iteration      988/    1000 | consumed samples:       505856 | elapsed time per iteration (ms): 7736.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155801E-01 | loss scale: 65536.0 | grad norm: 0.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2111.32 | backward-compute: 5484.50 | backward-params-all-reduce: 52.84 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.72 | optimizer: 80.04 | batch-generator: 12.21
 iteration      989/    1000 | consumed samples:       506368 | elapsed time per iteration (ms): 7734.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154229E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.77 | backward-compute: 5486.33 | backward-params-all-reduce: 53.15 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.74 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.08 | batch-generator: 12.24
 iteration      990/    1000 | consumed samples:       506880 | elapsed time per iteration (ms): 7731.1 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154858E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.54 | backward-compute: 5486.14 | backward-params-all-reduce: 52.17 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.76 | optimizer-copy-main-to-model-params: 11.77 | optimizer: 80.07 | batch-generator: 12.20
-----------------------------------------------------------------------------------------------
 validation loss at iteration 990 | lm loss value: 1.155548E-01 | lm loss PPL: 1.122496E+00 | 
-----------------------------------------------------------------------------------------------
 iteration      991/    1000 | consumed samples:       507392 | elapsed time per iteration (ms): 25822.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154467E-01 | loss scale: 65536.0 | grad norm: 0.029 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 20181.96 | backward-compute: 5487.89 | backward-params-all-reduce: 52.76 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.99 | batch-generator: 109.63
 iteration      992/    1000 | consumed samples:       507904 | elapsed time per iteration (ms): 7732.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153996E-01 | loss scale: 65536.0 | grad norm: 0.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2105.36 | backward-compute: 5487.22 | backward-params-all-reduce: 52.05 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.70 | optimizer-copy-main-to-model-params: 11.79 | optimizer: 80.06 | batch-generator: 12.15
 iteration      993/    1000 | consumed samples:       508416 | elapsed time per iteration (ms): 7729.8 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.156498E-01 | loss scale: 65536.0 | grad norm: 0.051 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2107.32 | backward-compute: 5482.89 | backward-params-all-reduce: 52.37 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.76 | optimizer-clip-main-grad: 8.67 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 79.99 | batch-generator: 12.14
 iteration      994/    1000 | consumed samples:       508928 | elapsed time per iteration (ms): 7730.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154168E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.62 | backward-compute: 5489.04 | backward-params-all-reduce: 51.86 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.73 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 79.84 | batch-generator: 12.08
 iteration      995/    1000 | consumed samples:       509440 | elapsed time per iteration (ms): 7730.3 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.154438E-01 | loss scale: 65536.0 | grad norm: 0.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2099.67 | backward-compute: 5491.26 | backward-params-all-reduce: 52.03 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.80 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.74 | optimizer: 80.00 | batch-generator: 12.19
 iteration      996/    1000 | consumed samples:       509952 | elapsed time per iteration (ms): 7727.7 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155087E-01 | loss scale: 65536.0 | grad norm: 0.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.05 | backward-compute: 5490.80 | backward-params-all-reduce: 51.74 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.22 | optimizer-unscale-and-check-inf: 11.78 | optimizer-clip-main-grad: 8.64 | optimizer-copy-main-to-model-params: 11.73 | optimizer: 79.96 | batch-generator: 12.10
 iteration      997/    1000 | consumed samples:       510464 | elapsed time per iteration (ms): 7731.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155036E-01 | loss scale: 65536.0 | grad norm: 0.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2102.49 | backward-compute: 5489.17 | backward-params-all-reduce: 52.26 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.21 | optimizer-unscale-and-check-inf: 11.79 | optimizer-clip-main-grad: 8.68 | optimizer-copy-main-to-model-params: 11.78 | optimizer: 80.12 | batch-generator: 12.73
 iteration      998/    1000 | consumed samples:       510976 | elapsed time per iteration (ms): 7725.4 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155439E-01 | loss scale: 65536.0 | grad norm: 0.002 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2095.75 | backward-compute: 5490.44 | backward-params-all-reduce: 51.92 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.24 | optimizer-unscale-and-check-inf: 11.75 | optimizer-clip-main-grad: 8.69 | optimizer-copy-main-to-model-params: 11.91 | optimizer: 80.13 | batch-generator: 12.34
 iteration      999/    1000 | consumed samples:       511488 | elapsed time per iteration (ms): 7724.6 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.155167E-01 | loss scale: 65536.0 | grad norm: 0.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2096.19 | backward-compute: 5489.45 | backward-params-all-reduce: 51.68 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.77 | optimizer-clip-main-grad: 8.72 | optimizer-copy-main-to-model-params: 11.81 | optimizer: 80.16 | batch-generator: 12.22
 iteration     1000/    1000 | consumed samples:       512000 | elapsed time per iteration (ms): 7727.0 | learning rate: 1.000E-05 | global batch size:   512 | lm loss: 1.153808E-01 | loss scale: 65536.0 | grad norm: 0.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
time (ms) | forward-compute: 2098.39 | backward-compute: 5489.49 | backward-params-all-reduce: 51.65 | backward-embedding-all-reduce: 0.02 | optimizer-copy-to-main-grad: 11.23 | optimizer-unscale-and-check-inf: 11.81 | optimizer-clip-main-grad: 8.83 | optimizer-copy-main-to-model-params: 11.76 | optimizer: 80.18 | batch-generator: 11.64
------------------------------------------------------------------------------------------------
 validation loss at iteration 1000 | lm loss value: 1.155422E-01 | lm loss PPL: 1.122482E+00 | 
------------------------------------------------------------------------------------------------
[after training is done] datetime: 2021-08-12 12:35:05 
------------------------------------------------------------------------------------------------------------------
 validation loss at the end of training for val data | lm loss value: 1.155717E-01 | lm loss PPL: 1.122515E+00 | 
------------------------------------------------------------------------------------------------------------------
Evaluating iter 1/10
Evaluating iter 2/10
Evaluating iter 3/10
Evaluating iter 4/10
Evaluating iter 5/10
Evaluating iter 6/10
Evaluating iter 7/10
Evaluating iter 8/10
Evaluating iter 9/10
Evaluating iter 10/10
-------------------------------------------------------------------------------------------------------------------
 validation loss at the end of training for test data | lm loss value: 1.155666E-01 | lm loss PPL: 1.122509E+00 | 
-------------------------------------------------------------------------------------------------------------------
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
